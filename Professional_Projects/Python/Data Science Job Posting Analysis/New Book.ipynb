{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ac0d33b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import warnings\n",
    "import urllib.request\n",
    "\n",
    "from webbot import Browser\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "13c5dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "8296097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words_list = pd.read_csv(\"Common_Articles_List.csv\")\n",
    "personality = pd.read_csv(\"Personality.csv\", sep=',')\n",
    "software = pd.read_csv(\"Programming_Languages.csv\")\n",
    "\n",
    "common = common_words_list[\"word\"].to_list()\n",
    "personality = [x.lower() for x in personality[\"Traits\"]]\n",
    "software = [x.lower() for x in software[\"languages\"]]\n",
    "education = [\"bachelors\", \"masters\", \"doctrine\", \"phd\", \"internship\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "a26c5d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indeed_page_numbers(page):\n",
    "    clock = False\n",
    "    page_numbers_element = page.find_all(\"span\", class_=\"pn\", text=True)\n",
    "\n",
    "    #First Loop To Give Us the 1st 5 Pages if available\n",
    "    page_number_list = []\n",
    "    for items in page_numbers_element:\n",
    "        #print(items)\n",
    "        page_number_list.append(\"https://www.indeed.com\" + items.parent[\"href\"])\n",
    "    \n",
    "    if len(page_numbers_element) == 4:\n",
    "        \n",
    "        loop_counter = 5\n",
    "        \n",
    "        while clock is False:\n",
    "            last_page = page_number_list[-1]\n",
    "            analysis_page = requests.get(last_page)\n",
    "            soup = BeautifulSoup(analysis_page.content, \"html.parser\")\n",
    "            new_link_list = soup.find_all(\"span\", class_=\"pn\", text=True)\n",
    "            \n",
    "            try:\n",
    "                additional_counter = int(new_link_list[-1].text) - loop_counter\n",
    "            \n",
    "                if additional_counter < 1: \n",
    "                    clock = True\n",
    "\n",
    "                else: \n",
    "                    for items in new_link_list[(additional_counter * -1):]:\n",
    "                        loop_counter = int(items.text)\n",
    "                        page_number_list.append(\"https://www.indeed.com\" + items.parent[\"href\"])\n",
    "                    clock = False\n",
    "                    \n",
    "            except IndexError:\n",
    "                clock = True\n",
    "        \n",
    "        \n",
    "    return page_number_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7dfa2722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chrome_engine():\n",
    "    options = Options()\n",
    "    options.binary_location = \"C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\"\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "    #User Input and Driver Link\n",
    "    driver.get('https://indeed.com/')\n",
    "    job_title = driver.find_element_by_id('text-input-what')\n",
    "    job_title.send_keys(\"Data Analyst\")\n",
    "    location = driver.find_element_by_id(\"text-input-where\")\n",
    "    location.send_keys(\"test\")\n",
    "    locate_clear_field = driver.find_element_by_class_name(\"icl-TextInputClearable-icon\")\n",
    "    locate_clear_field.click()\n",
    "    fixed_location = location.send_keys(\"Washington, DC\")\n",
    "    submit_button = driver.find_element_by_class_name(\"yosegi-InlineWhatWhere-primaryButton\")\n",
    "    submit_button.send_keys(Keys.RETURN)\n",
    "    current_page_url = driver.current_url\n",
    "    \n",
    "    print(\"Chrome Engine Successful\")\n",
    "    print(\"Base Link: \", current_page_url)\n",
    "    return current_page_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "097e8ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indeed_page_web_scrapper(current_page_url):\n",
    "    indeed_url = \"https://www.indeed.com\"\n",
    "\n",
    "    analysis_page = requests.get(current_page_url)\n",
    "    soup = BeautifulSoup(analysis_page.content, \"html.parser\")\n",
    "\n",
    "\n",
    "    additional_page_links = get_indeed_page_numbers(soup)\n",
    "\n",
    "    print(len(additional_page_links), \" Potential Jobs Pages\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    job_links = []    \n",
    "    job_listings = soup.find_all('a', class_=\"tapItem\")\n",
    "    counter = 0\n",
    "    for job in job_listings:\n",
    "        job_links.append(indeed_url + job[\"href\"])\n",
    "\n",
    "\n",
    "    for page_link in additional_page_links:\n",
    "        web_page = requests.get(page_link)\n",
    "        soup = BeautifulSoup(web_page.content, \"html.parser\")\n",
    "        job_listings = soup.find_all('a', class_=\"tapItem\")\n",
    "\n",
    "\n",
    "        for job in job_listings:\n",
    "            job_links.append(indeed_url + job[\"href\"])\n",
    "\n",
    "\n",
    "    print(\"Total Jobs Analyzed: \", len(job_links))\n",
    "    print(\"   \")\n",
    "    return job_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "09dc5aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_description_cleaner(page_body_text):\n",
    "    counter = 0\n",
    "    unwanted_chars = [\" \", \",\", \"/\", \"'\\'\", \".\", \"(\", \")\", \";\", '\"', \"'\", \":\", \"-\", \"_\", \n",
    "                      \"&\", \"[\", \"]\", \"*\", \"?\", \"#\", \"!\", \"%\", \"®\", \"“\", '”', \":\", \"~\"]\n",
    "\n",
    "    additional_splitting = [\"/\", \"(\", \")\", \"%\", \"/\", \".\", \"-\", \"/\"]\n",
    "    final_list = []\n",
    "    word_frequency = {}\n",
    "\n",
    "    for items in page_body_text:\n",
    "        if items is not None:\n",
    "            text = re.sub(\"\\n\", \" \", items)\n",
    "            clean_list = text.split()\n",
    "\n",
    "            for word in clean_list:\n",
    "                split_words = []\n",
    "                if word != \"\":\n",
    "\n",
    "                    if len(word) > 1:\n",
    "\n",
    "                        cleaned = False\n",
    "                        #print(\"Word Going Into Machine: \", word)\n",
    "                        while cleaned is False:\n",
    "\n",
    "                            if len(word) > 1 and word[len(word)-1] in unwanted_chars:\n",
    "                                word = word[:-1]\n",
    "\n",
    "                                if len(word) > 1 and word[0] in unwanted_chars:\n",
    "                                    word = word[1:]\n",
    "\n",
    "\n",
    "                            if len(word) > 1 and word[0] in unwanted_chars:\n",
    "                                word = word[1:]\n",
    "\n",
    "                                if len(word) > 1 and word[len(word)-1] in unwanted_chars:\n",
    "                                    word = word[:-1]\n",
    "\n",
    "\n",
    "                            if len(word) == 1:\n",
    "                                if word in unwanted_chars:\n",
    "                                    #print(\"Word Deleted: \", word)\n",
    "                                    cleaned = True\n",
    "\n",
    "                                else:\n",
    "                                    #print(\"Passed WORD = 1: \", word)\n",
    "                                    #print(\"   \")\n",
    "                                    final_list.append(word.lower().strip())\n",
    "                                    cleaned = True\n",
    "\n",
    "                            elif word[0] not in unwanted_chars and word[len(word) - 1] not in unwanted_chars:\n",
    "                                #print(\"Passed ELIF: \", word)\n",
    "                                #print(\"   \")\n",
    "                                if word[-2:] == \"'s\" or word[-2:] == \"’s\":\n",
    "                                    #print(\"Machine Processing S Condition: \", word)\n",
    "                                    word = word[:-2] + \"s\"\n",
    "                                    #print(\"Passed Condition: \", word)\n",
    "                                    #print(\"   \")\n",
    "\n",
    "                                if \"$\" in word:\n",
    "                                    #print(\"Machine Processing Money Condition: \", word)\n",
    "                                    word = \"$\" + word.split(\"$\", 1)[1]\n",
    "                                    #print(\"Passed Condition: \", word)\n",
    "                                    #print(\"   \")\n",
    "\n",
    "                                for symbols in additional_splitting:\n",
    "                                    if symbols in word: \n",
    "                                        split_words = word.split(symbols)\n",
    "                                        #print(\"Machine Processing Extra Symbols in Word Condition: \", word)\n",
    "                                        #print(\"Passed Condition: \", split_words)\n",
    "                                        #print(\"   \")\n",
    "\n",
    "                                if len(split_words) == 0: \n",
    "                                    final_list.append(word.lower().strip())\n",
    "                                    cleaned = True\n",
    "                                else: \n",
    "                                    for words in split_words:\n",
    "                                        #print(\"Word Added Based On Extra Symbol Condition: \", words)\n",
    "                                        #print(\"     \")\n",
    "                                        final_list.append(words.lower().strip())\n",
    "                                        cleaned = True\n",
    "\n",
    "                            else: \n",
    "                                cleaned = False\n",
    "\n",
    "                    else: \n",
    "                        if word not in unwanted_chars:\n",
    "                            #print(\"Passed SINGLE LETTER NOT IN CHARS: \", word)\n",
    "                            #print(\"   \")\n",
    "                            final_list.append(word.lower().strip())\n",
    "        \n",
    "        else: \n",
    "            continue\n",
    "\n",
    "    print(\"Cleaning Out Format Of Words!\")\n",
    "    print(\"Total Words For Analysis: \",len(final_list))\n",
    "    print(\"   \")\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "32b5f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_description_page(job_links):\n",
    "    counter = 0\n",
    "    page_body_text = []\n",
    "\n",
    "    for job_page in job_links:\n",
    "        loaded_page = requests.get(job_page)\n",
    "        soup = BeautifulSoup(loaded_page.text, \"html.parser\")\n",
    "\n",
    "\n",
    "        page_body = soup.find_all(\"div\", class_=\"jobsearch-JobComponent-description\")\n",
    "\n",
    "        for elements in page_body:\n",
    "            text = elements.get_text()\n",
    "\n",
    "            page_body_text.append(text)\n",
    "            counter += 1\n",
    "            \n",
    "    print(\"Analyzing Job Descriptions\")\n",
    "    print(\"Total Job Descriptions Readable: \", len(page_body_text))\n",
    "    print(\"   \")\n",
    "    return page_body_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "55b8dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counter(final_list):\n",
    "    word_frequency= {}\n",
    "    for words in final_list:\n",
    "        if words not in word_frequency:\n",
    "            word_frequency[words] = 1\n",
    "        else:\n",
    "            word_frequency[words] += 1\n",
    "\n",
    "    for words in common: \n",
    "        if words in word_frequency.keys():\n",
    "            del word_frequency[words]\n",
    "\n",
    "    sorted_word_frequency_list = sorted(word_frequency.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_word_frequency_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "4ff6b1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytics(sorted_word_frequency_list):\n",
    "    programming_languages = []\n",
    "    personality_traits = []\n",
    "    salary_expectations = []\n",
    "    experience = [] \n",
    "\n",
    "    for items in sorted_word_frequency_list: \n",
    "        if items[0] in software:\n",
    "            programming_languages.append(items)\n",
    "\n",
    "        if items[0] in personality:\n",
    "            personality_traits.append(items)\n",
    "\n",
    "        if items[0] in education:\n",
    "            experience.append(items)\n",
    "\n",
    "        elif \"$\" in items[0] and len(items[0]) > 1:\n",
    "            if \"k\" in items[0] and \"-\" not in items[0]: \n",
    "                money = items[0]\n",
    "                money = money[:-1] + \",000\"\n",
    "                salary_expectations.append((money, items[1]))\n",
    "                continue\n",
    "\n",
    "            if len(items[0]) <= 4:\n",
    "                money = items[0]\n",
    "\n",
    "                try:\n",
    "                    int(money[1:])\n",
    "                    money = \"$\" + str(f'{(int(money[1:]) * 40 * 52):,}')\n",
    "                    salary_expectations.append((money, items[1]))\n",
    "\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "            else:\n",
    "                try:\n",
    "                    money = items[0]\n",
    "                    money = \"$\" + str(f'{(int(money[1:])):,}')\n",
    "                    salary_expectations.append((money, items[1]))\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "    return programming_languages, personality_traits, salary_expectations, experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "28a188b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 100.0.4896\n",
      "Get LATEST chromedriver version for 100.0.4896 google-chrome\n",
      "Trying to download new driver from https://chromedriver.storage.googleapis.com/100.0.4896.60/chromedriver_win32.zip\n",
      "Driver has been saved in cache [C:\\Users\\Julio\\.wdm\\drivers\\chromedriver\\win32\\100.0.4896.60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chrome Engine Successful\n",
      "Base Link:  https://www.indeed.com/jobs?q=Data%20Analyst&l=Washington%2C%20DC&vjk=7929baad599bdf37\n",
      "64  Potential Jobs Pages\n",
      "Total Jobs Analyzed:  807\n",
      "   \n",
      "Analyzing Job Descriptions\n",
      "Total Job Descriptions Readable:  428\n",
      "   \n",
      "Cleaning Out Format Of Words!\n",
      "Total Words For Analysis:  247603\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "current_page_url = chrome_engine()\n",
    "\n",
    "job_links = indeed_page_web_scrapper(current_page_url)\n",
    "\n",
    "page_body_text = job_description_page(job_links)\n",
    "\n",
    "final_list = job_description_cleaner(page_body_text)\n",
    "\n",
    "sorted_word_frequency_list = word_counter(final_list)\n",
    "\n",
    "visualization_lists = analytics(sorted_word_frequency_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65413fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7a066f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a92714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f32990",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b38f4a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f057508c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf685554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfd0622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c68be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277635ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188495cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
