{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac0d33b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import warnings\n",
    "import urllib.request\n",
    "\n",
    "from webbot import Browser\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13c5dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8296097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_words():\n",
    "    \"Returns common english articles/words list from parsed excel list excel\"\n",
    "    \n",
    "    common_words_list = pd.read_csv(\"Common_Articles_List.csv\")\n",
    "    return common_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a26c5d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indeed_page_numbers(page):\n",
    "    page_numbers_element = soup.find_all(\"span\", class_=\"pn\", text=True)\n",
    "    print(page_numbers_element)\n",
    "    page_number_list = []\n",
    "    for items in page_numbers_element:\n",
    "        page_number_list.append(\"https://www.indeed.com\" + items.parent[\"href\"])\n",
    "    return page_number_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dfa2722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 100.0.4896\n",
      "Get LATEST chromedriver version for 100.0.4896 google-chrome\n",
      "Trying to download new driver from https://chromedriver.storage.googleapis.com/100.0.4896.60/chromedriver_win32.zip\n",
      "Driver has been saved in cache [C:\\Users\\Julio\\.wdm\\drivers\\chromedriver\\win32\\100.0.4896.60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span class=\"pn\">2</span>, <span class=\"pn\">3</span>, <span class=\"pn\">4</span>, <span class=\"pn\">5</span>]\n",
      "Total Jobs Analyzed:  75\n"
     ]
    }
   ],
   "source": [
    "options = Options()\n",
    "options.binary_location = \"C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\"\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "#User Input and Driver Link\n",
    "driver.get('https://indeed.com/')\n",
    "job_title = driver.find_element_by_id('text-input-what')\n",
    "job_title.send_keys(\"data engineer\")\n",
    "location = driver.find_element_by_id(\"text-input-where\")\n",
    "location.send_keys(\"test\")\n",
    "locate_clear_field = driver.find_element_by_class_name(\"icl-TextInputClearable-icon\")\n",
    "locate_clear_field.click()\n",
    "fixed_location = location.send_keys(\"Silver Spring, MD\")\n",
    "submit_button = driver.find_element_by_class_name(\"yosegi-InlineWhatWhere-primaryButton\")\n",
    "submit_button.click()\n",
    "\n",
    "\n",
    "current_page_url = driver.current_url\n",
    "indeed_url = \"https://www.indeed.com\"\n",
    "\n",
    "analysis_page = requests.get(current_page_url)\n",
    "soup = BeautifulSoup(analysis_page.content, \"html.parser\")\n",
    "\n",
    "\n",
    "additional_page_links = get_indeed_page_numbers(soup)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "job_links = []    \n",
    "job_listings = soup.find_all('a', class_=\"tapItem\")\n",
    "counter = 0\n",
    "for job in job_listings:\n",
    "    job_links.append(indeed_url + job[\"href\"])\n",
    "    \n",
    "\n",
    "for page_link in additional_page_links:\n",
    "    web_page = requests.get(page_link)\n",
    "    soup = BeautifulSoup(web_page.content, \"html.parser\")\n",
    "    job_listings = soup.find_all('a', class_=\"tapItem\")\n",
    "  \n",
    "    \n",
    "    for job in job_listings:\n",
    "        job_links.append(indeed_url + job[\"href\"])\n",
    "\n",
    "        \n",
    "print(\"Total Jobs Analyzed: \", len(job_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28a188b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "Total Texts:  75\n",
      "DONE\n",
      "Job detailsSalary$116,800 - $163,500 a yearJob TypeFull-timeFull Job Description\n",
      "\n",
      "\n",
      "YOUR LIFE'S MISSION: POSSIBLE \n",
      "You have goals, dreams, hobbies and things you’re passionate about.\n",
      " What’s Important to You Is Important to Us We’re looking for people who not only want to do meaningful, challenging work, keep their skills sharp and move ahead, but who also take time for the things that matter to them—friends, family and passions. And we're looking for team members who are passionate about our mission—making a difference in military members' and their families' lives. Together, we can make it happen.\n",
      " Don’t take our word for it.\n",
      "\n",
      "Military Times 2021 Best for Vets Employers\n",
      "WayUp Top 100 Internship Programs\n",
      "Forbes® 2021 The Best Employers for New Grads\n",
      "Forbes® America's Best Employers\n",
      "Newsweek Top 100 Most Loved Workplaces\n",
      "2021 People Companies that Care\n",
      "Fortune Best Workplaces for Women\n",
      "Fortune 100 Best Companies to Work For®\n",
      "Fortune Best Workplaces for Millennials\n",
      "Computerworld® Best Places to Work in IT\n",
      "\n",
      " Basic Purpose \n",
      "\n",
      "   To optimize the performance of business operations by analyzing current and forecasting future performance as it relates to our systems, system integrations and system processes. Apply various analytical techniques to solve operational issues and support strategic initiatives. Work under minimal supervision.\n",
      "   \n",
      " Develop strategies for data engineering, reporting and analytics. Responsible for designing, building, integrating data from various resources, and managing big data. Develop and write complex queries and ensure they work smoothly with the goal of optimizing the performance of Navy Federal’s data analytics ecosystem. Highly skilled and proficient in generating reports and visualizations for analytics. Considered senior level position. Conduct complex, essential work under minimal supervision and with wide latitude for independent judgment. Individual contributor and mentor to junior staff.\n",
      "   \n",
      "\n",
      "Responsibilities:\n",
      "   \n",
      "\n",
      "\n",
      "Provide Business Intelligence (BI) and Data Warehousing (DW) solutions and support by leveraging project standards and leading analytics platforms\n",
      "Evaluate and collaborate on functional requirements for BI and DW solutions\n",
      "Define and build data integration processes to be used across the organization\n",
      "Build conceptual and logical data models for stakeholders and management\n",
      "Work directly with business leadership to understand data requirements; propose and develop solutions that enable effective decision-making and drives business objectives\n",
      "Prepare advanced project implementation plans which highlight major milestones and deliverables, leveraging standard methods and work planning tools\n",
      "Evaluate, develop, and implement analytical techniques and best practices to educate business users\n",
      "Build and evangelize self-service BI & analytics capabilities across the enterprise\n",
      "Present trainings and webinars to the BI & analytics community on a regular basis\n",
      "Analyze and validate data accuracy of report results\n",
      "Analyze and interpret collected data; spotting trends; writing reports and recommendations for internal or external clients\n",
      "Recognize potential issues and risks during the analytics project implementation and suggest mitigation strategies\n",
      "Mentor junior project team members in carrying out analytics project implementation activities\n",
      "Prepare high quality project deliverables that are valued by the business and present them in such a manner that they are easily understood by project stakeholders\n",
      "Interpret data presented in models, charts, and tables and transform it into a format that is useful to the business and promotes effective decision making\n",
      "Use statistical practices to analyze current and historical data to make predictions, identify risks, and opportunities enabling better decisions on planned/future events\n",
      "Identify improvements to the way in which analytics services an entire function\n",
      "Communicate and own the process of manipulating and merging large datasets\n",
      "Key point of contact between the data analyst/data scientist and the project/functional analytics leads\n",
      "Perform other duties as assigned\n",
      "\n",
      "\n",
      " Qualifications and Education Requirements:\n",
      "\n",
      "\n",
      "\n",
      "Bachelor’s degree in Information Systems, Computer Science, Engineering, or related field, or the equivalent combination of education, training, and experience\n",
      "Advanced knowledge of various data structures and the ability to manipulate data within visualization tools such as Power BI and Tableau\n",
      "Experience with ETL tools and techniques and provisioning data for analytics using Azure Databricks, Azure Data Factory, Azure Synapse Analytics\n",
      "Programming skills in SQL, Python, R\n",
      "Experience with various data structures and the ability to extract data from various data sources such as data warehouse, data lake, data hubs and other\n",
      "Experience with data cleansing, data pipelines and other analytical techniques required for data usage\n",
      "Experience in data mapping and building requirements\n",
      "Understands data models, large datasets, business/technical requirements, statistical programming languages and libraries\n",
      "Experience with generating a services catalog and implementation plan\n",
      "Experience with provisioning analytics tools such as Power BI, Tableau in the Cloud\n",
      "Administration experience with Power BI, Tableau, and migration of infrastructure to Cloud\n",
      "Ability to understand the business problem and determine what aspects of it require optimization; articulate those aspects in a clear and concise manner\n",
      "Ability to define and analyze complex models that predict the probability of an outcome\n",
      "Ability to understand other projects or functional areas to consolidate analytical needs and processes\n",
      "Demonstrates a passion for analytics, data visualization, educating users, and customer enablement\n",
      "Demonstrates a high comfort level speaking in front of large audiences and possesses an executive presence\n",
      "Demonstrates change management and/or communication skills\n",
      "Demonstrates skill in sourcing, maintaining, and updating data\n",
      "Ability to manipulate raw data into effective visualization dashboards\n",
      "Ability to communicate end to end data outcomes visually\n",
      "Ability to manage the process between updating and maintaining data source systems and implementing data related requirements\n",
      "Proficient in managing the process between updating and maintaining data source systems and implementing data related requirements\n",
      "\n",
      "\n",
      " Desired Qualifications and Education Requirements:\n",
      "\n",
      "\n",
      "\n",
      "Knowledge of and the ability to perform advanced statistical analysis such as measures of central tendency, normal distribution, variance, standard deviation, basic tests, correlation, and regression techniques\n",
      "Knowledge of Navy Federal Credit Union instructions, standards, and procedures\n",
      "\n",
      "\n",
      " Hours: Monday - Friday, 8:00am - 4:30pm\n",
      "   \n",
      "\n",
      "Location: 820 Follin Lane, Vienna, VA 22180\n",
      "   \n",
      " Due to COVID-19 and social distancing, this position will be temporarily working from home with plans to return to campus at the desired location listed once Navy Federal is back to normal operations. The specific logistics for returning to campus will be determined at a future date by individual leadership.\n",
      "   \n",
      "\n",
      "Salary: Navy Federal Credit Union assesses market data to establish salary ranges that enable us to remain\n",
      "    competitive. You are paid within the salary range, based on your experience, location and market position.\n",
      "   \n",
      "\n",
      "The salary range for this position is: $116,800 to $163,500\n",
      "  \n",
      " Equal Employment Opportunity \n",
      "Navy Federal values, celebrates, and enacts diversity in the workplace. Navy Federal takes affirmative action to employ and advance in employment qualified individuals with disabilities, disabled veterans, Armed Forces service medal veterans, recently separated veterans, and other protected veterans. EOE/AA/M/F/Veteran/Disability  COVID-19 Vaccine Information  As a COVID-19 safety measure, our employees must either provide proof of COVID-19 vaccination or follow additional safety protocols, including testing.  Disclaimer  Navy Federal reserves the right to fill this role at a higher/lower grade level based on business need. An assessment may be required to compete for this position.  Bank Secrecy Act  Remains cognizant of and adheres to Navy Federal policies and procedures, and regulations pertaining to the Bank Secrecy Act.  Employee Referrals  This position is eligible for the TalentQuest employee referral program. If an employee referred you for this job, please apply using the system-generated link that was sent to you.\n",
      "\n",
      "Hiring InsightsJob activityPosted 30+ days ago\n",
      "Job detailsSalary$95,600 - $163,500 a yearJob TypeFull-timeFull Job Description\n",
      "\n",
      "\n",
      "YOUR LIFE'S MISSION: POSSIBLE \n",
      "You have goals, dreams, hobbies and things you’re passionate about.\n",
      " What’s Important to You Is Important to Us We’re looking for people who not only want to do meaningful, challenging work, keep their skills sharp and move ahead, but who also take time for the things that matter to them—friends, family and passions. And we're looking for team members who are passionate about our mission—making a difference in military members' and their families' lives. Together, we can make it happen.\n",
      " Don’t take our word for it.\n",
      "\n",
      "FORTUNE 100 Best Companies to Work For®\n",
      "Computerworld® Best Places to Work in IT\n",
      "FORTUNE® Best Workplaces for Millennials\n",
      "Forbes® America’s Best Employers\n",
      "\n",
      " Basic Purpose \n",
      "\n",
      "   Navy Federal Credit Union is seeking a staff engineer to join their Data Protection and Storage Services team (DPSS). DPSS provides infrastructure design, implementation and management for block, object and file storage systems throughout the NFCU enterprise. DPSS also provides design, implementation, and management of data protection services in the form of backup systems, data copy management, and resilient storage. To research, evaluate, design, implement, and maintain system and product solutions, applying knowledge of engineering principles. To provide technical direction and engineering support for projects and infrastructure. Develop and maintain expert functional knowledge of evolving IT engineering industry technologies/competition, concepts and trends.\n",
      "   \n",
      " The successful candidate will have broad knowledge of storage and data protection technologies, ability to work both independently and as a contributor in a team environment and will possess at least five years of relevant industry experience with a bachelor’s degree OR ten years of direct relevant experience.\n",
      "   \n",
      "\n",
      "Required attributes include:\n",
      "\n",
      "\n",
      "\n",
      "Strong experience with modern and legacy data protection solutions (i.e., Rubrik, Cohesity, Commvault, TSM, etc.). in a large multi-petabyte distributed environment. Preference for candidates who are experienced protecting on-prem and cloud-based data.\n",
      "Good understanding of physical tape libraries and experience with security key managers.\n",
      "Strong experience with both primary and secondary storage platforms, their implementation, operation, and protection. This should include SAN-based block storage, object storage, and file storage. Preference for candidates with IBM storage platform experience\n",
      "Good understanding of modern security threats, including ransomware attacks, and creating solutions to protect data against them.\n",
      "\n",
      "\n",
      "Desirable attributes include:\n",
      "\n",
      "\n",
      "\n",
      "IBM block storage systems, including Storwize/Spectrum Virtualize, Flash System A9000, Flash system 9100/9200\n",
      "IBM Cloud Object Storage\n",
      "NetApp Clustered Data OnTAP\n",
      "Demonstrated scripting ability\n",
      "Microsoft OneDrive Cloud administration\n",
      "Certifications in one or more of the required or preferred technical areas\n",
      "Experience with Linux, AIX or Windows Server integration\n",
      "Experience integrating with VMWare on Cisco UCS or other platforms\n",
      "Experience with automation/orchestration products\n",
      "Experience with vulnerability management processes\n",
      "\n",
      "\n",
      " Responsibilities\n",
      "\n",
      "\n",
      "\n",
      "Full life-cycle project management\n",
      " o Establish and lead project teams\n",
      "    o Develop project plan/scope/schedule/cost/communications\n",
      "    o Procure and/or manage resources/timelines/deadlines/quality\n",
      "    o Risk, Issue and Change management\n",
      "    o Ensure successful project implementation\n",
      "    o Scope of responsibility\n",
      "   \n",
      "\n",
      "Lead, guide and mentor less experienced staff\n",
      "Provide input and make budgetary recommendations regarding staffing and equipment\n",
      "Apply engineering principles into the design and enhancement of new and existing systems\n",
      "Document new system components, or modifications to existing components\n",
      "Ensure the security and integrity of system and product solutions including compliance with Navy Federal, industry engineering and Information Security principles and practices\n",
      "Perform engineering tasks and assignments in support of business needs\n",
      "Perform engineering technology research, procurement, deployment, and configuration for new and modified systems\n",
      "Provide technical leadership in the architecture discipline and development of information technology solutions\n",
      "Present clear, organized and concise information to all audiences through a variety of media to enable effective business decisions\n",
      "Perform other duties as assigned\n",
      "\n",
      "\n",
      " Qualifications\n",
      "\n",
      "\n",
      "\n",
      "Bachelor's Degree in Business Administration, Information Technology or the equivalent combination of training, education, and experience\n",
      "Significant experience in leading, guiding and coaching professional staff\n",
      "Advanced knowledge of engineering discipline\n",
      "Advanced organizational, planning and time management skills\n",
      "Advanced skill exercising initiative and using good judgment to make sound decisions\n",
      "Expert database and presentation software skills\n",
      "Expert research, analytical, and problem solving skills\n",
      "Expert verbal and written communication skills\n",
      "Expert word processing and spreadsheet software skills\n",
      "\n",
      "\n",
      " Hours: Working hours are 0800 – 1630 Monday through Friday. The engineer will be required to participate in a rotation requiring periodic 24x7 on-call coverage. The engineer will be required to participate in off-hours and weekend maintenance activities, as needed.\n",
      "   \n",
      "\n",
      "Location: The position is onsite at the major NFCU campuses in Vienna, Virginia or Pensacola, Florida. Teleworking will be considered on a case-by-case basis.\n",
      "   \n",
      "\n",
      "Salary: Navy Federal Credit Union assesses market data to establish salary ranges that enable us to remain\n",
      "    competitive. You are paid within the salary range, based on your experience, location and market position.\n",
      "   \n",
      "\n",
      "The salary range for this position is: $95,600 to $163,500 Annual\n",
      "  \n",
      " Equal Employment Opportunity \n",
      "Navy Federal values, celebrates, and enacts diversity in the workplace. Navy Federal takes affirmative action to employ and advance in employment qualified individuals with disabilities, disabled veterans, Armed Forces service medal veterans, recently separated veterans, and other protected veterans. EOE/AA/M/F/Veteran/Disability  COVID-19 Vaccine Information  As a COVID-19 safety measure, our employees must either provide proof of COVID-19 vaccination or follow additional safety protocols, including testing.  Disclaimer  Navy Federal reserves the right to fill this role at a higher/lower grade level based on business need. An assessment may be required to compete for this position.  Bank Secrecy Act  Remains cognizant of and adheres to Navy Federal policies and procedures, and regulations pertaining to the Bank Secrecy Act.  Employee Referrals  This position is eligible for the TalentQuest employee referral program. If an employee referred you for this job, please apply using the system-generated link that was sent to you.\n",
      "\n",
      "Hiring InsightsJob activityPosted 24 days ago\n",
      "Job detailsSalary$70,000 - $110,000 a yearJob TypeFull-timeFull Job Description\n",
      "\n",
      "  Jnr Data Engineer \n",
      "  \n",
      "   If you are a Data Engineer with experience, please read on!\n",
      "   \n",
      " Based in beautiful Bethesda, MD we're an employee centric and data driven tech company that specializes in serving higher education institutions. We empower institutional effectiveness through assessment, benchmarking and decision support via an enterprise analytics platform. Due to growth and demand for our services, we are in need of hiring a Data Engineer that possesses experience with ETL, SQL and other related platforms.\n",
      "  \n",
      " What You Will Be Doing\n",
      "\n",
      "    You will be joining our impressive technical team working on challenging data integration projects in a fast paced, collaborative team environment. Our team is built of ETL, BI developers and analysts who are dedicated to the success of higher education. This position is currently fully remote due to COVID, but may require occasional work from Bethesda, MD when return to work is possible.\n",
      "  \n",
      " What You Need for this Position\n",
      "\n",
      "    1+ year(s) experience \n",
      "    Need to have:\n",
      "   \n",
      "\n",
      "ETL\n",
      "SQL\n",
      "\n",
      " Preferred to have:\n",
      "   \n",
      "\n",
      "Data Warehouse\n",
      "Data Analysis\n",
      "System Integration\n",
      "\n",
      "\n",
      " What's In It for You\n",
      "\n",
      "    Salary ($80K - $110K)\n",
      "   \n",
      "\n",
      "Health, Vision, Dental\n",
      "401(k) w/comapny match \n",
      "WFH flexibility\n",
      "Competitive PTO package\n",
      "\n",
      "\n",
      "\n",
      "    Interested in joining a team orientated, cutting edge tech company with incredible benefits in a flexible work environment? Come show off your skills and see how you can make our data engineering department even better than it already is! \n",
      "    Go ahead apply now!\n",
      "  \n",
      "\n",
      "    Colorado employees will receive paid sick leave. For additional information about available benefits, please contact Andy Prickett\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "Applicants must be authorized to work in the U.S.\n",
      "\n",
      "CyberCoders, Inc is proud to be an Equal Opportunity Employer\n",
      "\n",
      " All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law. \n",
      "  \n",
      "\n",
      "Your Right to Work – In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.\n",
      " \n",
      "Hiring InsightsJob activityPosted Today\n",
      "Job detailsSalary$82,400 - $123,600 a yearJob TypeFull-timeFull Job Description\n",
      "\n",
      "Requisition ID: R10038357\n",
      "\n",
      "Category: Engineering \n",
      "Location: Falls Church, Virginia, United States of America \n",
      "Citizenship Required: United States Citizenship \n",
      "Clearance Type: None \n",
      "Telecommute: Yes- May Consider Full Time Teleworking for this position \n",
      "Shift: 1st Shift (United States of America) \n",
      "Travel Required: No \n",
      "Positions Available: 3 \n",
      "\n",
      "\n",
      "\n",
      "   At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.\n",
      "    Join Northrop Grumman on our continued mission to push the boundaries of possible across land, sea, air, space, and cyberspace. Enjoy a culture where your voice is valued and start contributing to our team of passionate professionals providing real-life solutions to our world’s biggest challenges. We take pride in creating purposeful work and allowing our employees to grow and achieve their goals every day by Defining Possible. With our competitive pay and comprehensive benefits, we have the right opportunities to fit your life and launch your career today.\n",
      " Northrop Grumman is seeking Systems Engineers. This position will be located in our Enterprise Services Sector at Falls Church, VA. This position will be in the Pathways rotational program where there will be three rotation opportunities within engineering.\n",
      " The qualified candidate will become part of Northrop Grumman’s Next Gen technology organization.\n",
      " Basic Qualifications:\n",
      " A candidate must meet ALL of the below criteria. The candidate must:\n",
      "\n",
      " Be completing or has completed their degree (Bachelor’s or Master’s) from an accredited institution\n",
      " Have an overall cumulative GPA of 3.0 out of 4.0 or higher (unofficial academic transcripts must be provided at time of application by uploading the documents to your application or profile)\n",
      " Be able to obtain a U.S. Government security clearance (U.S. citizenship is a pre-requisite)\n",
      "\n",
      " Preferred Qualifications:\n",
      "\n",
      " Have an overall cumulative GPA of 3.70/4.0 or higher\n",
      " Data Analytics\n",
      "\n",
      " Salary Range: 82,400 - 123,600\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.\n",
      "   \n",
      "\n",
      "\n",
      "\n",
      "The health and safety of our employees and their families is a top priority. With the continuing impacts of COVID-19 around the world, we are taking action to protect the health and well-being of our colleagues and maintain the safety of the communities where we operate. As a federal contractor, and consistent with Executive Order 14042 (https://www.saferfederalworkforce.gov/contractors/) we require all newly hired employees in the United States to be fully vaccinated by their start date. Federal guidance allows for disability/medical and religious accommodations with respect to the vaccine requirement. Any requested accommodations must be reviewed and approved (if applicable) in advance of your start date.\n",
      " Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.\n",
      "\n",
      "\n",
      "\n",
      "Hiring InsightsJob activityPosted 3 days ago\n",
      "Job detailsSalary$140,000 a yearFull Job Description\n",
      "\n",
      "  Addison Group is working with a client based in Arlington, VA looking to bring on a strong Sr. Data Engineer. This is a 100% remote opportunity that will be working on a team of Data Engineers and Administrators building and modernizing the client's data platform.\n",
      "  \n",
      " The current platform utilizes SQL Server Enterprise on Google Cloud Platform (GCP), as well as Snowflake and Python. This role is highly involved in the evolution of the platform to modern data warehousing technologies. The ideal candidate has experience with large data sets, hands on experience with cloud data warehousing, and a strong desire to continue learning and solving problems.\n",
      "  \n",
      "\n",
      "Primary Job Duties: \n",
      "\n",
      "Responsible for end to end project ownership\n",
      "Design high performance, resilient, efficient data pipelines\n",
      "Become a subject matter expert in the data layer with deep understanding of entire pipeline\n",
      "Play a key role in data architecture and design discussions\n",
      "Design and develop high-volume, low-latency applications for mission-critical systems, delivering high-availability and performance\n",
      "Follow established processes and be a champion for best practices and continuous improvement.\n",
      "Mentor junior developers and delegate work where appropriate\n",
      "Contribute in all phases of the development lifecycle\n",
      "Deliver timely, well written, well designed, testable, efficient code\n",
      "Ensure designs and code are in compliance with specifications\n",
      "Design solutions with a dev-ops mindset\n",
      "Support continuous improvement by investigating alternatives and technologies and presenting these for architectural review\n",
      "Perform other duties as assigned\n",
      "\n",
      "Minimum Qualifications:\n",
      "\n",
      "4+ years of experience implementing commercial data warehouses and data marts\n",
      "2+ years of experience with cloud data warehouse (BigQuery, Snowflake, Redshift )\n",
      "1+ year of experience in Python\n",
      "Experience working with APIs\n",
      "Hands-on proficiency with SQL, SSIS, and ETL jobs, including stored procedures\n",
      "A track record of shipping quality software\n",
      "A strong desire to learn new technologies\n",
      "A strong belief in automated testing\n",
      "Experience with Agile SDLC\n",
      "Must have access to private, quiet work space with high-speed internet to effectively work remotely\n",
      "\n",
      "Interpersonal Skills & Attributes:\n",
      "\n",
      "Ability to work collaboratively in a multi-location, cross-functional team with a wide range of experience levels\n",
      "Excellent communication skills (verbal and written) necessary to effectively interact with data engineering staff, product owners, and stakeholders\n",
      "Able to manage competing priorities\n",
      "Excellent analytical and problem solving skills\n",
      "Strong attention to detail and problem-solving skills\n",
      "Adaptable and flexible\n",
      "IND 005-009\n",
      "   #zr\n",
      " \n",
      "Hiring InsightsJob activityPosted today\n",
      "Job detailsSalaryFrom $75 an hourJob TypeFull-timeContractQualificationsBachelor's (Required)Full Job Description\n",
      "We are looking for an experienced AWS Big Data Engineer for an immediate opening specializing in creative solutions and strong customer engagement in support of a AWS SaaS and PaaS implementations with primary focus on big data, as well as enterprise data warehouse and data lake environments hosted in AWS. This forward-thinking and cloud-focused big data architect / engineer will be part of a AWS data team, specifically focusing on big data, application hosting solutions based on customer requirements, as well as being able to make recommendations using a balanced mix of technical and business skills.\n",
      "Responsibilities: \n",
      "\n",
      "Lead activities to provide “as a Service” platforms and system integration and implementation as an integral member of the team\n",
      "Review business context for solutions to challenges\n",
      "Support the clients' cloud customers that do not have their own independent technical support functions\n",
      "Elicit, document, and analyze business requirements in alignment with technical requirements to translate these requirements into a feasible and efficient cloud solution\n",
      "Lead cloud deployments of data lake and data warehouse services in AWS\n",
      "Assist with data migration into the AWS data lake and data warehouse services\n",
      "Designing, optimizing, and maintaining relational and non-relational databases including MySQL, MS SQL, Redshift, AWS RDS and other NoSQL databases\n",
      "Designing and building ETL packages, data pipelines and connecting these to BI applications\n",
      "Running production workload on AWS\n",
      "Assist transition from the legacy system which will lead to a legacy system being retired\n",
      "Assist in the development of a proposed to‐be infrastructure consisting of development, testing, staging, and production environments that leverages virtualization and cloud computing\n",
      "Assist in application and service design, implementation, and migration\n",
      "\n",
      "Skills / Qualifications: \n",
      "\n",
      "Bachelor’s degree in computer science or engineering or equivalent work experience\n",
      "AWS Solutions Architect – Associate certification within past five years\n",
      "AWS Certified Data Analytics – Specialty or AWS Certified Big Data – Specialty certifications\n",
      "Solutions architecture experience in an enterprise environment with emphasis on data systems\n",
      "Specific experience designing, executing and supporting AWS data lakes at scale\n",
      "Experience designing, optimizing, and maintaining relational and non-relational databases including MySQL, MS SQL, Redshift, AWS RDS and other NoSQL databases\n",
      "Experience with the design and building of ETL packages, data pipelines and connecting these to BI applications\n",
      "Running production workloads on AWS cloud\n",
      "Workload migration to AWS cloud\n",
      "Knowledge of data movement and data presentation tools such as; Informatica, MS SSIS, AWS Glue, Cognos, Tableau\n",
      "Ability to pass a background check and pass the criteria for a CJIS environment\n",
      "Willingness to research and self-study to keep technical skills relevant in a highly complex environment\n",
      "Ability to multi-task and prioritize deadlines as needed to deliver results\n",
      "Ability to work independently or as part of a team\n",
      "Mentors and coach colleague. Seeks opportunities for continuous improvement\n",
      "Excellent verbal and written communication skills with great attention to detail and accuracy\n",
      "Experience working in an Agile/Scrum environment\n",
      "\n",
      "About Avid Systems\n",
      "Avid Systems is a Washington DC based global managed services provider with a focus on cloud enablement, infrastructure, mobility, virtualization, security, storage and cyber security. Avid Systems combines unparalleled experience, comprehensive capabilities across all industries and business functions. Continuous innovation and rapid transformation have been themes throughout Avid Systems’ history, which the company traces to 2004.\n",
      "At Avid Systems our mission is quite simple: to be the best at what we do, providing our customers with the highest quality business and technology consulting services at the most competitive rates, while maintaining a level of integrity and customer dedication that is rare in the industry. We take great pride in our technical expertise and our ability to apply that expertise to the everyday challenges that face our customers. Our vision is to succeed where others have failed, by closing the gap between today’s technology and the future. Our values and our vision support and enhance our corporate values:\n",
      "\n",
      "We are 100% Customer Focused - We anticipate and meet the needs of our customers with our expertise, efficiency and relentless focus on exceeding their expectations. We are driven by our guiding principle, that the customer’s mission is our commitment.\n",
      "Earned Trust - We earn our customers' trust by delivering excellent performance in an ethical way. Our business decisions are based on traditional values – honesty, trust and integrity.\n",
      "\n",
      "Three Reasons why Avid is a great place to work\n",
      "\n",
      "Employee Focused, we believe that the success of the company starts and ends with the success of our employees.\n",
      "Employee Training, all our employees get training and certification classes on the latest technologies.\n",
      "Employee Benefits, our benefits packages are excellent.\n",
      "\n",
      "Job Types: Full-time, Contract\n",
      "Pay: From $75.00 per hour\n",
      "Benefits:\n",
      "\n",
      "401(k)\n",
      "Health insurance\n",
      "Life insurance\n",
      "Paid time off\n",
      "Professional development assistance\n",
      "Vision insurance\n",
      "\n",
      "Schedule:\n",
      "\n",
      "8 hour shift\n",
      "\n",
      "Ability to commute/relocate:\n",
      "\n",
      "Washington, DC 20001: Reliably commute or planning to relocate before starting work (Required)\n",
      "\n",
      "Application Question(s):\n",
      "\n",
      "Experience designing, executing and supporting AWS data lakes at scale\n",
      "Experience designing, optimizing, and maintaining relational and non-relational databases including MySQL, MS SQL, Redshift, AWS RDS and other NoSQL databases\n",
      "Experience with the design and building of ETL packages, data pipelines and connecting these to BI applications\n",
      "\n",
      "Education:\n",
      "\n",
      "Bachelor's (Required)\n",
      "\n",
      "License/Certification:\n",
      "\n",
      "AWS Solutions Architect - Associate certification (Required)\n",
      "AWS Certified Big Data (Required)\n",
      "\n",
      "Work Location: One location\n",
      "Hiring InsightsHiring 1 candidate for this roleUrgently hiringJob activityPosted 4 days ago\n",
      "Job detailsSalary$126,233 - $164,102 a yearJob TypeFull-timeFull Job Description\n",
      "\n",
      "\n",
      "Duties\n",
      "\n",
      "Direct and/or manage engineering and integration efforts for projects and/or programs.\n",
      "Oversee Projects/Programs that involve flight and ground systems, including design and operational requirements definition, hardware and/or software development, testing, verification, safety, integration, certification and operations.\n",
      "Manage the design, development, integration, test, evaluation, operation, and maintenance of the ground segment and associated hardware and software systems (including simulators).\n",
      "Provide technical leadership in defining a baseline operations approach for all aspects of mission operations, systems objectives and requirements, planning and design, and monitoring integration and testing.\n",
      "Manage multi-disciplinary teams in the design, development, integration, test, evaluation, operation, and long-term maintenance of flight or ground hardware, software, simulators, and associated systems.\n",
      "Integrate and coordinate the efforts of agency personnel with those of contractors in research, development, and engineering.\n",
      "Coordinate and lead the technical activities of senior and other ground system and ground subsystem engineers and interact effectively with project management.\n",
      "Guide and evaluate contractor efforts and assess technical progress in relation to the established schedule and resources allotted. Coordinate with other offices within the project to establish content, cost, schedule, deliverables, and services.\n",
      "Perform as an agency expert in integrating requirements necessary for development and operations of data systems and/or ground data systems.\n",
      "Develop broad resource requirements, policies, procedures, budget, and operational schedules for assigned programs or projects.\n",
      "\n",
      "\n",
      "\n",
      "Requirements\n",
      "Conditions of Employment\n",
      "\n",
      "This position is open to U.S. citizens, nationals or those who owe allegiance to the U.S\n",
      "Position subject to pre-employment background investigation\n",
      "You must meet qualifications requirements by the closing date of this announcement\n",
      "If selected, you will be required to complete a financial disclosure statement\n",
      "This position may require a one year trial period\n",
      "Please see the \"Additional Information\" section for important information about COVID-19 vaccination requirements for federal employees.\n",
      "\n",
      "\n",
      "Qualifications\n",
      "\n",
      "     In addition to the Basic Education Requirement (in the Education section below), to qualify for this position you must meet the requirements below and have one year of specialized experience equivalent to the next lower grade, which has equipped you with the particular competencies needed to successfully perform the duties of the position described above.\n",
      "     \n",
      " To qualify for GS-14, you must have one year of directly related specialized experience equivalent to the GS-13 level \n",
      "     \n",
      "assisting with the development and monitoring of system requirements, hardware/software interfaces, prototype/test bed activities, system configuration, and/or system implementation activities;\n",
      "preparing, reviewing, or providing recommendations for proposed project requirements, expected results, and/or budgetary estimates;\n",
      "leading the implementation of advanced information technologies to include establishing long-range agendas, product and technology evaluations, or trade studies;\n",
      "advising teams on technology advances in ground data systems.\n",
      "Your resume must include a clear and detailed narrative description, in your own words, of how you meet the required specialized experience. Experience statements copied from a position description, vacancy announcement or other reference material constitutes plagiarism and may result in disqualification and losing consideration for the job.\n",
      "     \n",
      "\n",
      "Additional selections may be made for similar positions across NASA within the local commuting area(s) of the location(s) identified in this announcement\n",
      "     . By applying, you agree to have your application shared with interested selecting official(s) within NASA. CTAP/ICTAP will be cleared for any additional selection from this announcement.\n",
      "\n",
      "\n",
      "\n",
      "Education\n",
      "\n",
      "     Basic Education Requirement: You must have successfully completed a bachelor's degree with a major in a) engineering from a college or university that has at least one ABET accredited engineering program or b) Physical Science, Mathematics, Life Science, Computer Science*, or other field of physical science.\n",
      "     \n",
      "\n",
      "Note: A computer science curriculum must include 30 semester hours of course work in any combination of mathematics, statistics and computer science. Of the 30 semester hours, 15 must be in any combination of statistics and mathematics which includes differential and integral calculus.\n",
      "\n",
      " If you did not complete a qualifying bachelor's degree, you may be eligible if you have obtained a graduate degree in an AST qualifying field, as listed above.\n",
      "     \n",
      " Degrees in engineering technology are \n",
      "     not considered qualifying for this position.\n",
      "     \n",
      "\n",
      "Engineering degrees earned within the United States: Engineering degrees earned within the United States must be from a college or university that has at least one ABET accredited engineering program. To find out if a school has at least one ABET accredited program, please visit http://www.abet.org.\n",
      "     \n",
      "\n",
      "Engineering degrees earned outside the United States: Engineering degrees earned outside the United States must be recognized by a Mutual Recognition Agreement (MRA), often known as accords. These are non-governmental agreements among organizations that accredit academic degree programs. MRAs recognize the substantial equivalence of mature accreditation systems and programs accredited by signatory organizations within their jurisdictions. For a listing of Signatories, please visit, https://www.abet.org/global-presence/mutual-recognition-agreements/is-your-program-recognized/.\n",
      "     \n",
      "\n",
      "Science and other related degrees\n",
      "earned within the United States: Science and other related degrees must have been awarded from colleges or universities that are accredited by recognized accrediting organizations. For a list of schools that meet this criteria, go to http://ope.ed.gov/accreditation/.\n",
      "     \n",
      "\n",
      "Science and other related degrees earned outside the United States: If you are using education completed in foreign colleges or universities to meet the qualification requirements, you must show that the education credentials have been evaluated by a private organization that specializes in interpretation of foreign education programs. These education credentials must be deemed equivalent to that gained in an accredited U.S. education program; or full credit has been given for the courses at a U.S. accredited college or university. For further information, visit: https://www2.ed.gov/about/offices/list/ous/international/usnei/us/edlite-visitus-forrecog.html.\n",
      "     \n",
      " All degrees must have been received in the year of, or any year subsequent to the original date of accreditation. \n",
      "    \n",
      "\n",
      "\n",
      "Additional information\n",
      "\n",
      "\n",
      "\n",
      "If you are selected, NASA may request information regarding your vaccination status for the purposes of implementing workplace safety protocols, such as masking, physical distancing, testing, travel, and quarantine.\n",
      "     \n",
      "\n",
      "      Due to COVID-19, NASA is currently in an expanded telework posture. \n",
      "      If selected, you may be expected to temporarily telework, even if your home is located outside the local commuting area. Once employees are permitted to return to the office, you will be expected to report to the duty station listed on this announcement within 30 days. At that time, you may be eligible to request to continue to telework one or more days a pay period depending upon the terms of the agency's telework policy.\n",
      "     \n",
      " Under the NASA Flexibility Act of 2004, individuals appointed under this announcement may be converted to permanent appointment, either non-competitively or through internal agency competitive placement procedures. Conversion is not guaranteed, and is contingent on the employee meeting all legal requirements. For more information, see: nasapeople.nasa.gov/hclwp/term-appointments.htm\n",
      "     \n",
      " Current Federal civilian employees may apply for this position. If selected, a break in service of at least 4 calendar days may be required prior to appointment to this position.\n",
      "     \n",
      " If you have special priority selection rights under the Agency Career Transition Assistance Program (CTAP) or the Interagency Career Transition Assistance Program (ICTAP), you must:\n",
      "     \n",
      "\n",
      "Indicate your eligibility when applying for a position. The questionnaire asks you to identify your ICTAP/CTAP eligibility.\n",
      "Be well qualified for this position to receive consideration. Candidates rated in the 'Best Qualified' category are considered well-qualified. Please see 'How You Will Be Evaluated' for more information.\n",
      "Submit proof that you meet the requirements for CTAP/ICTAP as indicated in 'Required Documents'\n",
      "\n",
      " For additional information about CTAP/ICTAP eligibility, click: https://www.opm.gov/policy-data-oversight/workforce-restructuring/employee-guide-to-career-transition/#ictap.\n",
      "     \n",
      " Reasonable Accommodation Requests: If you believe you have a disability (i.e., physical or mental), covered by the Rehabilitation Act of 1973 as amended and Americans with Disabilities Act 1990 as amended, that would interfere with completing the USA Hire Competency Based Assessments, you will be granted the opportunity to request a reasonable accommodation in your online application. Requests for Reasonable Accommodations for the USA Hire Competency Based Assessments and appropriate supporting documentation for Reasonable Accommodation must be received prior to starting the USA Hire Competency Based Assessments. Decisions on requests for Reasonable Accommodations are made on a case-by-case basis. If you meet the minimum qualifications of the position, after notification of the adjudication of your request, you will receive an email invitation to complete the USA Hire Competency Based Assessments. You must complete all assessments within 48 hours of receiving the URL to access the USA Hire Competency Based Assessments, if you receive the link after the close of the announcement. To determine if you need a Reasonable Accommodation, please review the Procedures for Requesting a Reasonable Accommodation for Online Assessments here: https://help.usastaffing.gov/Apply/index.php?title=Reasonable_Accommodations_for_USA_Hire\n",
      "     \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Benefits\n",
      "\n",
      "A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. \n",
      "\n",
      "Review our benefits \n",
      "\n",
      "Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "How You Will Be Evaluated\n",
      "\n",
      "You will be evaluated for this job based on how well you meet the qualifications above.\n",
      "You will be evaluated for this position based on how well you meet the qualifications and eligibility requirements listed in this vacancy announcement. To determine your qualifications and referral status, we may review your resume and supporting documentation and compare it against your responses to the vacancy questionnaire. Your qualifications will be evaluated based on your application materials (e.g., resume, supporting documents), the responses you provide on the application questionnaire, and the result of the online assessments required for this position.  You will be assessed on the following competencies: \n",
      "\n",
      "Planning and Evaluating\n",
      "Research\n",
      "Technical Competence\n",
      "Computer Systems and Engineering\n",
      "Data Systems and Technology \n",
      "Flight and Ground Data Systems\n",
      "Program/Project Analysis\n",
      "Software Engineering\n",
      "Attention to Detail\n",
      "Decision Making\n",
      "Flexibility \n",
      "Integrity/Honesty\n",
      "Interpersonal Skills\n",
      "Learning \n",
      "Reading\n",
      "Reasoning\n",
      "Self-Management (Achievement)\n",
      "Stress Tolerance\n",
      "Teamwork\n",
      "In order to be considered for this position, you must complete all required steps in the process. In addition to the application and application questionnaire, this position requires an online assessment. The online assessment measures critical general competencies required to perform the job.\n",
      "    \n",
      " Overstating your qualifications and/or experience in your application materials or application questionnaire may result in your removal from consideration. Cheating on the online assessment may also result in your removal from consideration.\n",
      "    \n",
      " NASA considers paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional; philanthropic; religious; spiritual; community, student, social). Volunteer work helps build critical competencies, knowledge, and skills and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience.\n",
      "    \n",
      " Under NASA's category rating process, applicants will be assessed on the position competencies and placed in one of three categories identified and defined below: \n",
      "    \n",
      "Best Qualified Category - Applicants who demonstrate a superior level of all evaluation criteria.\n",
      "Highly Qualified Category - Applicants who demonstrate a satisfactory level of the evaluation criteria.\n",
      "Qualified Category - Applicants who demonstrate the basic qualifications, with general knowledge, skills, and abilities.\n",
      "Names of all qualified candidates in the Best Qualified category will be sent to the hiring official for employment consideration (unless a sufficient number of qualified veterans are found - in which case only those names will be initially certified). Candidates within the Best Qualified category who are eligible for veteran preference will receive selection priority over non-veteran preference eligibles. \n",
      "   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Benefits\n",
      "\n",
      "A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. \n",
      "\n",
      "Review our benefits \n",
      "\n",
      "Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.\n",
      "\n",
      "\n",
      "Required Documents\n",
      "\n",
      "As a new or existing federal employee, you and your family may have access to a range of benefits. Your benefits depend on the type of position you have - whether you're a permanent, part-time, temporary or an intermittent employee. You may be eligible for the following benefits, however, check with your agency to make sure you're eligible under their policies.\n",
      "A complete application package includes a resume, required documents and completion of the vacancy announcement questionnaire. Please see this guidance: What to include in your resume. Your resume should describe your specialized experience and support your answers to the vacancy announcement questionnaire.  The following documents are required: \n",
      "\n",
      " Resume\n",
      " Transcript\n",
      "\n",
      "\n",
      " While a transcript is the preferred proof of qualifying education, you may submit any of the following items: \n",
      "      \n",
      "An unofficial transcript\n",
      "A copy of an official transcript\n",
      "A copy of a degree (i.e. a picture or scan)\n",
      "A list of completed/credited courses that includes, the title, course code, and number of semester, quarter or classroom hours for each course (i.e., BUAD- 101-Introduction to Business, 3 Semester hours)\n",
      "You will lose consideration if you do not submit proof of your education. Documents must fully support the education requirements listed above. Incomplete documents or documents that do not show completion of required degree program or coursework may result in disqualification.\n",
      "      \n",
      " There may be other supporting documents (licenses, certification, veterans preference, etc.), depending on your answers to the questionnaire and job announcement description, that you may have to submit, please verify your application.\n",
      "      \n",
      " If you are a surplus or displaced employee (CTAP and ICTAP), submit proof that you meet the requirements for CTAP/ICTAP. This includes copies of your agency notice, most recent Performance Rating and most recent Notification of Personnel Action (SF-50) noting current position, grade level, and duty location.\n",
      "      \n",
      " If you are a veteran and you are claiming veterans' preference, you must submit a DD214, Certificate of Release from Active Duty, which shows dates of service and discharge under honorable conditions. For more information on veterans' preference and possible other supporting documents that you may have to submit, please visit FedshireVets\n",
      "      \n",
      " Official documents are required at the time of appointment for verification of eligibility and qualifications.\n",
      "      \n",
      " If you are requesting a reasonable accommodation to the USA Hire Competency Based Assessments, submit documentation to support your request, including the Reasonable Accommodation Request Form found here. (https://help.usastaffing.gov/Apply/index.php?title=Reasonable_Accommodations_for_USA_Hire) \n",
      "     \n",
      "\n",
      "How to Apply\n",
      "\n",
      "\n",
      "Please read the entire announcement and all the instructions before you begin an application and have all required information available. We encourage you to provide a complete description of your educational achievements and include both paid and non-paid work in the experience portion of your resume. If you submit a resume that does not contain the required information, you may lose consideration.  To apply for this position, you must complete the initial online application, to include the initial online assessment and submission of the required documentation specified in the Required Documents section below.  The complete application package must be submitted by 11:59 PM (ET) on the closing date of the announcement to receive consideration. The application process is as follows:  1. To begin the application process, click the Apply button. You will need to be logged into your USAJOBS account to apply. If you do not have a USAJOBS account, you will need to create one before beginning the application. 2. Follow the prompts to select your resume and/or other supporting documents to be included with your application package. Answer the questions presented in the application and attach all necessary supporting documentation. During the application process you can review, edit, delete and update your information. We'll automatically save your progress as you go, so you won't lose any changes. Your uploaded documents may take several hours to clear the virus scan process. 3. After acknowledging you have reviewed your application package, complete the 'Include Personal Information' section as you deem appropriate and click to continue with the application process. You will be taken to the vacancy questionnaire which you must complete in order to apply for the position. Complete the online application, verify all required documentation is included with your application package, and submit the application. 4. Click the Submit Application button prior to 11:59PM (ET) on the announcement closing date. 5. After submitting an online application, you will be notified whether or not you are required to take additional online assessments through the USA Hire Competency Based Assessment system. This message will be delivered to you via email notification. The email may be routed to your \"Spam\" or \"Junk\" folder. 6. If you are asked to take the USA Hire Competency Based Assessments, you will be presented with a unique URL to access the USA Hire system. Access to USA Hire is granted through your USAJOBS login credentials. Be sure to review all instructions prior to beginning your USA Hire Assessments. Click here for Computer System Requirements (https://help.usastaffing.gov/Apply/index.php?title=USA_Hire_System_Requirements) 7. Note, set aside at least 3 hours to take these assessments; however, most applicants complete the assessments in less time. If you need to stop the assessments and continue at a later time, you can re-use the URL sent to you via email and also found on the Additional Application Information page that can be located in the application record in your USAJOBS account.  You may update your application documents and some questions related to your personal information at any time during the announcement open period. However, you will not be able to make changes to questions related to assessing the minimum qualifications and competencies (knowledge, skills, abilities and other characteristics) mentioned in the \"How You Will Be Evaluated\" section above. To make an allowed update to your application, return to your USAJOBS account (https://my.usajobs.gov/Account/Login). There you will find a record of your application, the application status, and an option to Update Application. This option will no longer be available once the announcement has closed.  If you have questions about this announcement, you may contact the agency toll free at the phone number located below. Be advised - application materials faxed, emailed, and/or mailed to Goddard Space Flight Center will not be accepted for this announcement.\n",
      "\n",
      "\n",
      "\n",
      "Agency contact information\n",
      "NASA Shared Services Contact Center \n",
      "\n",
      "\n",
      "Phone\n",
      "1-877-677-2123 \n",
      "Fax\n",
      "1-866-779-6772\n",
      "Email\n",
      "nssc-contactcenter@mail.nasa.gov \n",
      "\n",
      "\n",
      "Address\n",
      "\n",
      "\n",
      "Goddard Space Flight Center\n",
      "\n",
      "8800 Greenbelt Rd\n",
      "\n",
      "Greenbelt, MD 20771\n",
      "\n",
      "US \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Next steps\n",
      "\n",
      "Based on your application and your responses to the application questionnaire, you may be presented with instructions on how to access the USA Hire system to complete the online assessments. The online assessments must be completed within 48 hours following the close of this announcement. You will have the opportunity to request a testing accommodation for the assessment should you have a disability covered under the Americans with Disabilities Act (ADA). \n",
      "\n",
      "         The USA Hire assessment platform was recently updated. As a result, if you completed the USA Hire Competency Based Assessment in the last 12 months, you may be invited to complete it again and your previous scores may not be utilized. Once you complete the assessment in the upgraded platform, your assessment responses will be kept on record for one year and used toward future positions for which you might apply that require the same assessments.\n",
      "       \n",
      " Once you submit your application package, you will receive an acknowledgement email and be provided regular status updates through USAJOBS. To verify the status of your application both during and after the announcement open period, log into your USAJOBS account: https://my.usajobs.gov/Account/Login. All of your applications will appear on the Welcome page. The application record in your USAJOBS account provides an Additional Application Information page that provides information regarding the documentation you submitted and any correspondence we have sent related to this application, including the invitation to take the USA Hire assessment. The Application Status will appear along with the date your application was last updated. For information on what each Application Status means, visit: https://www.usajobs.gov/Help/how-to/application/status/.\n",
      "       \n",
      " If you are found qualified, you may be referred to the hiring manager for further consideration. Whether or not you are contacted for an interview depends upon the location of the position and the judgment of the hiring manager. \n",
      "      \n",
      "\n",
      "\n",
      "Fair and Transparent\n",
      "\n",
      "The Federal hiring process is setup to be fair and transparent. Please read the following guidance. \n",
      "\n",
      "Equal Employment Opportunity (EEO) Policy \n",
      "Reasonable accommodation policy \n",
      "Financial suitability \n",
      "Selective Service \n",
      "New employee probationary period \n",
      "Signature and false statements \n",
      "Privacy Act \n",
      "Social security number request \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Required Documents\n",
      "\n",
      "A complete application package includes a resume, required documents and completion of the vacancy announcement questionnaire. Please see this guidance: What to include in your resume. Your resume should describe your specialized experience and support your answers to the vacancy announcement questionnaire.  The following documents are required: \n",
      "\n",
      " Resume\n",
      " Transcript\n",
      "\n",
      "\n",
      " While a transcript is the preferred proof of qualifying education, you may submit any of the following items: \n",
      "    \n",
      "An unofficial transcript\n",
      "A copy of an official transcript\n",
      "A copy of a degree (i.e. a picture or scan)\n",
      "A list of completed/credited courses that includes, the title, course code, and number of semester, quarter or classroom hours for each course (i.e., BUAD- 101-Introduction to Business, 3 Semester hours)\n",
      "You will lose consideration if you do not submit proof of your education. Documents must fully support the education requirements listed above. Incomplete documents or documents that do not show completion of required degree program or coursework may result in disqualification.\n",
      "    \n",
      " There may be other supporting documents (licenses, certification, veterans preference, etc.), depending on your answers to the questionnaire and job announcement description, that you may have to submit, please verify your application.\n",
      "    \n",
      " If you are a surplus or displaced employee (CTAP and ICTAP), submit proof that you meet the requirements for CTAP/ICTAP. This includes copies of your agency notice, most recent Performance Rating and most recent Notification of Personnel Action (SF-50) noting current position, grade level, and duty location.\n",
      "    \n",
      " If you are a veteran and you are claiming veterans' preference, you must submit a DD214, Certificate of Release from Active Duty, which shows dates of service and discharge under honorable conditions. For more information on veterans' preference and possible other supporting documents that you may have to submit, please visit FedshireVets\n",
      "    \n",
      " Official documents are required at the time of appointment for verification of eligibility and qualifications.\n",
      "    \n",
      " If you are requesting a reasonable accommodation to the USA Hire Competency Based Assessments, submit documentation to support your request, including the Reasonable Accommodation Request Form found here. (https://help.usastaffing.gov/Apply/index.php?title=Reasonable_Accommodations_for_USA_Hire)\n",
      "   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  Help \n",
      "  This job is open to\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The public\n",
      "U.S. Citizens, Nationals or those who owe allegiance to the U.S.\n",
      "\n",
      "\n",
      "\n",
      "Hiring InsightsJob activityPosted today\n",
      "Job detailsSalary$66,077 - $164,102 a yearJob TypeFull-timeFull Job Description\n",
      "\n",
      "\n",
      "\n",
      "Data Engineers work with data consumers to create and populate optimal data architectures, structures, and systems to meet CIA’s business needs.\n",
      "\n",
      "\n",
      "\n",
      " Full time\n",
      " Starting salary: $66,077 - $164,102\n",
      " Bachelor's or master's degree \n",
      "Opportunities for domestic travel are possible\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About the Job\n",
      " As a Data Engineer for CIA, you will focus on the design, implementation, and operation of data management systems to meet the CIA’s business needs. This includes designing how the data will be stored, consumed, integrated, and managed by different data entities and digital systems. Data Engineers work together with data consumers to determine, create, and populate optimal data architectures, structures, and systems.\n",
      " Data Engineers must also plan, design, and optimize for data throughput and query performance issues. This requires constantly updating expertise in areas such as platform, network and storage technologies, bandwidth management, data bus implications, and design.\n",
      " Additionally, you will play a key role in the selection of backend database technologies (SQL, NoSQL, HPC, etc.), their configuration and utilization, and the optimization of the full data pipeline infrastructure to support the actual content, volume, ETL, and periodicity of data to support the intended kinds of queries and analysis to match expected responsiveness.\n",
      " Domestic and/or foreign travel may be required.\n",
      " Who You’ll Work With\n",
      " At the Central Intelligence Agency (CIA), we recognize our Nation’s strength comes from the diversity of its people. People from a broad range of backgrounds and viewpoints work at CIA, and our diverse teams are the reason we can keep our country safe.\n",
      " Read more about diversity and inclusion\n",
      " What You’ll Get\n",
      " Our benefits support every aspect of a working professional’s life, including health and wellness, time off, family, finances, and continuing education. Our programs include highly sought-after government health benefits, flexible schedules, sick leave, and childcare. In some cases, we also offer sign-on incentives and cover moving expenses if you relocate.\n",
      " As a CIA employee, you’ll also get the satisfaction of knowing your work is part of something bigger than yourself. Our work is driven by one mission: to keep our Nation safe. Every day is an opportunity to enhance U.S. national security.\n",
      " Learn more about working at CIA\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Minimum Qualifications\n",
      "\n",
      "Bachelor’s or master’s degree in one of the following fields or related studies: \n",
      "          \n",
      "Archives/Digitization Management\n",
      "Computer/Data Science\n",
      "Information/Data/Knowledge Management\n",
      "Information Technology\n",
      "Management Information Systems\n",
      "Mathematics\n",
      "Engineering\n",
      "\n",
      "At least a 3.0 GPA on a 4-point scale\n",
      "Knowledge of the following: \n",
      "          \n",
      "Data manipulation\n",
      "Databases\n",
      "Data structures\n",
      "Data management\n",
      "Best engineering practices\n",
      "\n",
      "Ability to meet the minimum requirements for joining CIA, including U.S. citizenship and a background investigation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Desired Qualifications\n",
      "\n",
      "Work experience related to data engineering, information, and data management\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "What You’ll Need to Apply\n",
      "\n",
      "Resume\n",
      "Unofficial transcripts for all degrees\n",
      "Cover letter in which you specify your qualifications for one or more positions. Please address why you want to work in this role and what differentiates you from other applicants.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hiring InsightsJob activityPosted 30+ days ago\n",
      "Job detailsJob TypeFull-timeFull Job Description\n",
      "\n",
      "\n",
      "\n",
      "    Assume the responsibility to properly operate and correctly maintain all plant and engineering equipment (electrical and mechanical) as assigned, within the Data Center, to ensure continuous availability, and delivery of required engineering services. This position consistently supports compliance and Kaiser Permanente's Code of Conduct by adhering to federal, state and local laws and regulations, accreditation and licenser requirements and Kaiser Permanente's policies and procedures. In addition to defined technical requirements, accountable for consistently demonstrating service behaviors and principles defined by the Kaiser Permanente Service Quality Credo, the KP Mission as well as specific departmental/organizational initiatives. Also accountable for consistently demonstrating the knowledge, skills, abilities, and behaviors necessary to provide superior and culturally sensitive service to each other, to our members, and to purchasers, contracted providers and vendors.\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Essential Responsibilities:\n",
      "\n",
      "\n",
      " Perform hands-on operation and maintenance of all Data Center building engineering-related equipment and systems, which include, but are not limited to: Mechanical (HVAC, chillers, boilers, Computer Room AC Units, pumps, strainers, controls, water treatment, etc.); Electrical (UPS, PDUs, generators, switchgear, etc); Plumbing (condensate, fuel oil, etc.); Building Automation and Control Systems (BAS, BMS, etc.); Fire/Life Safety (alarms, suppression, etc).\n",
      " Operate Building Automation and Control Systems.\n",
      " Operate computer based control and monitoring system, as well as PC based systems for tracking of operations and maintenance activities.\n",
      " Perform all work in accordance with Data Center Engineering Policies and Procedures, with special emphasis on work in designated critical areas, and demonstrate Critical Awareness in all work activities.\n",
      " Carry out routine Data Center Preventive Maintenance as directed on all equipment specified.\n",
      " Perform required Data Center Corrective Maintenance as directed on all equipment specified.\n",
      " Conduct Data Center facility/building rounds as scheduled.\n",
      " Promptly report all equipment/system anomalies noted while in the Data Center.\n",
      " Immediately report any hazardous materials encountered or unsafe work practices observed.\n",
      " Maintain logs, record readings, document equipment histories, and prepare other engineering-related documentation.\n",
      " Store, maintain and use Critical Spare Parts and general-use parts in accordance with prescribed policy.\n",
      " Perform services as directed in Project related work.\n",
      " Provide access/escort service to subcontractors working in engineering areas as required.\n",
      " Use all tools and equipment properly as designed and in a safe manner.\n",
      " Participate in all training programs provided.\n",
      " Actively take part in all emergency drills and scenario exercises as directed.\n",
      " Respond quickly and appropriately to all emergencies occurring in the Data Center.\n",
      " Work independently or with other team members as directed.\n",
      " Report any accidents encountered, either to self or others.\n",
      " Conduct all work in a professional manner and respond courteously to all client requests.\n",
      " Work weekend/evening shifts as required.\n",
      " Write, or assist in writing, documents related to the operation, maintenance and repairs of said equipment and systems. The documentation includes, but is not limited to, Critical Facility Work Authorization (CFWA), Methods of Procedure (MOP), Standard Operating Procedure (SOP), and Emergency Operating Procedure (EOP). \n",
      "\n",
      "\n",
      "\n",
      "Operating Engineers will carry out maintenance/operations tasks as assigned by management and submit accompanying documentation in a timely manner. Documentation includes but is not limited to when work was completed, how long the work took to complete, anomalies encountered, repairs made, parts used, etc. \n",
      "\n",
      "\n",
      "\n",
      "Take all required and mandated training in order to maintain required certifications and licenses per the State of Maryland.\n",
      " Performs other duties, within their field, as assigned by immediate supervisor.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Basic Qualifications:\n",
      "\n",
      "\n",
      " Experience\n",
      "   \n",
      "\n",
      " Minimum eight (8) years of experience in critical, high availability Data Centers and/or Hub Medical Centers required.\n",
      "\n",
      "\n",
      " Education\n",
      "   \n",
      "\n",
      " High School Diploma or equivalent combination of education, training, and experience is required.\n",
      " Demonstrated experience with heating, cooling, plumbing and electrical systems. \n",
      "\n",
      "\n",
      "\n",
      "In-depth knowledge of Life Safety codes on Federal, State and Local levels required. \n",
      "\n",
      "\n",
      "\n",
      "Ability to work independently and in a professional manner.\n",
      "\n",
      "\n",
      " License, Certification, Registration\n",
      "   \n",
      "\n",
      " State of Maryland first class Stationary Engineer license and Universal CFC or equivalent licensing from DC/VA required. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Additional Requirements:\n",
      "\n",
      "\n",
      " Ability to read and interpret blueprints, schematic drawings and technical manuals required.\n",
      " Knowledge of equipment and systems described above including electrical repairs and maintenance required.\n",
      " Attained CFC Certification required.\n",
      " Is current or willing to become member of IUOE required.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Preferred Qualifications:\n",
      "\n",
      "\n",
      " Completion of four-year apprentice program or have journeyman status in electrical/mechanical crafts.\n",
      " Documented and completed course work in electrical systems fundamentals, UPS Systems, generators, chillers systems, building automation and control systems.\n",
      "\n",
      "\n",
      "\n",
      " PrimaryLocation : Maryland,Silver Spring,Silver Spring Data Center\n",
      "   HoursPerWeek : 40\n",
      "   Shift : Night\n",
      "   Workdays : Tue, Wed, Thu, Fri, Sat\n",
      "   WorkingHoursStart : 10:00 PM\n",
      "   WorkingHoursEnd : 06:30 AM\n",
      "   Job Schedule : Full-time\n",
      "   Job Type : Standard\n",
      "   Employee Status : Regular\n",
      "   Employee Group/Union Affiliation : M41|IUOE|Local 99\n",
      "   Job Level : Individual Contributor\n",
      "   Job Category : Facility Services & Materials Management\n",
      "   Department : Silver Spring Data Center - ITO IPS DCO FM SSDC - 1808\n",
      "   Travel : No\n",
      "   Kaiser Permanente is an equal opportunity employer committed to a diverse and inclusive workforce. Applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy), age, sexual orientation, national origin, marital status, parental status, ancestry, disability, gender identity, veteran status, genetic information, other distinguishing characteristics of diversity and inclusion, or any other protected status.\n",
      " \n",
      "Hiring InsightsJob activityPosted 12 days ago\n",
      "Job detailsSalary$90,000 a yearJob TypeFull-timeFull Job Description\n",
      "\n",
      "\n",
      "   Posting Details \n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Position Number:\n",
      "\n",
      "\n",
      "      127092\n",
      "     \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Functional\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Category Status:\n",
      "\n",
      "\n",
      "      33-Exempt Regular\n",
      "     \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Applicant Search Category:\n",
      "\n",
      "\n",
      "      Staff\n",
      "     \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "University Authorized FTE:\n",
      "\n",
      "\n",
      "      1.00\n",
      "     \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Unit:\n",
      "\n",
      "\n",
      "      DIT-ATI-Academic Technology Experience (LTE)\n",
      "     \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Campus/College Information:\n",
      "\n",
      "\n",
      "      Founded in 1856, University of Maryland, College Park is the state’s flagship institution. Our 1,250-acre College Park campus is just minutes away from Washington, D.C., and the nexus of the nation’s legislative, executive, and judicial centers of power. This unique proximity to business and technology leaders, federal departments and agencies, and a myriad of research entities, embassies, think tanks, cultural centers, and non-profit organizations is simply unparalleled. Synergistic opportunities for our faculty and students abound and are virtually limitless in the nation’s capital and surrounding areas. The University is committed to attracting and retaining outstanding and diverse faculty and staff that will enhance our stature of preeminence in our three missions of teaching, scholarship, and full engagement in our community, the state of Maryland, and in the world.\n",
      "     \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Background Checks\n",
      "\n",
      "Offers of employment are contingent on completion of a background check. Information reported by the background check will not automatically disqualify you from employment.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Vaccine Protocol\n",
      "\n",
      "The University of Maryland has made the safety of our students, faculty and staff, and our surrounding communities a top priority. As part of that commitment, the University System of Maryland (USM) recently announced that students, faculty, and staff on USM campuses this fall, including UMD, are required to be vaccinated against COVID. As a prospective and/or a new employee at UMD, you will be required to comply with the University’s vaccination protocol. Proof of full vaccination will be required before the start of employment in order to work at any University of Maryland location. Prospective or new employees may seek a medical or religious exemption to the vaccination requirement at return.umd.edu and must have an approved exemption prior to the start of their employment. Failure to provide proof of vaccination or to obtain approval for a medical or religious exemption will result in the offer of employment being rescinded.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Position Summary/Purpose of Position:\n",
      "\n",
      "\n",
      "      The Division of Information Technology is seeking a qualified Data Engineer to support the Academic Technology Experience team (ATEX), which provides leadership and management of enterprise-wide initiatives related to student, faculty, and staff experiences with technologies. This is a full-time position and will report to the Senior Data Scientist. The ATEX team employs a quantitative, program evaluation-based approach to provide evidence-based insights, guidance, and recommendations concerning the use and efficacy of DIT systems and services. The incumbent will support this work by interfacing closely with the Senior Data Scientist and the Enterprise Data Services team to support the creation and maintenance of data pipelines (database and supporting infrastructure and applications) for data related to academic technology usage overseen by the Division.\n",
      "      \n",
      " The Data Engineer will be responsible for the design, implementation and maintenance of new ETL processes. This includes using cloud-based technologies, establishing best practices and procedures for ETL development, implementing ETL processes, and documentation. The Data Engineer will collaborate with the Enterprise Data Services (EDS) team on a regular basis to ensure that data solutions are aligned with the University’s overall data strategy and security requirements.\n",
      "      \n",
      " The emphasis of this position is the technical hands-on activities for the creation and evolution of new ETL processes to support the Academic Technology Experience (ATEX) group as well as other DIT initiatives and campus clients. The Data Engineer will work closely with the ATEX Senior Data Scientist to understand data needs and develop requirements. Of utmost importance is the ability to select and implement the appropriate ETL or ELT techniques and storing all data as structured files for subsequent usage in a data warehouse or Big Data analysis; prior successful ETL implementations and experience are essential, as is SQL experience. Clear communication, demonstrated organizational skills, and the ability to collaborate with non-technical stakeholders, create clear and concise technical documentation, and make critical decisions are requirements to be successful in this position.\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Minimum Qualifications:\n",
      "\n",
      "\n",
      "Bachelor’s degree from an accredited college or university in computer science, information systems, or related discipline.\n",
      "2-4 years of experience in designing, implementing and maintaining ETL processes. including experience with SQL.\n",
      "Knowledge of data privacy practices and laws;\n",
      "Skill in technical support documentation;\n",
      "Ability to conduct research into database issues, standards and products;\n",
      "Ability to present ideas in user-friendly language;\n",
      "Ability to work collaboratively with technical and non-technical stakeholders;\n",
      "Ability to communicate effectively orally, and in writing;\n",
      "Ability to independently to complete and build on assigned tasks;\n",
      "Comfortable working with occasional minimal guidance and varied job duties;\n",
      "Ability to persuade and lead others to think critically in discussions;\n",
      "Must be self-motivated, energetic, detail oriented and a team player.\n",
      "Willingness and desire to learn \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Preferences:\n",
      "\n",
      "\n",
      "\n",
      "Experience with various ETL platforms, ideally including Informatica.\n",
      "Experience with object-oriented/object function scripting languages (Python, R, Java, Scala), ideally Python\n",
      "Experience with or interest in educational data mining.\n",
      "Experience with Linux.\n",
      "Experience with JSON.\n",
      "Experience with APIs.\n",
      "Experience with Amazon Redshift or other MPP database platforms.\n",
      "Experience using AWS for data applications (e.g., EC2, Lambda, S3, Redshift, RDS, Data Pipeline)\n",
      "Experience with streaming data.\n",
      "Experience with data related Monitoring tools.\n",
      "Experience with Business Intelligence Tools (e.g., Tableau).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        The ideal candidate will have experience working with data from a variety of sources and in a variety of formats.\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Additional Certifications:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Additional Information:\n",
      "\n",
      "\n",
      "\n",
      "       **This position does not provide sponsorship for Visas.\n",
      "       \n",
      " Salary range is in the $90,000s.\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Job Risks\n",
      "\n",
      "\n",
      "      Not Applicable to This Position\n",
      "     \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Physical Demands\n",
      "\n",
      "\n",
      "\n",
      "Exerting up to 10 pounds of force occasionally and/or negligible amount of force frequently or constantly to lift, carry, push, pull or otherwise move objects.\n",
      "Substantial movements (motions) of the wrists, hands, and/or fingers.\n",
      "The worker is required to have close visual acuity to perform an activity such as: preparing and analyzing data and figures; transcribing; viewing a computer terminal; extensive reading.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Posting Date:\n",
      "\n",
      "\n",
      "      02/25/2022\n",
      "     \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Closing Date:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Open Until Filled\n",
      "\n",
      "\n",
      "      Yes\n",
      "     \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Best Consideration Date\n",
      "\n",
      "\n",
      "      03/17/2022\n",
      "     \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Diversity Statement:\n",
      "\n",
      "The University of Maryland, College Park, an equal opportunity/affirmative action employer, complies with all applicable federal and state laws and regulations regarding nondiscrimination and affirmative action; all qualified applicants will receive consideration for employment. The University is committed to a policy of equal opportunity for all persons and does not discriminate on the basis of race, color, religion, sex, national origin, physical or mental disability, protected veteran status, age, gender identity or expression, sexual orientation, creed, marital status, political affiliation, personal appearance, or on the basis of rights secured by the First Amendment, in all aspects of employment, educational programs and activities, and admissions.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hiring InsightsJob activityPosted 17 days ago\n",
      "Job detailsSalary$150,000 - $250,000 a yearJob TypeFull-timeContractQualificationsHigh school or equivalent (Preferred)Computer Networking: 5 years (Preferred)Data center experience: 5 years (Preferred)CCNP (Preferred)CCNA (Preferred)Full Job Description\n",
      "Join a team of highly motivated and talented Engineers focusing on the design and deployment of Cisco Data Center product lines. In this role, you will be focused on consulting with clients on their Cisco ACI goals while working with them to deliver the solution. Knowledge of other Cisco solutions is a plus as our bench supports every Cisco technology.\n",
      "Please do not apply if you do not have ACI implementation experience.\n",
      "Our team provides pre and post sales resources to partners, customers throughout the U.S. with the majority of work being remote.\n",
      "This is contractor position with competitive pay and flexibility of compensation choices based upon your desire for upside.''Contract Length:\n",
      "\n",
      "More than 1 year\n",
      "\n",
      "Contract Renewal:\n",
      "\n",
      "Likely\n",
      "\n",
      "Full Time Opportunity:\n",
      "\n",
      "Yes\n",
      "\n",
      "COVID-19 Precaution(s):\n",
      "\n",
      "Remote interview process\n",
      "Virtual meetings\n",
      "Sanitizing, disinfecting, or cleaning procedures in place\n",
      "\n",
      "This Job Is:\n",
      "\n",
      "A job for which military experienced candidates are encouraged to apply\n",
      "Open to applicants who do not have a high school diploma/GED\n",
      "A job for which all ages, including older job seekers, are encouraged to apply\n",
      "Open to applicants who do not have a college diploma\n",
      "\n",
      "Visa Sponsorship Potentially Available:\n",
      "\n",
      "Yes: H-1B work authorization\n",
      "Yes: Immigrant visa sponsorship (e.g., green card sponsorship)\n",
      "\n",
      "Work Remotely\n",
      "\n",
      "Temporarily due to COVID-19\n",
      "\n",
      "Job Types: Full-time, Contract\n",
      "Pay: $150,000.00 - $250,000.00 per year\n",
      "Schedule:\n",
      "\n",
      "Monday to Friday\n",
      "Night shift\n",
      "Weekend availability\n",
      "\n",
      "Supplemental Pay:\n",
      "\n",
      "Commission pay\n",
      "\n",
      "Education:\n",
      "\n",
      "High school or equivalent (Preferred)\n",
      "\n",
      "Experience:\n",
      "\n",
      "Computer Networking: 5 years (Preferred)\n",
      "Data center experience: 5 years (Preferred)\n",
      "ACI: 2 years (Required)\n",
      "\n",
      "License/Certification:\n",
      "\n",
      "CCNP (Preferred)\n",
      "CCNA (Preferred)\n",
      "\n",
      "Work Location: One location\n",
      "Hiring InsightsHiring 1 candidate for this roleJob activityEmployer reviewed job 13 days agoPosted 29 days ago\n",
      "Job detailsSalary$85,000 - $115,000 a yearJob TypeFull-timeQualificationsUS work authorization (Required)SQL: 4 years (Preferred)Python: 4 years (Preferred)Data warehouse: 4 years (Preferred)Full Job Description\n",
      "Education Data Engineer Job Description\n",
      "About EmpowerK12\n",
      "At EmpowerK12, we believe all students, regardless of race, gender, disability level or socioeconomic status should have equal access to a high-quality education. Our mission is to empower education leaders and teachers with the right information, relevant skills, and proper systems needed to continuously improve their educational institutions. To that end, we provide continuous improvement, strategic data planning, data coaching, dashboarding, and research & evaluation services. As part of our dashboarding work, we have developed a data platform including ETL, a common data warehouse structure, and a comprehensive set of dashboards. We also plan to phase-in predictive analytics. Our team supports over 40 schools across 19 school networks, and we strive to support DC’s broader cross-sector community through citywide research projects such as our work honoring Bold schools.\n",
      "Our Team Culture\n",
      "We are a tight-knit team that prides ourselves in figuring out how to overcome problems in pursuit of solutions for our partners. This includes doing anything it takes to serve our partners’ needs. Our personal interests vary from DIY home renovation, astronomy, and March Madness to reality TV and probability modeling. We have check-ins every day and happy hours where we play codenames, trivia, and games to get to know each other. We are constantly learning new skills and sharing our learning to grow as individuals and as an organization.\n",
      "Position Overview \n",
      "We are a team of full-stack data engineers and analysts who are looking to take our data platform and analyses to the next level. We are at a critical inflection point in our growth as we seek to double in size over the next two years in order to maximize our impact on the lives of students. We need to ensure our data systems are scalable, highly efficient, and create new insights into student success. Our new team member will bring specialized expertise to build out our skills as an organization and develop tools that drive dramatic gains in student growth and achievement. This position will be critical to helping us achieve our technical goals and hence our mission.\n",
      "Commitment to educational equity and EmpowerK12’s mission is important for this role. Direct experience in education is preferred, but we will consider candidates who demonstrate commitment to our mission in other ways as well.\n",
      "The ideal candidate will have experience building efficient, error-proof data pipelines and warehouses. This position will report to EmpowerK12’s managing director and is primarily internal-facing with some client-facing work.\n",
      "Essential Responsibilities\n",
      "\n",
      "Move our data platform from v1.0 to v2.0 by increasing our ETL scalability and developing error-proof pipelines\n",
      "Ensure all the data our partners see in their data warehouses and Power BI dashboards is error free\n",
      "Develop robust, modular data systems using the Microsoft Azure stack\n",
      "Create new methods for educators to efficiently input and modify data during meetings and analyze that data in real time\n",
      "Train our data analysts and specialists on the new tools you create\n",
      "\n",
      "Qualifications\n",
      "\n",
      "Bachelor’s degree required\n",
      "At least 4 years of data engineering experience strongly preferred\n",
      "Meticulous about writing modular, well-commented SQL code\n",
      "Systematic thinker with a strong attention to detail who is skilled at cleaning data, error-handling, and creating error-proof ETL pipelines\n",
      "Understands how to design flexible, robust data models to power interactive visualizations by collaborating with partners to identify critical metrics and user needs\n",
      "Strong communicator who can listen to the needs of teammates and partners as well as explain the systems you build\n",
      "Excited to work in a startup environment where challenges arise daily and where your ideas will take our services to the next level\n",
      "Self-directed, self-starter with a willingness to own high-priority projects and do whatever it takes to meet partner and organizational needs\n",
      "Desire for feedback; commitment to self-development and to improving skills\n",
      "Tenacity & a willingness to ask for help; understands that challenges are a signal to work smarter, collaboratively involve others, and creatively problem solve\n",
      "Effective project manager with ability to drive projects to completion and who is comfortable managing multiple priorities amid ambiguity\n",
      "Collaborative team player who is excited about building strong relationships among diverse communities\n",
      "\n",
      "We value a diversity of backgrounds; we will consider candidates that do not meet the listed education and experience requirements if they can demonstrate the qualifications listed above through alternative career paths.\n",
      "Compensation \n",
      "\n",
      "We offer a generous suite of benefits including PTO, SmartTrip, 401(K), short term-disability, long-term disability, life, health, dental, and vision insurance\n",
      "We anticipate a salary range or $85,000-115,000 commensurate with qualifications, experience, and fit\n",
      "\n",
      "Applying\n",
      "If you wish to apply for this position, please see the full job description and instructions on our website - https://www.empowerk12.org/team#Careers.\n",
      "Work Location:\n",
      "\n",
      "One location\n",
      "\n",
      "Work Remotely\n",
      "\n",
      "Yes\n",
      "\n",
      "Job Type: Full-time\n",
      "Pay: $85,000.00 - $115,000.00 per year\n",
      "Benefits:\n",
      "\n",
      "401(k)\n",
      "401(k) matching\n",
      "Dental insurance\n",
      "Flexible schedule\n",
      "Health insurance\n",
      "Life insurance\n",
      "Paid time off\n",
      "Parental leave\n",
      "Retirement plan\n",
      "Vision insurance\n",
      "\n",
      "Schedule:\n",
      "\n",
      "Monday to Friday\n",
      "\n",
      "COVID-19 considerations:We are following DC government guidelines.\n",
      "Experience:\n",
      "\n",
      "SQL: 4 years (Preferred)\n",
      "Python: 4 years (Preferred)\n",
      "K-12 education (or a related field): 1 year (Preferred)\n",
      "Data warehouse: 4 years (Preferred)\n",
      "\n",
      "Work Location: One location\n",
      "Hiring InsightsHiring 1 candidate for this roleJob activityPosted today\n",
      "Job detailsJob TypeFull-timeIndeed's salary guideNot provided by employer$122K to $155K per year is Indeed's estimated salary for data engineer in Washington, DC.loading surveyFull Job Description\n",
      "\n",
      "This is a full-time, permanent role. Candidates seeking contract-to-contract employment will not be considered.\n",
      "I'm currently partnering with a major news media company that has earned the trust of readers throughout the United states as one of the country's most reliable media sources due to its data-driven reporting. We are currently searching for an experienced Data Engineer. This is a fully-remote opportunity and is open to candidates currently residing and eligible to work in the United States.\n",
      "Responsibilities:\n",
      "\n",
      "Work with large data sets coming from a variety of internal and external sources\n",
      "Clean, transform, and merge data for optimized analysis\n",
      "Create reports and visualizations out of transformed data\n",
      "Architect and engineer robust data pipelines to obtain, manipulate, organize, and load large data sets\n",
      "Architect and deploy robust cloud data warehouses\n",
      "\n",
      "Required Qualifications:\n",
      "\n",
      "Experience working extensively with cloud environments, i.e.: BigQuery, GCP, AWS Redshift, Azure, or Snowflake\n",
      "Experience with both ETL/ELT processes\n",
      "Strong experience with either SQL and/or Python\n",
      "A minimum of 2-4 years of professional experience with the above processes\n",
      "\n",
      "Benefits:\n",
      "\n",
      "Medical, vision, and dental insurance options\n",
      "401k plan\n",
      "Tuition reimbursement\n",
      "Pretax savings plans including FSA, HAS, and Commuter Assistance\n",
      "Employer-paid life insurance and long-term disability\n",
      "Referral bonus\n",
      "Gym and exercise class discounts\n",
      "Adoption assistance\n",
      "Competitive vacation and paid sick leave\n",
      "Parent leave for both primary and secondary caregivers\n",
      "Scholarships for children of employees\n",
      "\n",
      "\n",
      "Hiring InsightsJob activityPosted 26 days ago\n",
      "Job detailsJob TypeFull-timeFull Job Description\n",
      "\n",
      "GEICO is leading the way in application of Machine Learning and AI in the industry. We have a culture of experimentation, rapid iterations and feedbacks, and lean delivery, complimented with strong partnership and collaboration with product, marketing, tech, and data teams. We’re looking for a Data Engineer to help design and build connected Feature Factory, Feature Engineering capabilities on the Cloud, using Machine Learning and data engineering skills.\n",
      "\n",
      " Job Responsibilities:\n",
      "\n",
      " You will work with our data engineering, MLops, and Data Science teams to shape adaptive feature engineering data pipelines, build Machine Learning solutions to construct and test variety of predictive features, build nested, time-series, time-travel features that can be adapted to different targets, design and build Features Factory and Feature Stores, and deploy feature construction pipeline / repository for model deployment, monitoring, and retraining. You will research the application of graph databases and design graph-based solutions for better management of ML features, and for better instantiation of connected features. You will be an important player in the evolution of data and AI in one of the largest insurance carrier.\n",
      "\n",
      " Required Qualifications:\n",
      "\n",
      " 3+ years of experience with Spark, Python, SQL and parsing of semi-structured data\n",
      " Experience developing, optimizing and deploying automated Feature Engineering pipelines\n",
      " Experience organizing, processing, and persisting Big Data at scale\n",
      " Experience with Azure Ecosystem (ADLS, Azure Data Factory, Azure Data Bricks, Azure Storage, CosmosDB), ADO Pipelines\n",
      " Knowledge of Data Warehousing concepts and design\n",
      " Knowledge of Snowflake platform, and DBT\n",
      "\n",
      "\n",
      " Preferred Qualifications:\n",
      "\n",
      " Experience with streaming technologies like Kafka\n",
      " Experience with Scala, Java\n",
      " Knowledge of Model monitoring capability\n",
      " Experience in building event-based / metrics-based alerting\n",
      " Experience with Data exploration, interactive visualization using python packages on a big-date environment\n",
      "\n",
      "\n",
      " To ensure our associates receive the training and support needed to excel and thrive, associates hired for this position are generally required to work at the GEICO building during their orientation period. GEICO follows federal and state guidance and legal requirements regarding measures designed to limit the spread of COVID-19, including masking and social distancing. Measures may vary by GEICO location.\n",
      "\n",
      " At GEICO, we make sure you have the support and resources to leverage and develop your skills, secure your financial future, and take care of your health and well-being. GEICO continually seeks to provide a workplace where everyone can be their authentic self. To help achieve this goal, we support associate-led Employee Resource Groups that foster a true sense of community. Through GEICO’s competitive benefits offerings and various training and development opportunities, we have you covered with our Total Rewards Program* includes:\n",
      "\n",
      "\n",
      " Premier Medical, Dental and Vision Insurance with no waiting period**\n",
      " Paid Vacation, Sick and Parental Leave\n",
      " 401(k) Plan with Profit Sharing\n",
      " Tuition Reimbursement\n",
      " Paid Training and Licensures\n",
      "\n",
      "\n",
      "\n",
      "Benefits may be different by location. Benefit eligibility requirements vary and may include length of service.\n",
      "\n",
      " **Coverage begins with the pay period after hire date. Must enroll in New Hire Benefits within 30 days of the date of hire for coverage to take effect.\n",
      "\n",
      " GEICO is an equal opportunity employer. GEICO conducts drug screens and background checks on applicants who accept employment offers.\n",
      "\n",
      " GEICO is proud to be an equal opportunity employer. We are committed to cultivating an environment where equal employment opportunities are available to all associates and job applicants regardless of race, color, religious creed, national origin, ancestry, age, gender, pregnancy, sexual orientation, gender identity, marital status, familial status, disability or genetic information, in compliance with applicable federal, state and local law. GEICO celebrates diversity and believes it is critical to our success. As such, we are committed to recruit, develop and retain the most talented individuals to join our team.\n",
      "\n",
      " #LI-AM1\n",
      "\n",
      "Hiring InsightsJob activityPosted 30+ days ago\n",
      "Indeed's salary guideNot provided by employer$101K to $128K per year is Indeed's estimated salary for data engineer in Washington, DC.loading surveyData Engineer- Remote is an option\n",
      "\n",
      "We are looking for experienced data engineers to join our team. You will have a critical role in bringing a wide range of external data sets to bear on financial crime analytics. You will be working with structured and unstructured data; account and transactional data; internal and external databases; relational and other architectures. You will architect, design, and implement approaches for bringing second- and first-party data together to address financial compliance, investigative, and enforcement efforts. We are looking for data engineers who are experienced in data architecture and database design, ETL, data provisioning, query design and management of data engineering.\n",
      "\n",
      "Eastport Analytics is a small growing company who values intellectual curiosity, innovation, professionalism and gives space to be creative. Eastport's domain experts, data experts and technologists work directly with clients in the fraud and compliance domain. We get better actionable insights out of existing data and systems and drive innovation across new techniques, upgraded systems, and novel data sets.\n",
      "\n",
      "\n",
      "As a Data Engineer, you will develop, construct, test and maintain data architectures, align data architecture with business requirements, data acquisition, develop data set processes, use programming language and tools, and identify ways to improve data reliability, efficiency and quality.\n",
      "\n",
      "About You\n",
      "Designed solutions for structured and unstructured data\n",
      "Experience delivering in a team Agile environment\n",
      "Proven strength in data modeling, data engineering, data architecture, database design\n",
      "\n",
      "and data provisioning\n",
      "Hands on knowledge of cloud-based data warehouse solutions\n",
      "Experience with scripting languages such as R, Python\n",
      "Hands on experience with cloud architecture and solutions\n",
      "Experience with Microsoft SQL Server and Oracle database systems\n",
      "Experience developing and operating large-scale data structures for business intelligence analytics\n",
      "\n",
      "using: ETL/ELT processes, OLAP technologies, data modelling, SQL\n",
      "Ability to communicate with all audiences about data architectures and implementation\n",
      "You have a Bachelor's degree in quantitative or data intensive field or equivalent related\n",
      "work experience\n",
      "You do not require any type of sponsorship now or in the future. Unfortunately, this is not an option. Must be able to successfully pass a government background investigation and obtain a government public trust clearance.\n",
      "We are flexible and open for remote candidates, and you are flexible to work and collaborate during core business hours Eastern standard time.\n",
      "\n",
      "Preferred experience:\n",
      "\n",
      "Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets\n",
      "Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc.)\n",
      "Experience building /operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets\n",
      "Financial area provisioning\n",
      "Fintech background\n",
      "Financial data interaction\n",
      "Active Public Trust clearance or above\n",
      "We know that sometimes the perfect candidate doesn't exist, and that people can put off applying for a job if they don't meet all of the requirements. If you are excited about working for us and meet most of the requirements we are looking for, please go ahead and apply. We have other work that may be around the corner.\n",
      "\n",
      " Eastport Analytics is an established small thriving DC-based company offering a work-life balanced culture with full benefits and a competitive compensation package. We offer competitive salary with a benefits package including full medical, dental and vision health insurance, life, short and long-term disability, 401k program, paid monthly commuter parking or public transit, flexible spending account, radical flex time and generous leave, quarterly company profit based bonus program, professional development opportunities, employee assistance program, fun in person and remote events, and a work life balance culture.\n",
      "\n",
      "Eastport Analytics is an Equal Opportunity Employer committed to providing equal employment opportunity without regard to an individual's race, color, religion, age, sex (including pregnancy, sex stereotyping, gender identity, gender expression or transgender status), status as a parent, marital status, political affiliation, veteran status, national origin, or physical or mental disability. Employment decisions are made in accordance with a merit system.\n",
      "No third parties please.Hiring InsightsJob activityPosted today\n",
      "Job detailsJob TypeFull-timeIndeed's salary guideNot provided by employer$122K to $155K per year is Indeed's estimated salary for data engineer in Washington, DC.loading surveyFull Job Description\n",
      "\n",
      "This is a full-time, permanent role. Candidates seeking contract-to-contract employment will not be considered.\n",
      "I'm currently partnering with a major news media company that has earned the trust of readers throughout the United states as one of the country's most reliable media sources due to its data-driven reporting. We are currently searching for an experienced Data Engineer. This is a fully-remote opportunity and is open to candidates currently residing and eligible to work in the United States.\n",
      "Responsibilities:\n",
      "\n",
      "Work with large data sets coming from a variety of internal and external sources\n",
      "Clean, transform, and merge data for optimized analysis\n",
      "Create reports and visualizations out of transformed data\n",
      "Architect and engineer robust data pipelines to obtain, manipulate, organize, and load large data sets\n",
      "Architect and deploy robust cloud data warehouses\n",
      "\n",
      "Required Qualifications:\n",
      "\n",
      "Experience working extensively with cloud environments, i.e.: BigQuery, GCP, AWS Redshift, Azure, or Snowflake\n",
      "Experience with both ETL/ELT processes\n",
      "Strong experience with either SQL and/or Python\n",
      "A minimum of 2-4 years of professional experience with the above processes\n",
      "\n",
      "Benefits:\n",
      "\n",
      "Medical, vision, and dental insurance options\n",
      "401k plan\n",
      "Tuition reimbursement\n",
      "Pretax savings plans including FSA, HAS, and Commuter Assistance\n",
      "Employer-paid life insurance and long-term disability\n",
      "Referral bonus\n",
      "Gym and exercise class discounts\n",
      "Adoption assistance\n",
      "Competitive vacation and paid sick leave\n",
      "Parent leave for both primary and secondary caregivers\n",
      "Scholarships for children of employees\n",
      "\n",
      "\n",
      "Hiring InsightsJob activityPosted 26 days ago\n",
      "Job detailsJob TypeFull-timeFull Job Description\n",
      "\n",
      "GEICO is leading the way in application of Machine Learning and AI in the industry. We have a culture of experimentation, rapid iterations and feedbacks, and lean delivery, complimented with strong partnership and collaboration with product, marketing, tech, and data teams. We’re looking for a Data Engineer to help design and build connected Feature Factory, Feature Engineering capabilities on the Cloud, using Machine Learning and data engineering skills.\n",
      "\n",
      " Job Responsibilities:\n",
      "\n",
      " You will work with our data engineering, MLops, and Data Science teams to shape adaptive feature engineering data pipelines, build Machine Learning solutions to construct and test variety of predictive features, build nested, time-series, time-travel features that can be adapted to different targets, design and build Features Factory and Feature Stores, and deploy feature construction pipeline / repository for model deployment, monitoring, and retraining. You will research the application of graph databases and design graph-based solutions for better management of ML features, and for better instantiation of connected features. You will be an important player in the evolution of data and AI in one of the largest insurance carrier.\n",
      "\n",
      " Required Qualifications:\n",
      "\n",
      " 3+ years of experience with Spark, Python, SQL and parsing of semi-structured data\n",
      " Experience developing, optimizing and deploying automated Feature Engineering pipelines\n",
      " Experience organizing, processing, and persisting Big Data at scale\n",
      " Experience with Azure Ecosystem (ADLS, Azure Data Factory, Azure Data Bricks, Azure Storage, CosmosDB), ADO Pipelines\n",
      " Knowledge of Data Warehousing concepts and design\n",
      " Knowledge of Snowflake platform, and DBT\n",
      "\n",
      "\n",
      " Preferred Qualifications:\n",
      "\n",
      " Experience with streaming technologies like Kafka\n",
      " Experience with Scala, Java\n",
      " Knowledge of Model monitoring capability\n",
      " Experience in building event-based / metrics-based alerting\n",
      " Experience with Data exploration, interactive visualization using python packages on a big-date environment\n",
      "\n",
      "\n",
      " To ensure our associates receive the training and support needed to excel and thrive, associates hired for this position are generally required to work at the GEICO building during their orientation period. GEICO follows federal and state guidance and legal requirements regarding measures designed to limit the spread of COVID-19, including masking and social distancing. Measures may vary by GEICO location.\n",
      "\n",
      " At GEICO, we make sure you have the support and resources to leverage and develop your skills, secure your financial future, and take care of your health and well-being. GEICO continually seeks to provide a workplace where everyone can be their authentic self. To help achieve this goal, we support associate-led Employee Resource Groups that foster a true sense of community. Through GEICO’s competitive benefits offerings and various training and development opportunities, we have you covered with our Total Rewards Program* includes:\n",
      "\n",
      "\n",
      " Premier Medical, Dental and Vision Insurance with no waiting period**\n",
      " Paid Vacation, Sick and Parental Leave\n",
      " 401(k) Plan with Profit Sharing\n",
      " Tuition Reimbursement\n",
      " Paid Training and Licensures\n",
      "\n",
      "\n",
      "\n",
      "Benefits may be different by location. Benefit eligibility requirements vary and may include length of service.\n",
      "\n",
      " **Coverage begins with the pay period after hire date. Must enroll in New Hire Benefits within 30 days of the date of hire for coverage to take effect.\n",
      "\n",
      " GEICO is an equal opportunity employer. GEICO conducts drug screens and background checks on applicants who accept employment offers.\n",
      "\n",
      " GEICO is proud to be an equal opportunity employer. We are committed to cultivating an environment where equal employment opportunities are available to all associates and job applicants regardless of race, color, religious creed, national origin, ancestry, age, gender, pregnancy, sexual orientation, gender identity, marital status, familial status, disability or genetic information, in compliance with applicable federal, state and local law. GEICO celebrates diversity and believes it is critical to our success. As such, we are committed to recruit, develop and retain the most talented individuals to join our team.\n",
      "\n",
      " #LI-AM1\n",
      "\n",
      "Hiring InsightsJob activityPosted 30+ days ago\n",
      "Indeed's salary guideNot provided by employer$101K to $128K per year is Indeed's estimated salary for data engineer in Washington, DC.loading surveyData Engineer- Remote is an option\n",
      "\n",
      "We are looking for experienced data engineers to join our team. You will have a critical role in bringing a wide range of external data sets to bear on financial crime analytics. You will be working with structured and unstructured data; account and transactional data; internal and external databases; relational and other architectures. You will architect, design, and implement approaches for bringing second- and first-party data together to address financial compliance, investigative, and enforcement efforts. We are looking for data engineers who are experienced in data architecture and database design, ETL, data provisioning, query design and management of data engineering.\n",
      "\n",
      "Eastport Analytics is a small growing company who values intellectual curiosity, innovation, professionalism and gives space to be creative. Eastport's domain experts, data experts and technologists work directly with clients in the fraud and compliance domain. We get better actionable insights out of existing data and systems and drive innovation across new techniques, upgraded systems, and novel data sets.\n",
      "\n",
      "\n",
      "As a Data Engineer, you will develop, construct, test and maintain data architectures, align data architecture with business requirements, data acquisition, develop data set processes, use programming language and tools, and identify ways to improve data reliability, efficiency and quality.\n",
      "\n",
      "About You\n",
      "Designed solutions for structured and unstructured data\n",
      "Experience delivering in a team Agile environment\n",
      "Proven strength in data modeling, data engineering, data architecture, database design\n",
      "\n",
      "and data provisioning\n",
      "Hands on knowledge of cloud-based data warehouse solutions\n",
      "Experience with scripting languages such as R, Python\n",
      "Hands on experience with cloud architecture and solutions\n",
      "Experience with Microsoft SQL Server and Oracle database systems\n",
      "Experience developing and operating large-scale data structures for business intelligence analytics\n",
      "\n",
      "using: ETL/ELT processes, OLAP technologies, data modelling, SQL\n",
      "Ability to communicate with all audiences about data architectures and implementation\n",
      "You have a Bachelor's degree in quantitative or data intensive field or equivalent related\n",
      "work experience\n",
      "You do not require any type of sponsorship now or in the future. Unfortunately, this is not an option. Must be able to successfully pass a government background investigation and obtain a government public trust clearance.\n",
      "We are flexible and open for remote candidates, and you are flexible to work and collaborate during core business hours Eastern standard time.\n",
      "\n",
      "Preferred experience:\n",
      "\n",
      "Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets\n",
      "Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc.)\n",
      "Experience building /operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets\n",
      "Financial area provisioning\n",
      "Fintech background\n",
      "Financial data interaction\n",
      "Active Public Trust clearance or above\n",
      "We know that sometimes the perfect candidate doesn't exist, and that people can put off applying for a job if they don't meet all of the requirements. If you are excited about working for us and meet most of the requirements we are looking for, please go ahead and apply. We have other work that may be around the corner.\n",
      "\n",
      " Eastport Analytics is an established small thriving DC-based company offering a work-life balanced culture with full benefits and a competitive compensation package. We offer competitive salary with a benefits package including full medical, dental and vision health insurance, life, short and long-term disability, 401k program, paid monthly commuter parking or public transit, flexible spending account, radical flex time and generous leave, quarterly company profit based bonus program, professional development opportunities, employee assistance program, fun in person and remote events, and a work life balance culture.\n",
      "\n",
      "Eastport Analytics is an Equal Opportunity Employer committed to providing equal employment opportunity without regard to an individual's race, color, religion, age, sex (including pregnancy, sex stereotyping, gender identity, gender expression or transgender status), status as a parent, marital status, political affiliation, veteran status, national origin, or physical or mental disability. Employment decisions are made in accordance with a merit system.\n",
      "No third parties please.Hiring InsightsJob activityPosted today\n",
      "Job detailsJob TypeFull-timeIndeed's salary guideNot provided by employer$92K to $117K per year is Indeed's estimated salary for data engineer in Fort Meade, MD 20755.loading surveyFull Job Description\n",
      "\n",
      "  Overview: \n",
      "  \n",
      "    Definitive Logic is currently seeking an experienced \n",
      "   Mid – Level Data Engineer to work in our Fort Meade, MD location 2-3 days and other days will be remote. We are looking for a person who appreciates the opportunity to be independent, creative and challenged. An individual with a curious mind, passionate about solving problems quickly and bringing innovative ideas to the table.\n",
      "   Responsibilities: \n",
      "  \n",
      "    Possesses and applies expertise on multiple complex work assignments. Assignments may be broad in nature, requiring originality and innovation in determining how to accomplish tasks. Operates with appreciable latitude in developing methodology and presenting solutions to problems. Contributes to deliverables and performance metrics where applicable.\n",
      "   Qualifications: \n",
      "  \n",
      " Required Qualifications:\n",
      "\n",
      "\n",
      " Active Interim Secret Clearance or higher Bachelor's Degree Minimum of four (4+) years of relevant data solution experience Background developing solutions for high volume, low latency applications and can operate in a fast paced, highly collaborative environment. Distributed computer understanding and experience with SQL, Spark, leading ETL technologies and approaches. Independent, creative and determined. Strong SQL experience. Experience developing data pipelines using modern Big Data ELT technologies like Nifi or StreamSets. Experience with a modern programming language such as Python or Java. Experience working in a big data and cloud environment.\n",
      "\n",
      "\n",
      " Preferred Qualifications:\n",
      "\n",
      "\n",
      " Minimum Two (2) years of experience working in an agile development environment. Ability to quickly learn technical concepts and communicate with multiple functional groups. Ability to display a positive, can-do attitude. Strong verbal and written communication skills.\n",
      "\n",
      "\n",
      " About Definitive Logic\n",
      "\n",
      "\n",
      "\n",
      " Definitive Logic is a management and technology consulting firm known for delivering outcomes and ROI for agencies’ most complex business challenges.\n",
      "  \n",
      "\n",
      "\n",
      " We are a Small Business based in Arlington, VA which delivers performance-based and outcome-driven technology consulting solutions that directly support the strategic intent of our Defense, Homeland Security, Emergency Management, Federal Civilian and Commercial clients. We’re the preferred technology integration partner for Federal agencies to apply the best of data science, app dev, DevSecOps, cyber and cloud solutions to improve decision support, empower front-line employees and enhance back-office operations. We serve as trusted advisors providing objective, fact-based, vendor & technology-neutral consulting services.\n",
      "  \n",
      "\n",
      "\n",
      " Definitive Logic is ultimately a team of problem solvers — thought leaders, domain experts, coders, data enthusiasts, and technophiles. Our exciting projects and learning and sharing culture has consistently resulted in validation as a Great Place to Work: 2021 Washington Post Top Work Places (7-time winner) | 2021 Virginia Best Places To Work (8 years running, #1 midsize in 2019).\n",
      "  \n",
      "\n",
      "Hiring InsightsJob activityPosted Today\n",
      "Job detailsSalary$90 - $100 an hourJob TypeFull-timeContractFull Job Description\n",
      "\n",
      "CISCO ACI\n",
      "Advanced knowledge and experience of core routing, switching and security design, configuration, and troubleshooting\n",
      "The candidate must be able to articulate the following networking elements:\n",
      "Strong communication skills, attention to detail\n",
      "Ability to demonstrate technical knowledge and consultative skills\n",
      "Ability to perform tasks with no or minor supervision\n",
      "Strong expertise in Cisco Data Center, Routing and Switching Technologies.\n",
      "Expertise in data centers design and implementation based on Cisco Nexus 9K, ACI Leaf & Spine switch fabric.\n",
      "Expert in multi-site ACI Data Center, data center Interconnectivity, Multi-pod and Multi-site design methodology and implementation.\n",
      "Expertise in planning, designing and execution of Legacy Nexus 9K integration and workload migration to ACI platform.\n",
      "Expert level knowledge of ACI IP fabric endpoint classification, categorization, naming and associated policies constructs for various scenarios\n",
      "High availability site and multi-site ACI platform configurations and integration with data center firewalls, Internet Service Provider (ISP) and Business-to-Business (B2B) Extranet, Wireless, Provider Edge (MPLS) and Out-of-Band (OOB) data center network segments.\n",
      "Expertise in designing, implementing APIC, MSO and automating operations and management\n",
      "Expert level knowledge of design considerations based on requirements which may include:\n",
      "Tenant constructs; Application Network Profiles; End Point Groups (EPGs); Contracts (Subjects and Filters); Fabric Access Policies\n",
      "Functional level knowledge of implementing Rest API, Ansible, Python, Curl and other relevant ACI automation tools\n",
      "Solid VMWare Hypervisor knowledge and integration of VMware ESXi, ACI and VMM Integration\n",
      "Experience in configuring, troubleshooting Cisco Nexus 9k, 7K, 5K in NX-OS and ACI deployments.\n",
      "\n",
      "Job Types: Full-time, Contract\n",
      "Pay: $90.00 - $100.00 per hour\n",
      "Schedule:\n",
      "\n",
      "8 hour shift\n",
      "\n",
      "Experience:\n",
      "\n",
      "Networking Engineer: 10 years (Preferred)\n",
      "Cisco ACI: 3 years (Preferred)\n",
      "Cisco Data Center Nexus 5k,7k,and 9k Switches: 5 years (Preferred)\n",
      "\n",
      "Work Location: One location\n",
      "Hiring InsightsApplication response rate: 64%Hiring 2 candidates for this roleUrgently hiringJob activityEmployer reviewed job 5 days agoPosted 5 days ago\n",
      "Indeed's salary guideNot provided by employer$84.8K to $107K per year is Indeed's estimated salary for data engineer in Washington, DC 20001.loading surveyMonumental Sports & Entertainment (MSE), located in Washington, D.C., is one of the largest integrated sports and entertainment companies in the country with one of the most diverse partnership groups in all of sports. MSE owns and operates five professional sports teams: the 2019 WNBA Champion Washington Mystics, the 2018 NHL Stanley Cup Champion Washington Capitals, NBA's Washington Wizards, NBA G League’s Capital City Go-Go, and NBA 2K League’s Wizards District Gaming. The company is also co-owner of aXiomatic, which has controlling interest in global esports franchise Team Liquid, and owns and operates Capital One Arena in DC. MSE also manages MedStar Capitals Iceplex, the state-of-the-art training facility for the Capitals and EagleBank Arena on George Mason University's campus. In conjunction with the District of Columbia and Events DC, MSE is a partner in a new sports and entertainment facility in Southeast DC on the St. Elizabeth’s East campus that opened in September 2018. Facility highlights include MedStar Wizards Performance Center, the brand-new training facility for the Wizards, Go-Go and Mystics, and a 4,200-seat arena which serves as the new home of the Mystics and Go-Go. MSE also co-owns and operates Monumental Sports Network (MSN) with the NBC Sports Group. MSN is the mid-Atlantic region’s top destination for exclusive fan experiences and original sports content across desktop, tablet, mobile and OTT streaming devices. Visit www.monumentalsports.com.\n",
      "MSE proudly promotes its core values for all those that interact with the company. As a member of our team:\n",
      "You will provide first-class customer service and value for our fans.\n",
      "You will champion a double-bottom line that engages, unifies and gives back to the community we serve.\n",
      "You will work tirelessly to build generationally exceptional teams that compete for championships year after year and create lifelong memories for our fans.\n",
      "You will measure performance with specific objectives and metrics and our analysis and decisions are compelled by data.\n",
      "You will prize leadership, but you should value teamwork and collaboration and transparency even more. We treat each other with respect. We act with honesty and integrity. We remain humble.\n",
      "You will innovate. We are nimble and first to market. We are not averse to risk.\n",
      "You will have fun. We are in the business of happiness.\n",
      "Position Overview: The Basketball Data Engineer will work closely with the Research and Strategy teams to maintain, enhance, and extend Monumental Basketball’s data infrastructure. This position is responsible for collecting and redefining data from various sources as well as preparing and distributing data for consumption by the team’s developers and analysts.\n",
      "Are you an experienced data pipeline builder who excels at automating and optimizing data systems, with a strong preference for cloud experience and a passion for basketball? We'd love to hear from you!\n",
      "Responsibilities\n",
      "Build, maintain, and optimize data ETL pipelines.\n",
      "Document, research, and resolve issues with data processes.\n",
      "Manage and design workflows to support data ingestion, analysis, and reporting.\n",
      "Identify, design, and implement internal process improvements.\n",
      "Prepare data sets for processing and research.\n",
      "Other duties as assigned.\n",
      "Minimum Qualifications\n",
      "Bachelor’s degree in Computer Science, Information Systems, or other technical field.\n",
      "1+ years related experience and/or training; or equivalent combination of education and experience.\n",
      "Experience working with and maintaining databases such as Google BigQuery, PostgreSQL, MySQL, Snowflake, or similar.\n",
      "Experience with programming languages such as Python, Java, C#, or other similar scripting language.\n",
      "Hands-on experience with data orchestration platforms such as Airflow, Composer, Prefect, or similar.\n",
      "Understanding of data warehousing and data structures, specifically relational modeling.\n",
      "Understanding of software dependencies, telemetry, network graphs, and similar concepts.\n",
      "Experience working with a variety of data types and sources, specifically JSON, XML, CSV, and unstructured-text data.\n",
      "Experience with source control such as git.\n",
      "Familiarity with advanced statistical basketball concepts.\n",
      "Flexibility to work evenings, weekends, and holidays as needed.\n",
      "All applicants for employment at Monumental Sports are required to be fully vaccinated against COVID-19 prior to commencing employment. Applicants who receive a conditional offer of employment will be required to produce proof of vaccination status prior to their first day of employment. Monumental Sports will evaluate requests for reasonable accommodations for applicants unable to be vaccinated due to a religious belief, disability or pregnancy on an individualized basis in accordance with applicable laws.\n",
      "We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.Hiring InsightsJob activityPosted 13 days ago\n",
      "Job detailsJob TypeFull-timeFull Job Description\n",
      "\n",
      "\n",
      "Who We Are:\n",
      " The Mid-Atlantic Permanente Medical Group, (MAPMG) is one of the nation's premier multispecialty medical groups and is the largest integrated medical group in Maryland, Virginia and the District of Columbia. Founded in 1980, the medical group has more than 1,700 Permanente physicians spanning more than 50 subspecialties. Together, we serve approximately 800,000 Kaiser Permanente members in Maryland, Virginia, and the District of Columbia at 34 area medical centers, plus several community hospitals and skilled nursing facilities.\n",
      " Job Summary:\n",
      " We are seeking a Data Engineer I to join our Finance team at Mid-Atlantic Permanente Medical Group (MAPMG). The Data Engineer I will be responsible for using various programming languages to develop applications and automate processes in service of the analytics teams. The Data Engineer will also act as a technical resource for identifying areas for workflow improvement and replacement of existing systems.\n",
      " Responsibilities:\n",
      "\n",
      " Develop, deploy, and maintain sites and web services within the context of a microservice architecture, using Docker or other contain runtimes\n",
      " Perform REST API calls to a variety of backends to perform automated administration (including access management, data recovery and restoration, and bulk updates) within web tools\n",
      " Enable efficient data storage by designing and developing logical schemas and table structures, deploying and maintaining ad-hoc database systems, and performing database administration\n",
      " Facilitate ETL (extract, transform and load) processes between different systems and database technologies, typically using Python and SQL\n",
      " Develop and design reusable frameworks and libraries in Python that enable other team members to produce new functionality with minimal coding effort and a reduction in complexity\n",
      " Troubleshoot production system failures\n",
      " Clearly and regularly communicate with management and technical support colleagues\n",
      " Perform other duties as required\n",
      "\n",
      " Qualifications:\n",
      "\n",
      " BS/BA required in computer science, engineering, mathematics, statistics, or related field\n",
      " Prior experience in web and software development in Python or similar languages\n",
      " Demonstrated knowledge of web technologies, such as HTML, CSS, and JavaScript\n",
      " Demonstrated experience in end-to-end solution design required\n",
      " Comfortable with working remotely in a CLI-based Linux server environment\n",
      " Ability to communicate complex technical concepts to a non-technical audience\n",
      " Expert in managing data structures, content and interpretation of specific data elements\n",
      " Detail-oriented, naturally curious, and passionate about solving business problems through high-quality solutions\n",
      " Demonstrated flexibility in meeting the needs of a challenging, fast-paced business environment\n",
      " Adaptable and flexible due to varying deadlines and project goals\n",
      " Rapid learner\n",
      " Able to work effectively in complex, political and ambiguous situations\n",
      " Ability to work independently and multi-task effectively\n",
      " Demonstrated understanding of projects from the perspective of both client and business\n",
      " Flexible and willing to accept a change in priorities as necessary\n",
      " Strong attention to detail\n",
      "\n",
      " Competitive Benefits:\n",
      "\n",
      " Competitive compensation package\n",
      " Comprehensive benefits including 100% employer-funded medical and dental insurance premiums for employees and families\n",
      " Great work/life balance\n",
      " Generous paid time off\n",
      " Maternity and parental leave\n",
      " Pension plan and 401(k) retirement plan\n",
      " Life insurance, and short-term disability and long-term disability coverage\n",
      " Education reimbursement\n",
      "\n",
      " Equity, Inclusion, and Diversity:\n",
      " MAPMG continuously works to identify and mitigate healthcare inequities, and that starts with providing an inclusive, supportive environment for our physicians. We encourage applicants of any race, color, religion, sex, sexual orientation, gender identity, or national origin who value diversity and will commit to practicing culturally competent healthcare.\n",
      "\n",
      " We are proud to be an equal opportunity/affirmative action employer.\n",
      " We value our diversity and E/O/E M/F/D/V.\n",
      "\n",
      "\n",
      "Hiring InsightsJob activityPosted 26 days ago\n",
      "Job detailsSalary$110,000 - $120,000 a yearJob TypeFull-timeQualificationsSQL: 4 years (Preferred)Full Job Description\n",
      "JOB TITLE: DATA ENGINEER\n",
      "MUST BE AN US CITIZEN/GREEN CARD\n",
      "LOCATION: ON-SITE\n",
      "BALTIMORE, MARYLAND\n",
      "_ Below are specifics about the position: _\n",
      "\n",
      "Up to $120k annually\n",
      "Full time, non-contract position\n",
      "On site (Columbia, MD)\n",
      "SQL\n",
      "Relocation required if out of local commuting area - no relocation expenses provided\n",
      "Medical, dental, vision offered/employee cost partially subsidized by employer\n",
      "401k with % match\n",
      "10 days/2 weeks PTO (no waiting for accrual)\n",
      "Team environment\n",
      "Commitment to work/life balance\n",
      "-----------------------------------------------------------------------------------\n",
      "POSITION DETAIL:  Baltimore based Healthcare Informatics and Business Intelligence Company is seeking candidates to fulfil the role of Data Engineer. The Data Engineer is responsible for the load, maintenance, improvement, accuracy, and analysis of data in the operational and analytics databases. The Data Engineer works with the source system software engineering team, data analytics team and data scientists to understand and aid in the implementation of database requirements, analyze performance, and troubleshoot any existent issues. The Data Engineer is an expert in SQL development providing support to the Data Analytics team in database design, data flow and analysis activities and plays a key role in the development and deployment of innovative data platforms for advanced analytics and data processing. Works closely with the senior analytics management in ensuring that the data being brought in and managed is accurate, clean, easily available, and complete and assists the business in ensuring that data warehouse processes are running at an optimum capacity at all times. Defines and builds the data pipelines that will enable faster, better, data-informed decision-making within the business.\n",
      "Required Qualifications:  Bachelor’s degree in Computer Science, Applied Mathematics, Engineering, or other technology related field. An equivalent of the same in working experience is also accepted for the position. · Minimum 3 years of working experience as a database engineering support personnel or a database engineering administrator within a fast-paced a complex business setting. Experience working with Microsoft SQL Servers in a business enterprise environment. Demonstrated experience working with large and complex data sets as well as experience analyzing volumes of data through basic Microsoft Excel functions, for example, macros and pivot tables. Experience in the creation and debugging of databases critical to the business’s mission. · Strong working and conceptual knowledge of building and maintaining physical and logical data models and experience with Tableau, Power BI, SSAS, SSRS or other business intelligence tools. · Expertise in system management monitoring, disaster recovery, backup, automated testing, automated schema migration, and continuous deployment as well as data modeling and query performance tuning on SQL Server or similar platforms.\n",
      "*PLEASE NOTE:  Must have exceptional analytical skills, showing fluency in the use of tools such as Python, Shell, Java, PHP, and T-SQL programming skills. She/He must also be technologically adept, demonstrating strong computer skills. The candidate must additionally be capable of developing databases using SSIS packages and T-SQL. · Demonstrated proficiency in the use of MS Word, MS Excel, PowerPoint, and Outlook, all necessary for the creation of both visually and verbally engaging reports and presentations, for senior data engineering management and senior data science leadership. ·\n",
      "Ability to design, build, and maintain the business’s ETL pipeline and data warehouse.\n",
      "Must be result-driven, an analytical and creative thinker, innovative problem solver, be self-motivated and proactive, highly organized, have ability to handle-multiple and simultaneous tasks meeting aggressive deadlines, be a team player, and demonstrate an exceptional ability to stay calm and composed in the face of adversity. Excellent communication skills are required to convey technical messages to supporting personnel and collaborative non-technical departments and personnel, leading to a positive outcome of partnerships and overall improvement in business performance.\n",
      "\n",
      "Job Type: Full-time\n",
      "Pay: $110,000.00 - $120,000.00 per year\n",
      "Benefits:\n",
      "\n",
      "401(k)\n",
      "Health insurance\n",
      "Vision insurance\n",
      "\n",
      "Schedule:\n",
      "\n",
      "8 hour shift\n",
      "Monday to Friday\n",
      "\n",
      "Ability to commute/relocate:\n",
      "\n",
      "Columbia, MD 21044: Reliably commute or planning to relocate before starting work (Preferred)\n",
      "\n",
      "Experience:\n",
      "\n",
      "SQL: 4 years (Preferred)\n",
      "\n",
      "Work Location: One location\n",
      "Hiring InsightsHiring 1 candidate for this roleJob activityEmployer reviewed job 4 days agoPosted 8 days ago\n",
      "Job detailsJob TypeFull-timeIndeed's salary guideNot provided by employer$79.3K to $100K per year is Indeed's estimated salary for software engineer in McLean, VA.loading surveyFull Job Description\n",
      "KLDiscovery, a leading global provider of electronic discovery, information governance and data recovery services, is currently seeking a Software Developer I.Join the Data Storage Technology Engineering Team. The position will assist in review and analysis of applications, product development, and enhancements including documentation, code development, and unit testing of releases while adhering to KLDiscovery development processes and workflows with supervision and direction from lead developers and superiors.Remote, work from home opportunity.Responsibilities\n",
      "\n",
      "Develop, maintain, and update a variety of data recovery desktop applications that need to work with the latest technologies in the market\n",
      "Assist team members with researching existing storage technologies from a hardware and software perspective\n",
      "Develop automated unit tests\n",
      "Develop automated functional and regression tests\n",
      "Support bug fixes and implement enhancements to applications in Production\n",
      "Work with the SQA team on defect resolution\n",
      "Create design and user documentation as needed\n",
      "Utilize, communicate and enforce coding standards\n",
      "Seek and participate in personal development opportunities to maintain a detailed knowledge of industry standards, engineering best practices, and business needs\n",
      "Provide Technical Support - bug fixes and implement enhancements to applications in Production within defined SLA\n",
      "Work in a team or with multiple organizational departments in a dynamic and rapidly changing environment\n",
      "Adhere to development processes and workflows\n",
      "\n",
      "Qualifications\n",
      "\n",
      "BS in Computer Science, Engineering, or related scientific field preferred\n",
      "1-2+ years of related experience preferred\n",
      "Capable of problem identification and resolutions\n",
      "Ability to learn from others and adapt to standards\n",
      "Ability to change projects as needed\n",
      "Ability to express complex technical concepts effectively, both verbally and in writing\n",
      "Understands various programming languages including C/C++, C#, SQL, Python, etc.\n",
      "Ability to work in a team or with multiple organizational departments in a dynamic and rapidly changing environment\n",
      "Ability to pass a background check upon offer\n",
      "\n",
      "This position does not qualify for VISA sponsorship .This position operates under International Traffic in Arms Regulations (ITAR) and therefore, any person hired must demonstrate with verifiable documentation that he/she is either (i) a U.S. Citizen; (ii) ac active Green Card Holder; pr (iii) a \"Protected Person\" as defined by 8 U.S.C. 1324(b)(a)(3).What We Offer\n",
      "\n",
      "A friendly and welcoming team-oriented environment\n",
      "Opportunities for career advancement and growth\n",
      "Business casual dress\n",
      "Medical/Dental/Vision benefits as well as company provided Life Insurance, Short Term and Long-Term Disability\n",
      "Paid Time Off & 401k retirement savings plan with company match\n",
      "\n",
      "Our Cultural ValuesEntrepreneurs at heart, we are a customer first team sharing one goal and one vision. We seek team members who are:\n",
      "\n",
      "Humble - No one is above another; we all work together to meet our clients’ needs and we acknowledge our own weaknesses\n",
      "Hungry - We all are driven internally to be successful and to continually expand our contribution and impact\n",
      "Smart - We use emotional intelligence when working with one another and with clients\n",
      "\n",
      "Our culture shapes our actions, our products, and the relationships we forge with our customers.Who We AreKLDiscovery provides technology-enabled services and software to help law firms, corporations, government agencies and consumers solve complex data challenges. The company, with offices in 40+ locations across 19 countries, is a global leader in delivering best-in-class eDiscovery, information governance and data recovery solutions to support the litigation, regulatory compliance, internal investigation and data recovery and management needs of our clients.Serving clients for over 30 years, KLDiscovery offers data collection and forensic investigation, early case assessment, electronic discovery and data processing, application software and data hosting for web-based document reviews, and managed document review services. In addition, through its global Ontrack Data Recovery business, KLDiscovery delivers world-class data recovery, email extraction and restoration, data destruction and tape management.KLDiscovery has been recognized as one of the fastest growing companies in North America by both Inc. Magazine (Inc. 5000) and Deloitte (Deloitte's Technology Fast 500) and CEO Chris Weiler was recognized as a 2014 Ernst & Young Entrepreneur of the Year™. Additionally, KLDiscovery is a Relativity Certified Partner and maintains ISO/IEC 27001 Certified data centers around the world.KLDiscovery is an Equal Opportunity Employer.\n",
      "Job Type: Full-time\n",
      "Hiring InsightsJob activityPosted 7 days ago\n",
      "Job detailsJob TypeFull-timeFull Job Description\n",
      "\n",
      "1+ years of experience working with Computerized Maintenance Management Systems (CMMS)\n",
      " Current, active US Government Security Clearance of TS/SCI with Polygraph\n",
      "\n",
      "\n",
      "\n",
      "  Job summary\n",
      "   At Amazon, we're working to be the most customer-centric company on earth! Amazon is a place where builders can build. We hire the world's brightest minds and offer them an environment in which they can invent and innovate to improve the experience for our customers. If you'd like to help us build a place where you can find and buy anything online, this is the job for you.\n",
      "  \n",
      " The Data Center Global Engineering Operations organization is looking for an individual with proven and tested leadership skills to help bring to fruition a newly developed Global Continuity Center (GCC). The GCC is responsible for 24X7 monitoring of the data center’s physical infrastructure and will serve as a facilitator for all Large Scale Events (LSEs) and Critical Site Events (CSEs). This role will also serve as a central monitoring location for the facility electrical and mechanical systems. This team will ensure that the customer experience will be optimal and gratifying by way of consistency, reliability and attention to detail.\n",
      "  \n",
      " The ideal candidate will need to have an understanding of data center IT infrastructure and data center facilities infrastructure and how the two entities co-exist. The successful candidate will be responsible for providing assistance and support to the onsite team. The position will help ensure overall availability and reliability to meet or exceed defined service levels. Qualified candidates must also have experience functioning in a large-scale data center and have demonstrated and displayed the ability to think outside of the box. This skill is essential, as the candidate will assist with aligning the GCC with the larger objectives of other business and peer organizations. You will need to play a role with growing the team to a standard of operational excellence.\n",
      "  \n",
      " If you are passionate about the Customer Experience, you think and act globally, and you want to contribute to the operational excellence of Amazon Data Centers, then this may be the challenge you’ve been looking for!\n",
      "  \n",
      " Roles, Responsibilities and Requirements (job description is not meant to be an all-inclusive statement of every duty and responsibility required):\n",
      "  \n",
      "\n",
      "Monitors the global data center Amazon facilities infrastructure platform\n",
      "Serves as a Point of Contact for internal and external teams\n",
      "Assists with the development of communication and escalation protocols designed to improve the team’s performance\n",
      "Contributes to outage post mortem analysis\n",
      "Ensures records are updated in a timely manner\n",
      "Assists with coordination and communication during emergency recovery efforts\n",
      "Assists with the development of tools that will enhance the team’s performance\n",
      "\n",
      " The ability to support a 24X7 environment (This is shift work which may require that you work weekends and holidays).\n",
      "  \n",
      " This position requires that the candidate selected be a US Citizen and must currently possess and maintain an active TS/SCI security clearance with polygraph.\n",
      "  \n",
      " Upon application you will be asked qualifying questions that will be used only in relation to the US Government Security Clearance required for this role.\n",
      "  \n",
      " In compliance with the U.S. government requirement that employees of its contractors, and employees who work on or in connection with U.S government contracts must receive the COVID-19 vaccine, this position may require that the candidate selected be fully vaccinated against COVID-19. A person is considered fully vaccinated by completing the full regimen of the COVID-19 vaccine (two doses for Pfizer or Moderna and one dose for Johnson & Johnson)\n",
      "  \n",
      " Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and we host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.\n",
      " \n",
      " · 3+ years of Electrical or Mechanical Experience . 1+ years of experience working with Building and/or Electrical Platform Management Systems · 3+ Years’ Experience in Data Center Engineering/ Operations · 3+ years’ experience working in a large-scale data center · 3+ years’ experience in a NOC (Network Operations Center) · Professional traits that are not unique to this position, but necessary for success at Amazon: Strong verbal and written communication skills . Strong Microsoft Office skills (Word, Excel, Access) · Ability to communicate with senior leaders · Ability to maintain SLAs through the implementation of proactive issue detection and reporting tools · Ability to follow and complete support procedures, system documentation, and issue tracking entries · Strong customer focus approach and perspective · Exhibit excellent judgment · High standards - never satisfied with the status quo · Able to dive deep and never be out of touch with the details of the business or the technology · Strive for innovation and simplification · Strong results orientation and able to think big · A strong desire to work in a dynamic environment · Root cause analysis and complex problem solving skills · Able to translate business requirements into technical specifications · Have a personal emphasis toward highly available and scalable global solutions · Self-starter · Shows good judgment and instincts in decision making · Ability to prioritize in a complex environment Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.\n",
      "Hiring InsightsJob activityPosted Today\n",
      "The Challenge:\n",
      "Do you want to work at the forefront of advanced technology and solve complex data challenges? You know that data yields pivotal insights when it’s gathered from disparate sources and organized. As a data engineer, you have the chance to develop and deploy the pipelines and platforms that make this data meaningful. What’s more, you’ll have the chance to grow Booz Allen’s DataOps capabilities while working with a multi-disciplinary team of analysts, data engineers, data scientists, developers, and data consumers in a fast-paced, agile environment. We’re looking for someone like you to ensure our clients meet their mission by improving operations or detecting anomalous customer activity.\n",
      "This is an opportunity to support data engineering activities on some of the most mission-driven projects in the industry. You’ll have the chance to architect data systems, stand up data platforms, build-out ETL pipelines, write custom code, interface with data stores, perform data ingestion, and build data models. From performing analytical exploration and examination of data to leading the assessment, design, building, and maintenance of scalable platforms, you’ll guide your clients to solve their most pressing challenges. This position is open to remote delivery anywhere within the U.S., to include the District of Columbia.\n",
      "Ready to drive innovation using cutting-edge data tools and techniques?\n",
      "Join us. The world can’t wait.\n",
      "You Have:\n",
      "3+ years of experience in data engineering, data science, or software development roles\n",
      "Experience with operationalizing data and advanced analytics solutions\n",
      "Experience with databases, including Postgres or Oracle\n",
      "Experience with building and operationalizing data pipelines, including ETL or ELT\n",
      "Experience in building data and analytics solutions\n",
      "Experience with programming in languages commonly used in engineering outside of databases, including R or Python\n",
      "Ability to obtain a security clearance\n",
      "Bachelor's degree\n",
      "Nice If You Have:\n",
      "Experience with SQL\n",
      "Knowledge of machine learning tools, techniques, and processes\n",
      "Knowledge of Agile and Scrum processes\n",
      "Possession of excellent verbal and written communication skills\n",
      "Clearance:\n",
      "Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.\n",
      "Compensation:\n",
      "The proposed salary range for this position in Colorado is 90,000 to 120,000. Final salary will be determined based on various factors.\n",
      "At Booz Allen, we celebrate your contributions, provide you with opportunities and choice, and support your total well-being. Our comprehensive benefit offerings include healthcare, retirement plan, insurance programs, commuter program, employee assistance program, paid and unpaid leave programs, education assistance, and childcare benefits.\n",
      "Build Your Career:\n",
      "At Booz Allen, we know the power of analytics and we’re dedicated to helping you grow as a data analysis professional. When you join Booz Allen, you’ll have the chance to:\n",
      "access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk\n",
      "change the world with the Data Science Bowl—the world’s premier data science for social good competition\n",
      "participate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government\n",
      "You’ll have access to a wealth of training resources through our Analytics University, an online learning portal specifically geared towards data science and analytics skills, where you can access more than 5000 functional and technical courses, certifications, and books. Build your technical skills through hands-on training on the latest tools and state-of-the-art tech from our in-house experts. Pursuing certifications that directly impact your role? You may be able to take advantage of our tuition assistance, on-site bootcamps, certification training, academic programs, vendor relationships, and a network of professionals who can give you helpful tips. We’ll help you develop the career you want as you chart your own course for success.\n",
      "We’re an EOE that empowers our people—no matter their race, color, religion, sex, gender identity, sexual orientation, national origin, disability, veteran status, or other protected characteristic—to fearlessly drive change.Hiring InsightsJob activityPosted 11 days ago\n",
      "Job detailsSalary$65,000 - $129,000 a yearJob TypeFull-timeContractQualificationsUS work authorization (Required)Secret (Required)Full Job Description\n",
      "Software Engineer II – Data Engineer\n",
      "Arlington, VA\n",
      "Raytheon BBN is one of Raytheon’s premier research and development centers. Our diverse research portfolio combines the best technologies to deliver imaginative, custom solutions with real-world beneﬁt. Located in Arlington, VA, our Information Exploitation group is seeking a Scientist with software research interests. Our world- class team works with a broad range of Government agencies to resolve problems that are both technically challenging and have a real operational impact.\n",
      "What will you doThe ideal candidate will be energized by the opportunity to push the envelope of the state of the art working in a team at the intersections of advanced research in data analytics and engineering of mission-critical applications. At Raytheon BBN, problem solving and refining approaches to hard problems is key, as is involvement in business development activities.\n",
      "Applicants will work in a dynamic multi-disciplinary environment with engineers from a variety of other backgrounds and professional experience. The ideal candidate will have solid experience in software engineering using Java or Python with some experience or interest in machine reasoning, semantic web technologies, data analytics, or artiﬁcial intelligence technologies. Our research work applies the above technologies to develop both prototype and real operational systems. You will be working on challenging problems including:\n",
      "\n",
      "Developing mission-critical applications for deployment into global enterprise operations\n",
      "Optimizing software for high performance knowledge representation, reasoning, and predictive analytics\n",
      "Designing novel machine reasoning and learning algorithms and solutions to complex, open-ended intelligence problems.\n",
      "Working with senior technical staff to grow our business with both current and new customers\n",
      "\n",
      "What will you need\n",
      "\n",
      "BS in Computer Science or equivalent discipline and 2 years of paid experience; MS degree and 0 years of experience\n",
      "Proﬁciency in software development using Java and/or Python and their respective ecosystems\n",
      "Practical experience with DevOps, CI/CD, Gitlab, Docker, Kubernetes\n",
      "Excellent communications skills and the ability to work both independently and in a team\n",
      "Ability to obtain and maintain DoD Top Secret security clearance\n",
      "\n",
      "Highly Desired Skills\n",
      "\n",
      "2 years of related research experience in one of the technical areas mentioned above\n",
      "Practical experience with modern software conﬁguration management tools such as Git, Gradle, Ivy, etc.\n",
      "Experience with REST and web application development\n",
      "Experience in application areas such as command and control, military planning, space systems or DoD logistics is highly desired\n",
      "Experience with DevSecOps, and work in secure environments\n",
      "Active TS/SCI highly desired\n",
      "\n",
      "Why usRaytheon BBN is proud to offer a comprehensive total compensation package including a competitive 401k company match, a Retirement Contribution plan, performance based incentive, and competitive benefits package. In addition to protecting your and your family’s health and well-being, we also offer important financial and family friendly benefits to meet your needs.\n",
      "Our Work/Life benefits include – Paid Parental Leave – Adoption Assistance – Auto and Home Insurance – Child/Elder Back Up Care – College Coach – Retirement Planning Services – Flexible Work Arrangements - Legal Services – LifeResources – Employee Discount Program – Educational Assistance – Transportation Benefits – and Wellness Reward.\n",
      "U.S. Citizenship status is required as this position requires eligibility for U.S. Security Clearance\n",
      "Relocation Available - Yes\n",
      "Raytheon Technologies is An Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age or any other federally protected class.\n",
      "Job Types: Full-time, Contract\n",
      "Pay: $65,000.00 - $129,000.00 per year\n",
      "Benefits:\n",
      "\n",
      "401(k)\n",
      "401(k) matching\n",
      "Dental insurance\n",
      "Employee assistance program\n",
      "Employee discount\n",
      "Flexible schedule\n",
      "Flexible spending account\n",
      "Health insurance\n",
      "Health savings account\n",
      "Life insurance\n",
      "Paid time off\n",
      "Parental leave\n",
      "Professional development assistance\n",
      "Referral program\n",
      "Relocation assistance\n",
      "Retirement plan\n",
      "Tuition reimbursement\n",
      "Vision insurance\n",
      "\n",
      "Schedule:\n",
      "\n",
      "8 hour shift\n",
      "\n",
      "Application Question(s):\n",
      "\n",
      "What is your email address?\n",
      "\n",
      "Security clearance:\n",
      "\n",
      "Secret (Required)\n",
      "\n",
      "Work Location: One location\n",
      "Hiring InsightsHiring 1 candidate for this roleJob activityEmployer reviewed job 9 days agoPosted 10 days ago\n",
      "Job detailsSalary$90,000 - $100,000 a yearJob TypeFull-timePart-timeContractQualificationsInformatica: 1 year (Preferred)SQL: 1 year (Preferred)Data warehouse: 1 year (Preferred)US work authorization (Preferred)Full Job Description\n",
      "Data Engineer\n",
      "Reports to Manager, Data EngineeringVisa type: GC,Citizen\n",
      "SUMMARY:\n",
      "We are looking for an experienced Data Engineer to join our team. You will use various methods to transform raw data into useful data systems. You’ll strive for efficiency by aligning data systems with business goals. To succeed in this position, the Data Engineer must have strong analytical skills and the ability to combine data from different sources. If you are detail-oriented, with excellent organizational skills and experience in this field, we’d like to hear from you!\n",
      "Specific duties include but are not limited to the following essential job functions:\n",
      "ESSENTIAL JOB FUNCTIONS:\n",
      "To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. This position will work closely with all Bright MLS business groups and customers. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.\n",
      "· Identify and resolve data quality issues in data sets\n",
      "· Assemble large, complex data sets that meet functional / non-functional business requirements\n",
      "· Identify, design and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability\n",
      "· Build the infrastructure required for optimal extraction, transformation and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies\n",
      "· Create new ETLs in AWS Glue with Python or Node.Js as the scripting language\n",
      "· Create AWS Lambdas using Python or Node.Js as the scripting language\n",
      "· Modify existing ETLs to fix issues where approach is appropriate\n",
      "· Use Glue for ETLs inside of AWS to and from all AWS types of data sources\n",
      "· Support the migration of data into S3, Redshift, DynamoDB, AWS RDS\n",
      "· Advanced knowledge for Microsoft SQL Server for future migration to an AWS Database Platform\n",
      "· Use Spark via AWS EMR for Big Data scale data preprocessing and support Data Scientists with Feature Engineering\n",
      "· Use Terraform for their AWS components\n",
      "EQUIRED SKILLS/EDUCATION/EXPERIENCE:\n",
      "· 5+ years of experience in a Data Engineer role\n",
      "· 5+ years’ ETL experience\n",
      "· AWS Glue ETL experience\n",
      "· Experience using: Python, Spark, AWS S3, AWS Lambda, Microsoft SQL Server\n",
      "· Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases\n",
      "· Experience building and optimizing ‘big data’ pipelines, architectures and data sets\n",
      "· Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement\n",
      "· A successful history of manipulating, processing and extracting value from large disconnected datasets\n",
      "· Preferred Experience:\n",
      "· Previous experience with data quality projects and public records\n",
      "· Previous experience with: AWS DynamoDB, AWS Elastic Map Reduce, AWS Lambda, AWS Step Functions, AWS Redshift, AWS RDS, Terraform or CloudFormation\n",
      "· AWS Certification is a plus\n",
      "· Document Storage in S3 buckets is a plus\n",
      "Job Types: Full-time, Part-time, Contract\n",
      "Salary: $90,000.00 - $100,000.00 per year\n",
      "Schedule:\n",
      "\n",
      "8 hour shift\n",
      "\n",
      "Ability to commute/relocate:\n",
      "\n",
      "Washington, DC 30668: Reliably commute or planning to relocate before starting work (Required)\n",
      "\n",
      "Application Question(s):\n",
      "\n",
      "What is your Visa Type?\n",
      "\n",
      "Experience:\n",
      "\n",
      "Informatica: 1 year (Preferred)\n",
      "SQL: 1 year (Preferred)\n",
      "Data warehouse: 1 year (Preferred)\n",
      "\n",
      "Work Location: One location\n",
      "Hiring InsightsApplication response rate: 60%Hiring 5 candidates for this roleUrgently hiringJob activityEmployer reviewed job 13 days agoPosted 24 days ago\n",
      "Job detailsJob TypeFull-timeFull Job Description\n",
      "\n",
      "Degree in Computer Science, Engineering, Mathematics, or a related field or 3+ years industry experience.\n",
      "3+ years of experience with demonstrated strength in ETL/ELT, data modeling, data warehouse technical architecture.\n",
      "Expert-level skills in writing and optimizing SQL.\n",
      "3+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data sets.\n",
      "2+ years of experience in scripting languages like etc.\n",
      "Experience with Big Data technologies such as Hive/Spark, AWS EMR, AWS Glue, AWS Lambda , Kinesis, Redshift.\n",
      "Experience leading and influencing the data strategy of your team or organization\n",
      " Job summary \n",
      " Are you looking for a challenge? Imagine being part of a team that owns one of the largest supply chain simulation systems in the world to predict inventory flows for the millions of items available on Amazon.com worldwide. Inventory planning involves many algorithms to buy inventory in the right quantities, at the right frequencies, from the right vendors, and assigning to the best warehouse to fulfill customer demand to optimize long term free cash flow for Amazon. Our system lives at the heart of these algorithms, keeping up with the rapid pace of optimization improvements and simulating how they interact with each other. We simulate what these systems will do for months into the future, predicting inventory flows and key operational and financial metrics across the network. This experimentation platform is critical in understanding labor needs, managing our network capacity, and allowing continued optimizations to the many algorithms we simulate. Imagine enabling Amazon's supply chain systems to make data driven decisions based on simulations of trillions of inventory events per day. \n",
      " \n",
      " Every time an Amazon customer makes a purchase, a number of systems are involved: these systems help optimize inventory acquisition, enable a number of purchase options, ensure great pricing, store products so they are available for fast delivery, and minimize package frustration. The Supply Chain Optimization Technology (SCOT) Group develops and manages these systems. We are central to Amazon customers' ability to find what they want and get it when they want it. Within SCOT, the SimEx (Simulation and Experimentation) team is responsible for designing and executing the simulations and experiments that measure the impact of SCOT initiatives, as well as predicting inventory flows for labor planning. \n",
      " \n",
      " The SimEx team is looking for an experienced, self-driven, analytical, and thoughtful Data Engineer. You will design and support systems that generate multi-billion dollar predictions of the highest level of visibility and importance to the highest business leaders in SCOT. In this role, you will be working in one of the world's largest and most complex data warehouse environments. You should be passionate about working with large, complex datasets and be someone who loves to bring data together in a scalable manner to answer business questions and extract meaningful business insights through collaboration with Business Intelligence Engineers (BIEs), Software Development Engineers (SDEs), and Data Scientists. You will have ownership of end-to-end development of data engineering solutions to complex questions and you’ll play an integral role in strategic decision-making. \n",
      " \n",
      " As a Data Engineer in the SimEx team, you will work with AWS technologies such as Redshift, EC2, S3, EMR, Hive, Kinesis, SNS/SQS, and you will enable the team to leverage dashboarding tools for self-service analytics and science platforms for data science. \n",
      " \n",
      "\n",
      "\n",
      "Master’s or Bachelor degree in Computer Science, Engineering, or related field\n",
      "Industry experience as a Data Engineer or related speciality (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.\n",
      "Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets\n",
      "Experience building data products incrementally and integrating and managing datasets from multiple sources\n",
      "Experience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, etc.\n",
      "Knowledge of Engineering and Operational Excellence using standard methodologies.\n",
      "Ability to work on a diverse team or with a diverse range of coworkers\n",
      " Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.\n",
      "Hiring InsightsJob activityPosted 13 days ago\n",
      "Job detailsJob TypeFull-timeIndeed's salary guideNot provided by employer$99.4K to $126K per year is Indeed's estimated salary for data engineer in Washington, DC.loading surveyFull Job Description\n",
      "\n",
      "Who We Are \n",
      "International Justice Mission (IJM) is the global leader in protecting vulnerable people from violence around the world. Our global team of over 1,200 professionals are at work in 33 offices. Together, we are catalyzing a global revolution that will rescue millions, protect half a billion, and make justice unstoppable. \n",
      "Motivated by God’s call to seek justice for the oppressed, we believe that the way we work is as important as the results we achieve. We are a global community that cares for one another. We value joy and celebration, and we strive to provide professional excellence to all those we serve. \n",
      "\n",
      "The Need \n",
      "After almost 25 years of continued growth and operational success in pioneering the work of protecting those who are experiencing poverty from violence, IJM has become a $100+ million organization. As IJM continues this trajectory of growth and scaling of its impact, with the Vision to protect 500 million people by the year 2030, IJM’s Data Science & Systems team is adding a Data Engineer to help design and build the infrastructure that powers the innovative reporting and advanced analytics that inform how IJM approaches fundraising, marketing, digital communications, and supporter engagement. The Data Engineer will bring expertise that will allow the North America Regional team to build a secure and scalable modern data stack that makes it possible for business stakeholders to analyze, build models, and to deliver insights on donor and supporter data. \n",
      "\n",
      "This position is based at IJM Headquarters in the Washington, DC area or may be remote (in the US) and reports to the Sr. Manager, Data Science & Systems, North America . \n",
      "\n",
      "Responsibilities \n",
      "\n",
      "Recommend modernizations to North America’s data stack, including data pipelines, warehousing, transformation layers, and reporting/Business Intelligence tools; \n",
      "Test, develop, and implement optimized, integrated data sets that support omnichannel analysis and donor-centric relationship management; \n",
      "Accountable for recommending tools and resources to promote self-service reporting by business stakeholders; \n",
      "Maintain data quality standards and deploying and monitoring proactive data hygiene activities; \n",
      "Work with cross-functional teams of fundraisers, digital marketers, analysts, and technology leads where necessary to create and implement solutions (including both North America and IJM Global); and \n",
      "Lead ongoing discovery conversations with business stakeholders to understand their emerging needs and to collaboratively ideate on data analytics-supported solutions. \n",
      "\n",
      "\n",
      "Requirements: \n",
      "\n",
      "Knowledgeable about software engineering best practices including systems design, testing, and documentation in addition to data engineering skills, such as data pipelines, workflow orchestrators, data modeling, and streaming data; \n",
      "Substantial experience with databases and database query languages (e.g., Redshift, SQL); \n",
      "Experience with using a modern scripting language (e.g., Python) for problems such as job orchestration, scraping, data wrangling, etc.; \n",
      "Experience working with remote teams, including across cultures, is preferred; \n",
      "Knowledge of latest trends and technologies in data infrastructure and data warehousing Knowledge of common software engineering best practices (e.g., interacting with file system, using version control); \n",
      "Knowledge of CRM technologies (e.g., Salesforce), web analytics tools (e.g., Google Analytics), and business intelligence and reporting tools (e.g., Tableau) required; \n",
      "Ability to extract, transform and load data from various data sources; \n",
      "Training in data hygiene and data analytics & data quality techniques; \n",
      "Familiarity with data visualization best practices, non-profit finance requirements, US and Canada data privacy/nonprofit regulations and prospect development ethics. \n",
      "\n",
      "\n",
      "Critical Qualities: \n",
      "\n",
      "Mature orthodox Christian faith as defined by the Apostles’ Creed; \n",
      "Self-starter with strong initiative; \n",
      "Disciplined with priorities; \n",
      "Strong interpersonal skills and self-awareness; \n",
      "Exceptional verbal and written communication; \n",
      "Flexible, collaborative and eager to support others; \n",
      "Effective team player who fosters collaborative environment; and \n",
      "Adept at creative problem solving. \n",
      "\n",
      "\n",
      "\n",
      "What does IJM have to offer? \n",
      " - Comprehensive Medical/Dental/Vision benefits \n",
      "   \n",
      "\n",
      "Monthly commuter and parking benefits \n",
      "Generous 6% retirement contribution \n",
      "Paid leave starting at 23 days \n",
      "11 holidays (plus early release the day prior) \n",
      "Relocation reimbursement \n",
      "Daily, quarterly and annual community spiritual formation \n",
      "Robust staff care resources \n",
      "\n",
      "\n",
      "\n",
      "Upload Resume, Cover Letter & Statement of Faith* in one document. \n",
      "\n",
      "*What is a statement of faith?  A statement of faith should describe your Christian faith and how you see it as relevant to your involvement with IJM. The statement can either be incorporated into the cover letter or submitted as a separate document and should include, at a minimum, a description of your spiritual disciplines (prayer, study, etc.) and your current fellowship or place of worship.\n",
      "\n",
      "\n",
      "Hiring InsightsJob activityPosted 21 days ago\n",
      "Job detailsJob TypeFull-timeIndeed's salary guideNot provided by employer$99.4K to $126K per year is Indeed's estimated salary for data engineer in Washington, DC.loading surveyFull Job Description\n",
      "\n",
      "Who We Are \n",
      "International Justice Mission (IJM) is the global leader in protecting vulnerable people from violence around the world. Our global team of over 1,200 professionals are at work in 33 offices. Together, we are catalyzing a global revolution that will rescue millions, protect half a billion, and make justice unstoppable. \n",
      "Motivated by God’s call to seek justice for the oppressed, we believe that the way we work is as important as the results we achieve. We are a global community that cares for one another. We value joy and celebration, and we strive to provide professional excellence to all those we serve. \n",
      "\n",
      "The Need \n",
      "After almost 25 years of continued growth and operational success in pioneering the work of protecting those who are experiencing poverty from violence, IJM has become a $100+ million organization. As IJM continues this trajectory of growth and scaling of its impact, with the Vision to protect 500 million people by the year 2030, IJM’s Data Science & Systems team is adding a Data Engineer to help design and build the infrastructure that powers the innovative reporting and advanced analytics that inform how IJM approaches fundraising, marketing, digital communications, and supporter engagement. The Data Engineer will bring expertise that will allow the North America Regional team to build a secure and scalable modern data stack that makes it possible for business stakeholders to analyze, build models, and to deliver insights on donor and supporter data. \n",
      "\n",
      "This position is based at IJM Headquarters in the Washington, DC area or may be remote (in the US) and reports to the Sr. Manager, Data Science & Systems, North America . \n",
      "\n",
      "Responsibilities \n",
      "\n",
      "Recommend modernizations to North America’s data stack, including data pipelines, warehousing, transformation layers, and reporting/Business Intelligence tools; \n",
      "Test, develop, and implement optimized, integrated data sets that support omnichannel analysis and donor-centric relationship management; \n",
      "Accountable for recommending tools and resources to promote self-service reporting by business stakeholders; \n",
      "Maintain data quality standards and deploying and monitoring proactive data hygiene activities; \n",
      "Work with cross-functional teams of fundraisers, digital marketers, analysts, and technology leads where necessary to create and implement solutions (including both North America and IJM Global); and \n",
      "Lead ongoing discovery conversations with business stakeholders to understand their emerging needs and to collaboratively ideate on data analytics-supported solutions. \n",
      "\n",
      "\n",
      "Requirements: \n",
      "\n",
      "Knowledgeable about software engineering best practices including systems design, testing, and documentation in addition to data engineering skills, such as data pipelines, workflow orchestrators, data modeling, and streaming data; \n",
      "Substantial experience with databases and database query languages (e.g., Redshift, SQL); \n",
      "Experience with using a modern scripting language (e.g., Python) for problems such as job orchestration, scraping, data wrangling, etc.; \n",
      "Experience working with remote teams, including across cultures, is preferred; \n",
      "Knowledge of latest trends and technologies in data infrastructure and data warehousing Knowledge of common software engineering best practices (e.g., interacting with file system, using version control); \n",
      "Knowledge of CRM technologies (e.g., Salesforce), web analytics tools (e.g., Google Analytics), and business intelligence and reporting tools (e.g., Tableau) required; \n",
      "Ability to extract, transform and load data from various data sources; \n",
      "Training in data hygiene and data analytics & data quality techniques; \n",
      "Familiarity with data visualization best practices, non-profit finance requirements, US and Canada data privacy/nonprofit regulations and prospect development ethics. \n",
      "\n",
      "\n",
      "Critical Qualities: \n",
      "\n",
      "Mature orthodox Christian faith as defined by the Apostles’ Creed; \n",
      "Self-starter with strong initiative; \n",
      "Disciplined with priorities; \n",
      "Strong interpersonal skills and self-awareness; \n",
      "Exceptional verbal and written communication; \n",
      "Flexible, collaborative and eager to support others; \n",
      "Effective team player who fosters collaborative environment; and \n",
      "Adept at creative problem solving. \n",
      "\n",
      "\n",
      "\n",
      "What does IJM have to offer? \n",
      " - Comprehensive Medical/Dental/Vision benefits \n",
      "   \n",
      "\n",
      "Monthly commuter and parking benefits \n",
      "Generous 6% retirement contribution \n",
      "Paid leave starting at 23 days \n",
      "11 holidays (plus early release the day prior) \n",
      "Relocation reimbursement \n",
      "Daily, quarterly and annual community spiritual formation \n",
      "Robust staff care resources \n",
      "\n",
      "\n",
      "\n",
      "Upload Resume, Cover Letter & Statement of Faith* in one document. \n",
      "\n",
      "*What is a statement of faith?  A statement of faith should describe your Christian faith and how you see it as relevant to your involvement with IJM. The statement can either be incorporated into the cover letter or submitted as a separate document and should include, at a minimum, a description of your spiritual disciplines (prayer, study, etc.) and your current fellowship or place of worship.\n",
      "\n",
      "\n",
      "Hiring InsightsJob activityPosted 21 days ago\n",
      "Job detailsSalary$140,000 - $200,000 a yearFull Job Description\n",
      "\n",
      "\n",
      "Who is Recruiting from Scratch:\n",
      " Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. If you are a fit, the team will reach out to you about this role or any others that may be a fit for our clients. \n",
      "\n",
      "\n",
      "\n",
      "About Our Client \n",
      "\n",
      "\n",
      "\n",
      "     Our client's vision is a hyper-connected world achieved through implementing 5G in a format that is accessible, consumable, and intuitive. As a leading innovator, they are the creator of the industry’s first 5G Base-Station-on-a-Chip. Led by seasoned executives who have delivered industry-transforming technologies (4G/5G, WiFi, Wimax, Artificial Intelligence, Cloud Servers) for the last few decades, our client is inventing a new paradigm within the wireless infrastructure industry. \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      As an engineer of the Platform Software team, you will help build a dynamic platform for the next generation 5G SoC. You will be in a fast paced environment and challenged creatively as you interact with internal and external customers. Must be able to own, implement and optimize Linux kernel device drivers, RTOS firmware and Linux application stacks. \n",
      "     \n",
      "\n",
      "\n",
      "\n",
      "Role Responsibilities \n",
      "\n",
      "\n",
      "Identifying bottlenecks in networking and communication protocols \n",
      "Developed DPDK PMD and DPDK fast path \n",
      "Putting together DPDK on an ARMv8 embedded system \n",
      "Troubleshooting and optimizing data path \n",
      "Architect the next generation 5G base station on a chip’s data path \n",
      "\n",
      "\n",
      "\n",
      "Job Requirements \n",
      "\n",
      "\n",
      "Strong programming experience in c/c++ \n",
      "In-depth knowledge in packet forward path in layer 2 and layer 3 \n",
      "Hands on experience with DPDK fastpath \n",
      "5G RAN architecture knowledge preferred but not required \n",
      "Have good knowledge and experience working in Linux environment \n",
      "10 years experience with DPDK preferred \n",
      "\n",
      "\n",
      "Benefits: Competitive PTO, Health Benefits, and More!\n",
      " Base Salary Range: $140,000 to $200,000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hiring InsightsJob activityPosted 30+ days ago\n",
      "Job detailsJob TypeFull-timeIndeed's salary guideNot provided by employer$111K to $141K per year is Indeed's estimated salary for data engineer in Rockville, MD.loading surveyFull Job Description\n",
      "\n",
      "Our client, one of the largest Amazon Web Services (AWS) partners for data services, is looking for a Mid level Big Data Engineer to contribute to join their team of technologists to build and contribute to large-scale, innovative projects. Technological and career growth opportunities are a natural and every day part of the working environment.\n",
      "\n",
      "This role is only available for W2 or individual contracts. Please no C2C. \n",
      "100% Remote Work.\n",
      "\n",
      "\n",
      " Responsibilities:\n",
      "\n",
      " Analyze system requirements and design responsive algorithms and solutions.\n",
      " Use big data and cloud technologies to produce production quality code.\n",
      " Engage in performance tuning and scalability engineering.\n",
      " Work with team, peers and management to identify objectives and set priorities.\n",
      " Perform related SDLC engineering activities like sprint planning and estimation.\n",
      " Work effectively in small agile teams.\n",
      " Provide creative solutions to problems.\n",
      " Identify opportunities for improvement and execute.\n",
      "\n",
      "\n",
      " Requirements:\n",
      "\n",
      " Minimum 3 years of proven professional experience working in the IT industry.\n",
      " Degree in Computer Science or related domains.\n",
      " Experience with cloud based Big Data technologies.\n",
      " Experience with big data technologies like Hadoop, Spark and Hive.\n",
      " AWS experience is a big plus.\n",
      " Proficiency in Hive / Spark SQL / SQL. Experience with Spark.\n",
      " Experience with one or more programming languages like Scala & Python & Java.\n",
      " Ability to push the frontier of technology and independently pursue better alternatives.\n",
      " Kubernetes or AWS EKS experience will be a plus.\n",
      "\n",
      "\n",
      " Thanks for applying!\n",
      "\n",
      "Hiring InsightsJob activityPosted 3 days ago\n",
      "Job detailsJob TypeFull-timeFull Job Description\n",
      "\n",
      "\n",
      "   Sony AI America, a branch of Sony AI, is a remotely distributed organization spread across the U.S. and Canada. Sony AI is Sony’s new research organization pursuing the mission to use AI to unleash human creativity. Sony AI works closely with Sony’s other business units, including Sony Interactive Entertainment LLC., Sony Pictures Entertainment Inc., and Sony Music Entertainment. With some 900 million Sony devices in hands and homes worldwide today, a vast array of Sony movies, television shows and music, and the PlayStation Network, Sony creates and delivers more entertainment experiences to more people than anyone else on earth. To learn more: \n",
      "   \n",
      "    https://ai.sony/\n",
      "   \n",
      "\n",
      "\n",
      "    Sony AI is seeking highly motivated, self-driven individuals with expertise in data engineering and interest in AI ethics. Sony has many real-world AI applications in entertainment and electronics, and we are looking for smart, enthusiastic people who want to research, develop, and deploy fair, transparent, and accountable technology for computer vision and real-world applications in various business areas.\n",
      "  \n",
      "\n",
      "\n",
      "    Roles and Responsibilities\n",
      "  \n",
      "\n",
      " Develop and maintain data pipeline infrastructure for data storage, management, and processing, particularly of image datasets.\n",
      " Identify and automate manual processes.\n",
      " Build data analytics tools.\n",
      " Ensure high standards of data privacy and information security.\n",
      " Work closely with a team of AI researchers and programmers in the US, Switzerland, and Japan on ambitious AI ethics projects.\n",
      "\n",
      "\n",
      "\n",
      "    Required Qualifications and Skills\n",
      "  \n",
      "\n",
      " Master’s in Computer Science, Statistics, Information Systems, or related field (or equivalent experience).\n",
      " 5+ years of experience in a data engineering role.\n",
      " Experience developing and optimizing data pipelines from the ground up.\n",
      " Experience working with image data.\n",
      " Experience addressing privacy and information security concerns with data storage and processing.\n",
      " Experience working with different business stakeholders, such as researchers, engineers, lawyers, and compliance officers.\n",
      " Excellent written and oral communication skills, as well as interpersonal skills, including the ability to articulate technical concepts to both technical and non-technical audiences.\n",
      " Scripting experience in at least one language (Bash, Python, etc)\n",
      " Experience working with various cloud services (AWS, GCP or similar)\n",
      " Experience with container technologies (Kubernetes, Docker, Minikube, Helm, Tilt, etc)\n",
      "\n",
      "\n",
      "\n",
      "    Other Required Knowledge\n",
      "  \n",
      "\n",
      " The ability to deliver on tight deadlines and adapt to evolving or changing requirements\n",
      " Excellent verbal and written communication skills in English\n",
      "\n",
      "\n",
      "\n",
      "    Preferable major\n",
      "  \n",
      "\n",
      "    Computer Science, Statistics, Information Systems\n",
      "  \n",
      "\n",
      "\n",
      "    Working Location\n",
      "  \n",
      "\n",
      "    United States (location flexible) or Tokyo, Japan\n",
      "  \n",
      "\n",
      "\n",
      "    #LI-AS1\n",
      "  \n",
      "\n",
      "    Sony is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religious creed, sex (including pregnancy), gender, national origin, citizenship, ancestry, age, physical or mental disability, military status, status as a veteran or disabled veteran, sexual orientation, gender identity or expression, marital or family status, genetic information, medical condition, or any other basis protected by applicable federal, state, or local law, ordinance, or regulation.\n",
      "  \n",
      "\n",
      "\n",
      "    Disability Accommodation for Applicants to Sony Corporation of America Sony Corporation of America provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in job application procedures. For reasonable accommodation requests, please contact us by email at \n",
      "   \n",
      "    careers@sonyusa.com\n",
      "    or by mail to: Sony Corporation of America, Human Resources Department, 25 Madison Avenue, New York, NY 10010. Please indicate the position you are applying for.\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Supplement\n",
      "                                       \n",
      "\n",
      "\n",
      "\n",
      " As part of our commitment to health and safety, this position requires that the job candidate be fully vaccinated against COVID-19. Please note that an applicant will be considered fully vaccinated two weeks after their second dose in a 2-dose vaccine series (Pfizer or Moderna), or two weeks after a single-dose vaccine (Johnson & Johnson’s Janssen vaccine). The Company will consider requests for reasonable accommodations for documented medical reasons and for sincerely held religious beliefs in accordance with applicable law. Please do not include proof of vaccine status or any indication of a possible request for an accommodation when submitting your application materials. If applicable, the Company will follow up with you directly to request proof of vaccination and to discuss any potential accommodations.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hiring InsightsJob activityPosted 18 days ago\n",
      "Job detailsJob TypeFull-timeFull Job Description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ARLINGTON, VA | FRAYM | DATA SCIENCE | FULL TIME\n",
      " About Fraym: \n",
      "\n",
      "\n",
      "\n",
      "          Our company has pioneered the use of geospatial data to understand population dynamics. Governments and organizations around the world rely on Fraym data to make strategic and operational decisions while tackling challenges like inequity and insecurity, climate vulnerability, public health, and more. Our advanced AI/ML models are the first to generate high-resolution insights about human characteristics and behaviors at the sub-neighborhood level and make them commercially available at scale.\n",
      "         \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Summary of Position\n",
      "\n",
      "\n",
      "Fraym is seeking a mid-level data engineer to build out our data pipelines and enable data science workflows at scale. Your contributions will support decisions made in emerging markets across commercial, international development, and intelligence sectors.\n",
      " You will lead a project team responsible for implementing Fraym’s data engineering pipelines and will play a critical role in scaling our existing solutions. You will be responsible for creating new data pipelines, improving existing pipelines, and transitioning these technologies to the cloud. Additionally, you will help identify and brainstorm solutions for gaps in our data management architecture which will manage our geospatial (raster and vector) and survey data. Preference will be given to applicants who are looking to specialize in data engineering.\n",
      " You should have experience in and a passion for data engineering and building cloud-based data pipelines and applications. We are looking for someone who can think of and implement creative solutions to managing diverse and unstructured data. Our team comes from a variety of backgrounds and is committed to improving access and representation in tech - we are looking for colleagues who share this sentiment and will help promote diversity, equity, and inclusion both internally and externally.\n",
      "\n",
      "\n",
      "\n",
      "Your responsibilities will include, but are not limited to, the following:\n",
      "\n",
      "\n",
      "Designing ETL pipelines that ensure the quality, consistency, and availability of data used in machine learning workflows\n",
      "Contributing to the design and implementation of AWS-based data management systems that integrate household surveys, satellite imagery, and other spatial data\n",
      "Working with data scientists to create tools that simplify internal analysis and data discovery within our data lake\n",
      "Project-managing data engineering projects and products\n",
      "Collaborating with business development and client-facing teams to expand data delivery options\n",
      "Collaborating with software engineers to deploy pipelines to the cloud\n",
      "Mentoring other data scientists and engineers on the Data Science team\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "You will have the following qualifications and skills:\n",
      "\n",
      "Interest in or passionate about Fraym’s mission\n",
      "Commitment to Diversity, Equity, and Inclusion\n",
      "At least 2 years of data engineering; preference will be given to applicants with practical experience building and maintaining cloud-based data processing pipelines\n",
      "Essential skills: Experience with databases, Object-Oriented Programming in Python, engineering best practices (testing, deployment management, containerization)\n",
      "Experience or ability to collaborate within a distributed team and communicate effectively with colleagues of different technical backgrounds\n",
      "Ability to quickly develop skills, learn new tools, and solve problems independently\n",
      "Bonus Points For: Experience working with raster or survey data, common AWS services, scoping tools for a tech stack, SQL/Postgres databases, columnar storage, automation and orchestration tools, and/or RESTful APIs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "         Not sure you tick all the boxes? We encourage you to apply. We have a culture of learning, and if this job description sounds exciting, we’d love to hear from you.\n",
      "        \n",
      "\n",
      "\n",
      "         Interested? Please submit your application with a resume and short statement answering “Why Fraym.”\n",
      "        \n",
      "\n",
      "\n",
      "         Fraym offers a competitive salary commensurate with experience and a full benefits package.\n",
      "        \n",
      "\n",
      "\n",
      "         Fraym recruits, employs, trains, compensates, and promotes regardless of race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, family status, veteran status, and other protected status as required by applicable law.\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hiring InsightsJob activityPosted 30+ days ago\n",
      "Job detailsJob TypeFull-timeFull Job Description\n",
      "\n",
      "  Overview: \n",
      "  \n",
      "    Guidehouse is a leading global provider of consulting services to the public sector and commercial markets, with broad capabilities in management, technology, and risk consulting. By combining our public and private sector expertise, we help clients address their most complex challenges and navigate significant regulatory pressures focusing on transformational change, business resiliency, and technology-driven innovation. Across a range of advisory, consulting, outsourcing, and digital services, we create scalable, innovative solutions that help our clients outwit complexity and position them for future growth and success. The company has more than 12,000 professionals in over 50 locations globally. Guidehouse is a Veritas Capital portfolio company, led by seasoned professionals with proven and diverse expertise in traditional and emerging technologies, markets, and agenda-setting issues driving national and global economies. For more information, please visit www.guidehouse.com.\n",
      "   Responsibilities: \n",
      "   Data System Engineer will support complex client environment and team of experienced operation engineers, data analysts, and developers. The Systems Engineer will be responsible for administering and maintaining operating systems and applications and tools used by the data analysts and development teams; ensuring systems are available for the teams and end users; supporting data administration as required. The Systems Engineer will bring hands-on experience with administering, maintaining, monitoring, and upgrading relevant environment; creating and maintaining system documentation including servers, networks, maintenance schedules, system health, and performance; and ensuring program SLA's are adhered to. Qualifications: \n",
      "   The following skills/experience/knowledge are REQUIRED to be considered for this role:\n",
      "\n",
      " Bachelor’s degree and 3-5 years of experience minimum required or equivalent experience working with relevant technology stack.\n",
      " Experience with server and network architecture\n",
      " Strong experience administering Red Hat Enterprise Linux (RHEL)\n",
      " Experience with Windows Server administration\n",
      " Experience supporting Apache Zeppelin, Spark, R and CRAN or equivalent tools\n",
      " Supporting Python, PYPI, and Perl\n",
      " Significant understanding of Data Engineering & Analytics \n",
      "Experience with tools such as Docker, Jenkins, Maven\n",
      " Maintain proper system controls and quality standards\n",
      " Meet with team and stakeholders reviewing system environment planning and status updates\n",
      " Ability to obtain Public Trust\n",
      " US Citizen\n",
      "\n",
      "\n",
      " The following skills/experience/knowledge are PREFERRED to be considered for this role:\n",
      "\n",
      " Experience supporting team designing, coding, testing, debugging, data architecture support.\n",
      " Familiarity with IBM Integrated Analytics Systems - Sailfish, InfoSphere, Informatica\n",
      " Has experience using JIRA or an equivalent agile project management tool (i.e. Pivotal Tracker, VersionOne) \n",
      "Reviewing and analyzing complex programming specifications to resolve issues.\n",
      " Analyzing and troubleshooting skills independently.\n",
      " Root cause analysis of system issues and creation of recovery plans.\n",
      " Remediation of security and performance related issues as they arise.\n",
      " Proactively plan and perform routine maintenance, performance updates, and overall system availability and stability\n",
      " Exposure to CI/CD tools such as Jenkins, Maven, Docker\n",
      " Database Administration (DBA) skills to support team\n",
      " Additional Requirements: \n",
      "  \n",
      "    The successful candidate must not be subject to employment restrictions from a former employer (such as a non-compete) that would prevent the candidate from performing the job responsibilities as described.\n",
      "  \n",
      "\n",
      " Disclaimer: \n",
      "   About Guidehouse\n",
      " Guidehouse is an Equal Employment Opportunity / Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, national origin, ancestry, citizenship status, military status, protected veteran status, religion, creed, physical or mental disability, medical condition, marital status, sex, sexual orientation, gender, gender identity or expression, age, genetic information, or any other basis protected by law, ordinance, or regulation.\n",
      "\n",
      " Guidehouse will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of applicable law or ordinance including the Fair Chance Ordinance of Los Angeles and San Francisco.\n",
      "\n",
      " If you have visited our website for information about employment opportunities, or to apply for a position, and you require an accommodation, please contact Guidehouse Recruiting at 1-571-633-1711 or via email at RecruitingAccommodation@guidehouse.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodation.\n",
      "\n",
      " Guidehouse does not accept unsolicited resumes through or from search firms or staffing agencies. All unsolicited resumes will be considered the property of Guidehouse and Guidehouse will not be obligated to pay a placement fee.\n",
      "\n",
      " Rewards and Benefits\n",
      " Guidehouse offers a comprehensive, total rewards package that includes competitive compensation and a flexible benefits package that reflects our commitment to creating a diverse and supportive workplace.\n",
      "\n",
      " Benefits include:\n",
      "\n",
      " Medical, Rx, Dental & Vision Insurance\n",
      " Personal and Family Sick Time & Company Paid Holidays\n",
      " Position may be eligible for a discretionary variable incentive bonus\n",
      " Parental Leave and Adoption Assistance\n",
      " 401(k) Retirement Plan\n",
      " Basic Life & Supplemental Life\n",
      " Health Savings Account, Dental/Vision & Dependent Care Flexible Spending Accounts\n",
      " Short-Term & Long-Term Disability\n",
      " Tuition Reimbursement, Personal Development & Learning Opportunities\n",
      " Skills Development & Certifications\n",
      " Employee Referral Program\n",
      " Corporate Sponsored Events & Community Outreach\n",
      " Emergency Back-Up Childcare Program\n",
      "\n",
      "\n",
      "Hiring InsightsJob activityPosted Today\n",
      "Job detailsSalaryUp to $90 an hourJob TypeFull-timeContractQualificationsUS work authorization (Required)Bachelor's (Preferred)CCIE (Preferred)Full Job Description\n",
      "Advanced knowledge and experience of core routing, switching and security design, configuration, and troubleshooting\n",
      "The candidate must be able to articulate the following networking elements:\n",
      "Strong communication skills, attention to detailAbility to demonstrate technical knowledge and consultative skillsAbility to perform tasks with no or minor supervisionStrong expertise in Cisco Data Center, Routing and Switching Technologies.Expertise in data centers design and implementation based on Cisco Nexus 9K, ACI Leaf & Spine switch fabric.Expert in multi-site ACI Data Center, data center Interconnectivity, Multi-pod and Multi-site design methodology and implementation.Expertise in planning, designing and execution of Legacy Nexus 9K integration and workload migration to ACI platform.Expert level knowledge of ACI IP fabric endpoint classification, categorization, naming and associated policies constructs for various scenariosHigh availability site and multi-site ACI platform configurations and integration with data center firewalls, Internet Service Provider (ISP) and Business-to-Business (B2B) Extranet, Wireless, Provider Edge (MPLS) and Out-of-Band (OOB) data center network segments.Expertise in designing, implementing APIC, MSO and automating operations and managementExpert level knowledge of design considerations based on requirements which may include:Tenant constructs; Application Network Profiles; End Point Groups (EPGs); Contracts (Subjects and Filters); Fabric Access PoliciesFunctional level knowledge of implementing Rest API, Ansible, Python, Curl and other relevant ACI automation toolsSolid VMWare Hypervisor knowledge and integration of VMware ESXi, ACI and VMM IntegrationExperience in configuring, troubleshooting Cisco Nexus 9k, 7K, 5K in NX-OS and ACI deployments.\n",
      "Responsibilities:1. Formulates and defines systems scope and objectives based on both user needs and a thorough understanding of business systems and industry requirements.2. Devises or modifies procedures to solve complex problems considering computer equipment capacity and limitations, operation time, and form of desired results. Includes analysis of business and user needs, documentation of requirements, and translation into proper system requirements specifications.3. Provides consultation on complex projects and is considered to be the top level contributor/specialist of most phases of systems analysis, while considering the business implications of the application of technology to the current and future business environment.\n",
      "Minimum Education/Certification Requirements :Bachelor’s degree in Information Technology or related field or equivalent experience; or a current Project ManagementCCIE or CCDP Data Center Certification\n",
      "Bachelor’s degree in IT or related field or equivalent experience\n",
      "Job Types: Full-time, Contract\n",
      "Pay: Up to $90.00 per hour\n",
      "Benefits:\n",
      "\n",
      "401(k)\n",
      "401(k) matching\n",
      "Dental insurance\n",
      "Employee assistance program\n",
      "Employee discount\n",
      "Flexible spending account\n",
      "Health insurance\n",
      "Life insurance\n",
      "Paid time off\n",
      "Professional development assistance\n",
      "Referral program\n",
      "Tuition reimbursement\n",
      "Vision insurance\n",
      "\n",
      "Schedule:\n",
      "\n",
      "8 hour shift\n",
      "Day shift\n",
      "\n",
      "COVID-19 considerations:All employees are required to show proof of Covid-19 vaccination. If asking for an exemption, candidates agree to be subjected to a weekly Covid-19 test.\n",
      "Ability to commute/relocate:\n",
      "\n",
      "Washington, DC 20005: Reliably commute or planning to relocate before starting work (Preferred)\n",
      "\n",
      "Education:\n",
      "\n",
      "Bachelor's (Preferred)\n",
      "\n",
      "Experience:\n",
      "\n",
      "Network technologies and core Internet protocols: 7 years (Required)\n",
      "Design and implement data center fabric solutions: 3 years (Required)\n",
      "VXLAN/EVPN: 10 years (Required)\n",
      "Cisco Data Center Nexus 5k,7k,and 9k Switches: 5 years (Required)\n",
      "Convey technical and functional concept: 10 years (Required)\n",
      "Prepare complex technical documentation: 10 years (Required)\n",
      "\n",
      "License/Certification:\n",
      "\n",
      "CCIE (Preferred)\n",
      "CCDP - Data Center (Required)\n",
      "\n",
      "Work Location: One location\n",
      "Hiring InsightsHiring 1 candidate for this roleJob activityPosted 18 days ago\n",
      "Job detailsSalary$70 - $80 an hourJob TypeFull-timeContractFull Job Description\n",
      "Hello Prospect,\n",
      "I am Ismail from AgileEngine, we are currently hiring for Big Data Engineer for one of our Direct Clients at REMOTE Work.\n",
      "Please send me your current resume, along with the best contact number and time to call details.\n",
      "References are highly appreciated. Good day!\n",
      "Job Title: Big Data Engineer\n",
      "Job Location: Remote Until CovidJob Duration: Long Term Contract\n",
      "Hourly Pay Rate: DOE\n",
      "Job Description: \n",
      "Interview Process: Prescreening questionnaire (Online test) required along with resume submission, followed by telephonic interview, followed by in-person or Video Conferencing Interview (FinR)\n",
      "Experience Level: Senior level\n",
      "Job Functions:Analyze system requirements and design responsive algorithms and solutionsUse big data and cloud technologies to produce production quality codeEngage in performance tuning and scalability engineeringWork with team, peers and management to identify objectives and set prioritiesPerform related SDLC engineering activities like sprint planning and estimationWork effectively in small agile teamsProvide creative solutions to problemsIdentify opportunities for improvement and execute\n",
      "Essential skills:Experience with cloud based Big Data technologiesProficiency in Hive / Spark SQLExperience with SparkExperience with one or more programming languages like Scala, Python, and/or JavaAbility to push the frontier of technology and independently pursue better alternatives\n",
      "Core Skills: Hive, SQL, Spark, Hadoop, Python, Big Data, AWSNice to have skills: Scala, Machine Learning\n",
      "IsmailAgileEngine\n",
      "Contract length: 12 months\n",
      "Job Types: Full-time, Contract\n",
      "Salary: $70.00 - $80.00 per hour\n",
      "Work Remotely:\n",
      "\n",
      "Temporarily due to COVID-19\n",
      "\n",
      "Hiring InsightsHiring 5 candidates for this roleJob activityPosted 30+ days ago\n",
      "Indeed's salary guideNot provided by employer$117K to $148K per year is Indeed's estimated salary for data engineer in Washington, DC.loading surveyAbout Koalafi\n",
      "\n",
      "We're one of the fastest growing consumer finance companies in America. Why? We're making it simpler, faster, and more transparent to purchase the things you need to make your life go.\n",
      "\n",
      "By combining smarter technology with a relentless focus on customer experience, we're transforming the financing experience for essential life purchases in retail stores nationwide.\n",
      "\n",
      "About the Opportunity\n",
      "\n",
      "Our data engineering team is looking for an engineer to help modernize our cloud native data platform. We're reinventing our data to help support our analysts and data scientists to make faster, better decisions with data.\n",
      "\n",
      "This position is responsible for designing, executing, assessing, and troubleshooting data pipelines using modern toolsets like Snowflake, Stitch, FiveTran, Databricks, and DBT. This includes interacting with stakeholders, gathering business requirements, and developing data solutions for enterprise analytics. The data engineer will apply proven communication, analytical, and problem-solving skills to help define success, determine approach, and deliver quality data solutions.\n",
      "\n",
      "Design, develop, test, and deploy data pipelines and use case driven data sets that meet critical business needs, both operational and analytical.\n",
      "Engage with the data analyst community to train and guide them on engineering best practices and new development patterns.\n",
      "Conduct research on emerging technologies, approaches, and best practices to incorporate into the data environment.\n",
      "Design and build modern and traditional data warehousing solutions for business intelligence consumption.\n",
      "Partner closely with stakeholders to understand requirements and create consensus on approach and outcomes.\n",
      "Model business and application processes based on findings through use case scenarios, workflow diagrams, and data models.\n",
      "Provide guidance and mentor new/junior members of the team.\n",
      "Lead in the preparation and documentation of data process requirements and specifications.\n",
      "Lead other data consumers in conceptualizing and developing new data solutions.\n",
      "\n",
      "About You\n",
      "Exceptional analytical, conceptual, and problem-solving abilities.\n",
      "Highly self-motivated and directed, with keen attention to detail.\n",
      "Ability to drive towards outcomes that meet stakeholder needs.\n",
      "Skilled at performing research into emerging technologies and trends, standards, and products.\n",
      "Proven experience in development of complex projects including technical design and analyzing requirements.\n",
      "Strong knowledge of scrum/agile software development process.\n",
      "Expert in building data pipelines in a production environment that supports critical data output.\n",
      "Experience and exposure to a variety of ETL/ELT tools and approaches.\n",
      "Experience with construction or maintenance of modern or traditional data warehouse environments.\n",
      "Expert knowledge of ANSI-SQL (T-SQL is also helpful).\n",
      "Experience with Python, Apache Spark library or other programming languages.\n",
      "Experience with managing services within any of the major cloud providers: AWS (preferred), Azure, or GCE.\n",
      "Experience building solutions with Snowflake, dbt, and Stitch Data (or similar technologies).\n",
      "Experience with source control tools such as Git, and familiarity with CICD concepts.\n",
      "\n",
      "Education/ Certification\n",
      "\n",
      "Four-year college or university program certificate in Computer Science/Engineering or Information Systems; or 5+ years related experience and/or training; or equivalent combination of education and experience.\n",
      "5+ years hands on experience designing and developing enterprise data solutions.\n",
      "2+ years' experience owning outcomes and driving results.\n",
      "\n",
      "Things we value:\n",
      "\n",
      "Curiosity. Why? How?\n",
      "Nerdiness. Financial news and trends are fascinating. Seriously.\n",
      "Relentlessness. No one here gives up. We try. We fail. We try again.\n",
      "Passion. If you don't get excited about point-of-sale financing, retail, and consumer empowerment, it simply won't work.\n",
      "Smarts: Book and street. We have to use all of the tools at our disposal to build Koalafi.\n",
      "Empathy and Compassion. You understand that people's access to life essential goods and services are in your hands.\n",
      "Communication. Can you ask for help or put your hand up when you don't understand?\n",
      "Building. Doing. Making. Yes, we have to do a lot of thinking and talking to figure this stuff out, but you can't wait to leave the conversation and build it.Hiring InsightsJob activityPosted 6 days ago\n",
      "Job detailsSalary$40,000 a yearFull Job Description\n",
      "\n",
      "About Remote\n",
      " Remote is solving global remote organizations' biggest challenge: employing anyone anywhere compliantly. We make it possible for businesses big and small to employ a global team by handling global payroll, benefits, taxes, and compliance (learn more about how it works at remote.com/how-it-works). We're backed by A+ investors and our team is world-class, literally and figuratively, as we're all scattered around the world.\n",
      " Please check out our public handbook (at remote.com/handbook) to learn more about our culture. We encourage folks from all ethnic groups, genders, sexuality, age and abilities to apply. You can also check out independent reviews by other candidates on Glassdoor. If this job description resonates with you, we want to hear from you!\n",
      " All of our positions are fully remote. You do not have to relocate to join us!\n",
      " How we work\n",
      " We love working async (www.notion.so/80c01cd443ad4c77a8ceaef7c5fba5d0) and this means you get to do your own schedule.\n",
      " We empower ownership and proactivity and when in doubt default to action instead of waiting.\n",
      " The position\n",
      " As a data engineer, you will be the link between data producers and data consumers at Remote. You'll primarily focus on building out our data pipeline to unify our various data sources in a compliant manner. That being said, you should also be able to jump in as needed and help deliver consumable data to internal users.\n",
      " Requirements\n",
      " Must have (professional experience)\n",
      "\n",
      "3+ years of experience with SQL (we use PostgreSQL at Remote)\n",
      "3+ years experience with data pipeline tools, e.g. Meltano or Stitch\n",
      "Experience with BI Tools e.g. Metabase, Looker, or Tableau\n",
      "\n",
      "Key responsibilities\n",
      "\n",
      "Maintain our data pipeline by scheduling extractors within Meltano, and handling errors.\n",
      "Writing custom extractors in Python for our Meltano ELT pipeline.\n",
      "Writing transformations using DBT.\n",
      "Identify and address data quality issues.\n",
      "Build documentation around our tools.\n",
      "Work with stakeholders to get them the data they need while maintaining safe data access.\n",
      "Work with stakeholders to build the necessary data pipelines to get people the data they need.\n",
      "Building a clear vision for the needs of the data team, and how to improve our process.\n",
      "\n",
      "Remote Compensation Philosophy\n",
      " Remote's Total Rewards philosophy is to ensure fair unbiased compensation and fair pay along with competitive benefits in all locations in which we operate. We do not agree to or encourage cheap-labour practices and therefore pay a minimum annual salary of USD 40,000 per year, in all locations throughout the world. Actual compensation may vary based upon geographical location, experience, and/or skill level. However, it will never be below our minimum global compensation mentioned.\n",
      " Benefits\n",
      " You can learn more about the benefits we're offering to all internal employees at Remote by visiting our public Benefits & Perks Handbook page (at www.notion.so/people-Benefits-perks-1e48a5869c274f40910b76d405b92f63).\n",
      " Practicals\n",
      "\n",
      "You'll report to: Head of Automation\n",
      "Team: Automation\n",
      "Location: Anywhere in the World\n",
      "Start date: As soon as possible\n",
      "\n",
      "Application process\n",
      "\n",
      "\n",
      "(async) Profile review\n",
      "\n",
      "\n",
      "Interview with recruiter\n",
      "\n",
      "\n",
      "Interview with future manager\n",
      "\n",
      "\n",
      "(async) Small challenge\n",
      "\n",
      "\n",
      "(async) Challenge Review\n",
      "\n",
      "\n",
      "Interview with team members (no managers present)\n",
      "\n",
      "\n",
      " Prior employment verification check(s)\n",
      "\n",
      "\n",
      "(async) Offer\n",
      "\n",
      "\n",
      "How to apply\n",
      " Please fill out the form below. Thank you!\n",
      "\n",
      " #LI-DNI\n",
      "\n",
      "\n",
      "Hiring InsightsJob activityPosted 30+ days ago\n",
      "Job detailsJob TypeFull-timeIndeed's salary guideNot provided by employer$109K to $139K per year is Indeed's estimated salary for data engineer in Bethesda, MD 20814.loading surveyFull Job Description\n",
      "\n",
      "HelioCampus, located in Bethesda, MD, Chapel Hill, NC, and Philadelphia, PA, is a data-driven tech company that serves higher education institutions. We empower institutional effectiveness through assessment, benchmarking and decision support via an enterprise analytics platform. Through three complementary lines of business, HelioCampus helps institutions measure and evaluate their effectiveness in fulfilling their mission by connecting investments with financial and student learning outcomes. With data from every corner of campus, HelioCampus takes a comprehensive, data-informed approach towards continuous improvement and learner success as a methodology to run an institution.\n",
      "\n",
      " We are seeking a Senior Data Engineer to join our technical team working on challenging data integration projects. We value innovative employees who have a sense of ownership in their work and perform well in a fast paced, collaborative team environment. You will work on a combination of exciting new projects and initiatives while also working to improve and maintain HelioCampus’ existing solutions (using cloud technologies). You will become an integral part of a fast-growing team of ETL, BI developers and analysts dedicated to the success of higher education.\n",
      "\n",
      " Key Accountabilities & Responsibilities:\n",
      "\n",
      "Perform SQL development, unit testing and deployment of ETL solutions\n",
      "Design complex data workflow solutions and data models based on user requirements\n",
      "Develop ETL using open source tools and commercial solutions such as Oracle Data Integrator (ODI), Informatica.\n",
      "Performs design and code review functions for the development projects\n",
      "Mentor and coach other ETL developers\n",
      "Research and recommends alternative actions to resolve problems\n",
      "Analyze trends in performance to proactively prevent problems\n",
      "Troubleshoot ETL issues in real-time and diagnoses the root cause\n",
      "\n",
      "\n",
      "\n",
      " Required Skills & Qualifications:\n",
      "\n",
      "6+ years in ETL and related experience \n",
      "4+ years leading the design and development of complex solutions\n",
      "Bachelor’s degree from an accredited institution of higher learning\n",
      "\n",
      "\n",
      "\n",
      " Preferred Skills & Qualifications:\n",
      "\n",
      "Understanding of data warehouse concepts and structures\n",
      "Experience developing complex SQL queries and analyze data, systems integration experience\n",
      "Experience with data mapping, and the ability to design and develop ETL solutions\n",
      "Experience with translation of requirements into data model specifications\n",
      "Ability to multi-task, ability to troubleshoot problems in real-time and diagnose the root cause\n",
      "Desire to join a small, growing company where the sky is the limit on opportunity\n",
      "Attitude of self-starter and ability to explore and find solutions with minimal supervision\n",
      "\n",
      "\n",
      "\n",
      " Compensation and Benefits:\n",
      " HelioCampus offers employees a competitive salary along with paid time off, healthcare, vision, dental, 401(k) w/ company match, remote work flexibility, and a fun, collaborative work environment.\n",
      "\n",
      " HelioCampus is an equal opportunity employer all qualified candidates will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status.\n",
      "\n",
      "Hiring InsightsJob activityPosted Today\n",
      "Job detailsJob TypeFull-timeIndeed's salary guideNot provided by employer$71.2K to $90.2K per year is Indeed's estimated salary for data engineer in Washington, DC.loading surveyFull Job Description\n",
      "\n",
      "  Overview: \n",
      "  \n",
      "    Aurotech is seeking an experienced \n",
      "   Data Engineer (Lvl. 1) to assist Federal Client.\n",
      "   Qualifications: \n",
      "  \n",
      " REQUIRED EXPERIENCE:\n",
      "\n",
      "\n",
      " 1 year of experience in the following:\n",
      "   \n",
      "\n",
      "Experience managing code in GitHub.\n",
      "Experience building applications in Python.\n",
      "Excellent communication skills and ability to work with\n",
      " customers, senior management and other technical teams.\n",
      "   \n",
      "\n",
      "Excellent documentation and organizational skills.\n",
      "\n",
      "\n",
      "\n",
      "Hiring InsightsJob activityPosted 30+ days ago\n",
      "Job detailsSalary$85,000 - $95,000 a yearJob TypeFull-timeQualificationsUS work authorization (Required)Top Secret (Required)Full Job Description\n",
      "Job Title: Voice Data Communications Engineer- Senior\n",
      "Location: Arlington, VA\n",
      "Position Type: Full-time, shift hours (Mon-Thur; consists of a combination of 8- and 12-hour shifts evening shifts)\n",
      "Clearance Required: DoD Top Secret\n",
      "Certification Required: 8570 Baseline Cert (minimum CompTIA Security+)\n",
      "Job Description\n",
      "Description, Duties and Responsibilities\n",
      "The Voice Data Communications Engineer supports and troubleshoots and maintains a DoD Command and Control Computer Systems. This Senior role possesses and applies a comprehensive knowledge across key tasks and high impact assignments. Plans and leads major technology assignments. Evaluates performance results and recommends major changes affecting short-term project growth and success. Functions as a technical expert across multiple project assignments. May supervise others.\n",
      "\n",
      "Provides technical direction and engineering knowledge for communications activities including planning, designing, developing, testing, installing and maintaining large communications networks.\n",
      "Ensures that adequate and appropriate planning is provided to direct building architects and planners in building communications spaces and media pathways meet industry standards.\n",
      "Develops, operates, and maintains voice, wireless, video, and data communications systems.\n",
      "Provides complex engineering or analytical tasks and activities associated with one or more technical areas within the communications function.\n",
      "Provides advice and guidance in implementing IT security policies and procedures in the development and operation of network systems.\n",
      "Coordinates maintenance and operational actions directly with the Joint Staff, DDO, CWO, and the Joint\n",
      "\n",
      "Staff Surveillance Officer.\n",
      "\n",
      "Provides 24/7 maintenance for Processing Display Subsystem–Migration (PDS-M) for the\n",
      "\n",
      "DDO, Surveillance Officer, and all Secure Operation Teams.\n",
      "\n",
      "Conducts risk and vulnerability assessments of installed information systems to identify vulnerabilities, risks, and protection needs.\n",
      "Performs maintenance of Ground Communication Network Modernization (GCNM), Command and\n",
      "\n",
      "Control, Battle Management and Communications (C2BMC), Communications Processing System(CPS), and the components used to make these systems work including smart routers, keyboards, cabling, servers, and personal computers.\n",
      "\n",
      "Maintains a comprehensive quality assurance program for diverse platforms that covers, file backup and recovery, equipment maintenance, and quality control of systems processing and outputs.\n",
      "\n",
      "Qualifications and Education Requirements\n",
      "\n",
      "Bachelor’s Degree or higher, preferred.\n",
      "\n",
      "TIME Systems, LLC is an equal opportunity/affirmative action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.\n",
      "Updated: 4/1/2022\n",
      "Job Type: Full-time\n",
      "Pay: $85,000.00 - $95,000.00 per year\n",
      "Benefits:\n",
      "\n",
      "401(k)\n",
      "401(k) matching\n",
      "Dental insurance\n",
      "Health insurance\n",
      "Health savings account\n",
      "Life insurance\n",
      "Paid time off\n",
      "Referral program\n",
      "Retirement plan\n",
      "Vision insurance\n",
      "\n",
      "Schedule:\n",
      "\n",
      "12 hour shift\n",
      "8 hour shift\n",
      "\n",
      "Security clearance:\n",
      "\n",
      "Top Secret (Required)\n",
      "\n",
      "Work Location: One location\n",
      "Hiring InsightsApplication response rate: 65%Hiring 1 candidate for this roleUrgently hiringJob activityPosted 4 days ago\n",
      "Job detailsSalaryUp to $177,424 a yearFull Job Description\n",
      " Peraton drives missions of consequence spanning the globe and extending to the farthest reaches of the galaxy. As the world’s leading mission capability integrator and transformative enterprise IT provider, we deliver trusted and highly differentiated national security solutions and technologies that keep people safe and secure. Peraton serves as a valued partner to essential government agencies across the intelligence, space, cyber, defense, civilian, health, and state and local markets. Every day, our employees do the can’t be done, solving the most daunting challenges facing our customers. \n",
      " Responsible for translating the client’s business requirements into specific systems, applications or process designs for very large complex IT solutions and integrating architecture. Acts as an advocate for the client as the ultimate authority on the architecture designed to address client business problems. Plans, implements, tests, documents, and maintains enterprise-wide solutions to total system or subsystems using internally created and/or off the shelf products. Analyzes and ident ifies all or part of an organization’s existing or new peripheral, network, and telecommunications systems requirements, taking into consideration the special technology needs. Establishes functional and technical specifications and standards, solves hardware/software interface problems, defines input/output parameters, and en sures integration of the system or subsystem via data exchange methodologies . Provides direction for design activities. \n",
      " \n",
      "\n",
      "Contract Specific Responsibilities: Advise government partners and stakeholders on the design, development and/or implementation of information sharing systems. Conduct research and analysis of existing systems and solutions within federal government departments and agencies to aid enterprise-wide interoperability and the technical exchange of information. Support the identification and resolution of complex issues and develop innovative technical solutions for supporting government operations and requirements. Prepare and write technica l briefings, position papers, and industry standard engineering artifacts. Develop technical project plans and advise the Government on proposed project goals, objectives, and tasks to achieve on-time delivery of products/services. Participate in technical exchange and governance meetings used to develop, issue, and monitor the implementation of guidance on systems/architectures. Facilitate requirements definition sessions, document requirements, help develop the test cases/scenarios, ensuring consistency in project plans and updates, and support testing modules as these are developed. Support evaluation of cloud-based hosting options and recommend solutions. Collaborate with stakeholders to gain consensus, formulate planning and drive progress. Take meeting notes as required. \n",
      " Active TS/SCI with Poly level clearance is required Bachelor’ degree or higher is required, STEM is preferred Industry standard certifications are desirable, especially to augment non-STEM degree At least five (5) years of relevant experienc e developing, implementing, or enhancing information sharing systems, preferably for government organizations; Working knowledge of existing systems and solutions within federal government departments and agencies, to include the IC; Full understanding of Software Development Life Cycle. Hands-on experience developing software solutions using JAVA and/or the .Net environments, and good understanding of the AWS or Azure Ability to understand and design technical solutions; Demonstrated analytical capabilities and discipline in identifying and resolving complex issues and developing innovative solutions for supporting government mission business processes and requirements; Ability to draft position papers, prepare briefings, and record minutes for executive level interagency meetings; Ability to communicate and work with executive-level partners and decision makers; Ability to develop project plans and propose project goals, objectives, and tasks to achieve on-time delivery of customer products; Past experience with creating/managing and integrating systems with diverse databases, schemas, XML/JSON based exchange specifications like NIEM is highly desired; Experience developing test cases/scenarios, ensuring consistency in project plans and updates, and conduct testing modules as these are developed. UML modeling experience is highly desirable ; Certifications and operational experience with VMware, Amazon Web Services (AWS), or Microsoft Azure desirable. \n",
      " \n",
      "\n",
      "Colorado Salary Minimum: $82,992.00 \n",
      " \n",
      "Colorado Salary Maximum: $177,424.00 \n",
      " \n",
      " The estimate displayed represents the typical salary range for this position, and is just one component of Peraton's total compensation package for employees. Other rewards may include annual bonuses, short- and long-term incentives, and program-specific awards. In addition, Peraton provides a variety of benefits to employees.\n",
      "Hiring InsightsJob activityPosted 30+ days ago\n",
      "Job detailsJob TypeFull-timeFull Job Description\n",
      "\n",
      "\n",
      "   Aledade is looking for a remote Data Engineer to help develop our data pipelines and create new data assets that are used to empower primary care physicians to improve the quality of healthcare for millions of patients. Aledade is in a period of rapid growth and we need your help to tame the many-headed hydra of healthcare data and spin it into gold.\n",
      "  \n",
      "\n",
      "\n",
      " Data Engineers on the engineering team work with our Business Intelligence and Impact Analytics teams to create new data assets that power insight both internally and externally. In addition, they manage and extend the core data model, in collaboration with data engineers on the corporate systems team as well as engineers in the product application.\n",
      "  \n",
      "\n",
      "\n",
      " Aledade has a US based permanently remote engineering and product team\n",
      "  \n",
      " Here’s what you’ll do:\n",
      "\n",
      " Create and maintain optimal data pipeline architecture (SQL, python, Snowflake, dbt, Airflow, AWS), from multiple raw sources of data to polished datasets for analytic and dashboard consumption\n",
      " Work with internal reporting and analytics teams to design and implement new data assets that support greater insight and/or improve downstream business processes\n",
      " Work alongside data architects and data engineers from other teams to solve problems related to the core data model\n",
      " Collaborate with product teams on migration of schema elements to production\n",
      " Work with data and analytics experts to strive for greater functionality in our data systems\n",
      "\n",
      " Requirements:\n",
      "\n",
      " Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.\n",
      " 2 or more years experience building and optimizing ‘big data’ data pipelines, architectures and data sets, 4 years experience in engineering\n",
      " Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.\n",
      " A successful history of manipulating, processing and extracting value from large disconnected datasets.\n",
      " A love of supporting and working with cross-functional teams in a dynamic environment.\n",
      "\n",
      " Bonus points if you also have:\n",
      "\n",
      " Worked with healthcare data\n",
      "\n",
      "\n",
      " All prospective hires will be required to demonstrate that they have been fully vaccinated, including booster shots, against COVID-19 with a COVID-19 vaccine for which the U.S. Food and Drug Administration has issued a license or an Emergency Use Authorization prior to mutually-agreed upon start date at Aledade, unless they qualify for a medical or religious accommodation to this vaccination requirement. In certain limited circumstances, Aledade will accept documented proof of prior infection with COVID-19 in lieu of a booster shot.\n",
      "\n",
      "\n",
      "\n",
      " If you are passionate about transforming the healthcare system into one that best serves the needs of patients, doctors, and society, we’d love for you to join us!\n",
      "\n",
      "\n",
      "\n",
      " Who We Are:\n",
      "\n",
      "\n",
      "    Aledade is a leader in population health that is using innovative, value based solutions to transform the way physicians interact with their patients. We are on a mission to change healthcare for the better and solve complex problems within the healthcare system.\n",
      "  \n",
      "\n",
      "\n",
      " We follow the simple but radical idea that Aledade only succeeds when our partner practices succeed. From our cutting-edge technology platform to practice transformation services, we provide physicians with everything they need to create and run an accountable care organization (ACO), revamping the way they practice and getting them back to where they should be: quarterbacking their patients’ health care!\n",
      "  \n",
      "\n",
      "\n",
      " Our customized solutions help clinicians in communities across America preserve their autonomy, deliver better care to their patients, reduce overall costs, and keep independent physician practices flourishing.\n",
      "  \n",
      "\n",
      "\n",
      " What Does This Mean for You?\n",
      "\n",
      "\n",
      "    At Aledade, you will be part of a creative culture that is driven by a passion for tackling complex issues with respect, open-mindedness, and a desire to learn. You will work with team members that bring a wide range of experiences, interests, backgrounds, beliefs, and achievements to their work, united by a shared passion for public health and a commitment to the Aledade mission.\n",
      "  \n",
      "\n",
      "\n",
      " We’ve recently been recognized as a Top Workplace by The Washington Post, Best Workplace in HealthCare & Biopharma, Top 100 Best Small & Medium Workplaces, Glassdoor Best Places to Work, a Best and Brightest Companies to Work for in the Nation, a Tech Tribune 10 Best Tech Startups in Maryland and Bethesda, Best Tech for Good, Best Workplaces for Millennials, Best Workplaces for Women, Best Workplaces for Parents, and a 2020 Inno on Fire by DC Inno.\n",
      "   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "That’s because the things that matter to you also matter to us!\n",
      "\n",
      "\n",
      "\n",
      " In addition to time off to support work-life balance and enjoyment, we offer the following comprehensive benefits package designed for the needs of our team-members:\n",
      "  \n",
      "\n",
      "\n",
      " Flexible work schedules and ability to work remotely available for many roles\n",
      "  \n",
      "\n",
      "    Educational Assistant Program\n",
      "  \n",
      "\n",
      "    Robust time off plan (21 days of PTO in your first year!)\n",
      "  \n",
      "\n",
      "    Paid Volunteer Days\n",
      "  \n",
      "\n",
      "    10 paid holidays\n",
      "  \n",
      "\n",
      "    12 weeks paid Parental Leave for all new parents\n",
      "  \n",
      "\n",
      "    6 weeks paid sabbatical\n",
      "  \n",
      "\n",
      "    Health, dental and vision insurance paid up to 80% for employees, dependents, and domestic partners\n",
      "  \n",
      "\n",
      "    401(k) with up to 4% match\n",
      "  \n",
      "\n",
      "    Stock options\n",
      "  \n",
      "\n",
      "    Monthly cell phone stipend\n",
      "  \n",
      "\n",
      "    Weekly catered lunches\n",
      "  \n",
      "\n",
      "    Jeans everyday workplace\n",
      "  \n",
      "\n",
      "    Gender neutral bathrooms\n",
      "  \n",
      "\n",
      "    And more!\n",
      "  \n",
      "\n",
      "\n",
      " At Aledade, we don’t just accept differences, we celebrate them! We strive to attract, develop, and retain highly qualified individuals representing the diverse communities where we live and work. Aledade is committed to creating a diverse environment and is proud to be an equal opportunity employer. Employment policies and decisions at Aledade are based on merit, qualifications, performance, and business needs. All qualified candidates will receive consideration for employment without regard to age, race, color, national origin, gender (including pregnancy, childbirth or medical conditions related to pregnancy or childbirth), gender identity or expression, religion, physical or mental disability, medical condition, legally protected genetic information, marital status, veteran status, or sexual orientation.\n",
      "\n",
      "\n",
      "Hiring InsightsJob activityPosted 12 days ago\n",
      "Job detailsJob TypeFull-timeIndeed's salary guideNot provided by employer$111K to $141K per year is Indeed's estimated salary for data engineer in Rockville, MD 20850.loading surveyFull Job Description\n",
      "\n",
      "Our client, one of the largest Amazon Web Services (AWS) partners for data services, is looking for a Mid level Big Data Engineer to contribute to join their team of technologists to build and contribute to large-scale, innovative projects. Technological and career growth opportunities are a natural and every day part of the working environment.\n",
      "\n",
      "This role is only available for W2 or individual contracts. Please no C2C. \n",
      "100% Remote Work.\n",
      "\n",
      "\n",
      " Responsibilities:\n",
      "\n",
      " Analyze system requirements and design responsive algorithms and solutions.\n",
      " Use big data and cloud technologies to produce production quality code.\n",
      " Engage in performance tuning and scalability engineering.\n",
      " Work with team, peers and management to identify objectives and set priorities.\n",
      " Perform related SDLC engineering activities like sprint planning and estimation.\n",
      " Work effectively in small agile teams.\n",
      " Provide creative solutions to problems.\n",
      " Identify opportunities for improvement and execute.\n",
      "\n",
      "\n",
      " Requirements:\n",
      "\n",
      " Minimum 3 years of proven professional experience working in the IT industry.\n",
      " Degree in Computer Science or related domains.\n",
      " Experience with cloud based Big Data technologies.\n",
      " Experience with big data technologies like Hadoop, Spark and Hive.\n",
      " AWS experience is a big plus.\n",
      " Proficiency in Hive / Spark SQL / SQL. Experience with Spark.\n",
      " Experience with one or more programming languages like Scala & Python & Java.\n",
      " Ability to push the frontier of technology and independently pursue better alternatives.\n",
      " Kubernetes or AWS EKS experience will be a plus.\n",
      "\n",
      "\n",
      " Thanks for applying!\n",
      " \n",
      "gnaYLD58ZG\n",
      "\n",
      "Hiring InsightsJob activityPosted 3 days ago\n",
      "Job detailsJob TypeFull-timeFull Job Description\n",
      "\n",
      "Why will you enjoy this new opportunity? \n",
      "Every new job is an opportunity for growing your career. VMware is growing and growing fast in the multi-cloud space. As part of this, VMware is growing its data products and cloud services portfolio to provide our customers a truly multi-cloud platform. That includes SQL, no-SQL engines, analytics capabilities (everything from BI to AI), and messaging and caching services for modern, cloud-native application development.\n",
      "\n",
      " You can be a part of this growth story as VMware is the only company perfectly positioned to provide the multi-cloud platform for all the applications our customers need to accelerate their business today, and in the future. Joining VMware gives you long-term opportunities to expand your skills with annual education and/or training reimbursements, job rotation programs, subscriptions to online training platforms and employee networking groups. As a Tanzu Data Solutions Engineer you must be equally comfortable in both a business and technical context, interacting with executives and talking shop with technical audiences.\n",
      "\n",
      " A little bit about the role & the team \n",
      "In this role you will be reporting to the America’s head of solution engineering and be responsible for all current and new accounts. We are customer obsessed and we believe in the value we can add and stay honest about it. We love to learn, are open to giving and receiving feedback and are passionate about making our customers successful. Our team works to ensure data is accessible, usable and valuable to everyone. On this team, you'll be working on hard, worthwhile problems with a collaborative team, accelerating your growth as a Data Architect / Engineer. The challenges we solve for our customers vary from implementing high performance, highly available transactional systems for industry leading financial institutions to designing messaging / eventing architectures for healthcare companies to optimizing deep analytics across petabytes of critical business data for consumer clients.\n",
      "\n",
      " In this role you will get to:\n",
      "\n",
      " Learn about customer’s data use cases and design patterns and then position complementary/competitive VMWare Tanzu Data products & services.\n",
      " Educate/enable technical audience on Tanzu Data products like Greenplum for MPP analytics, Open Source database products like Postgres/MySQL, caching solutions like GemFire (Apache Geode) and messaging products like RabbitMQ.\n",
      " Present Tanzu Data technology and vision to executives and technical contributors at prospects and customers\n",
      " Work hands-on with prospects and customers to demonstrate and communicate the value of Tanzu Data technology throughout the sales cycle, from demo to proof of concept to design and implementation\n",
      " Immerse yourself in the ever-evolving industry, maintaining a deep understanding of competitive and complementary technologies and vendors and how to position Tanzu Data in relation to them.\n",
      " Collaborate with Product Management, Engineering, and Marketing to continuously improve Tanzu Data's products and marketing.\n",
      "\n",
      "\n",
      " Desired Skills and Experience\n",
      "\n",
      " Ability to connect a customer's specific business problems and Tanzu Data's solutions\n",
      " Outstanding presentation skills to both technical and executive audiences, whether impromptu on a whiteboard or using presentations and demos.\n",
      " Understanding of traditional DW/BI components (ETL, Staging, DW, ODS, Data Marts, BI Tools)\n",
      " Understanding of the hardware and networking architecture behind large scale systems\n",
      " Familiarity with standard statistical/BI packages to perform analytic calculations\n",
      " Experience with cloud infrastructure architecture and use; AWS, Azure, GCP\n",
      " Operational knowledge of vSphere, Kubernetes , Docker, containers\n",
      " Ability to work independently and meet deadlines with little to no supervision\n",
      " Building, deploying, and managing systems leveraging a variety of data technologies.\n",
      " Specific experience with Postgres and the associated ecosystems of tooling and related technologies is a plus.\n",
      " Experience with Massively Parallel Processing (MPP) data warehouses such as Greenplum, Teradata, Netezza, Exadata, Azure SQL Data Warehouse, Redshift, and/or Hadoop.\n",
      " Data science understanding - AI/ML, GIS, MADlib, etc\n",
      " Excellent verbal and written communications skills along with the ability to present technical data and approaches to both technical and non-technical audiences\n",
      " Hands-on expertise with DBaaS, NoSQL, SQL and SQL analytics\n",
      " University degree in computer science, engineering, mathematics or related fields, or equivalent experience preferred\n",
      "\n",
      "\n",
      " What are the benefits and perks of working at VMware?\n",
      " You and your loved ones will be supported with a competitive and comprehensive benefits package. Below are some highlights, or you can view the complete benefits package by visiting www.benefits.vmware.com.\n",
      "\n",
      "Employee Stock Purchase Plan\n",
      "Medical Coverage, Retirement, and Parental Leave Plans for All Family Types\n",
      "Generous Time Off Programs\n",
      "40 hours of paid time to volunteer in your community\n",
      "Rethink's Neurodiversity program to support parents raising children with learning or behavior challenges, or developmental disabilities\n",
      "Financial contributions to your ongoing development (conference participation, trainings, course work, etc.)\n",
      "Wellness reimbursement and online fitness and wellbeing classes\n",
      "\n",
      "\n",
      " This job may require the candidate to comply with travel restrictions and/or work from a facility that requires full vaccination prior to entry.\n",
      " Category : Sales Subcategory: Systems Engineering Experience: Manager and Professional Full Time/ Part Time: Full Time Posted Date: 2022-03-30\n",
      " VMware Company Overview: At VMware, we believe that software has the power to unlock new opportunities for people and our planet. We look beyond the barriers of compromise to engineer new ways to make technologies work together seamlessly. Our cloud, mobility, and security software form a flexible, consistent digital foundation for securely delivering the apps, services and experiences that are transforming business innovation around the globe. At the core of what we do are our people who deeply value execution, passion, integrity, customers, and community. Shape what’s possible today at http://careers.vmware.com.\n",
      "  \n",
      " Equal Employment Opportunity Statement: VMware is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: VMware is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at VMware are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. VMware will not tolerate discrimination or harassment based on any of these characteristics. VMware encourages applicants of all ages. Vmware will provide reasonable accommodation to employees who have protected disabilities consistent with local law.\n",
      " \n",
      "Hiring InsightsJob activityPosted 6 days ago\n",
      "Job detailsSalary$120,000 - $140,000 a yearJob TypeFull-timeFull Job Description\n",
      "Responsibilities\n",
      "\n",
      "Work under the direction of the product owner as part of an agile team\n",
      "Collaborate with a cross-functional team of architects, developers and product managers to develop and deliver advanced analytics solutions.\n",
      "Research, articulate and propose proper usage of descriptive, diagnostic, predictive and prescriptive analytics to align with business goals.\n",
      "Develop processes to collect and streamline varying data sources into a curated set of data repositories.\n",
      "Transform data and analysis into informative visualizations and interactive dashboards using open-source and commercially available tools.\n",
      "Leverage analytical tools to create data pipelines, providing actionable insight into key business performance metrics including operational efficiency and customer acquisition\n",
      "Help leverage open source and commercial artificial intelligence platforms.\n",
      "Help build required infrastructure for optimal extraction, transformation and loading of data from various data sources using AWS and other technologies\n",
      "Implement techniques to understand and clean raw and unstructured data (data wrangling).\n",
      "Implement statistics, data checking, and internal controls on data reporting and quality, consistency.\n",
      "\n",
      "Qualifications\n",
      "\n",
      "5 years of professional production data engineering experience\n",
      "2+ years of professional production experience with AWS\n",
      "2+ years of professional production experience with Cloudera Data Platform\n",
      "2+ years of professional production experience with Apache Spark\n",
      "7+ year of experience developing dashboards using data visualization tools\n",
      "7+ years of experience with relational databases and SQL\n",
      "7+ years of professional programming\n",
      "\n",
      "Education Requirements: Bachelor’s degree in mathematics, statistics, computer science, physical science, natural science, data science, or engineering; Master’s degree preferred\n",
      "Job Type: Full-time\n",
      "Pay: $120,000.00 - $140,000.00 per year\n",
      "Benefits:\n",
      "\n",
      "401(k)\n",
      "Dental insurance\n",
      "Flexible schedule\n",
      "Health insurance\n",
      "Paid time off\n",
      "Vision insurance\n",
      "\n",
      "Schedule:\n",
      "\n",
      "Monday to Friday\n",
      "\n",
      "Experience:\n",
      "\n",
      "Data engineering: 5 years (Preferred)\n",
      "AWS, Cloudera Data Platform, Apache Spark: 2 years (Preferred)\n",
      "Relational databases, SQL, Professional programming: 7 years (Preferred)\n",
      "\n",
      "Work Location: One location\n",
      "Hiring InsightsApplication response rate: 67%Hiring 1 candidate for this roleUrgently hiringJob activityEmployer reviewed job 10 days agoPosted 27 days ago\n",
      "Indeed's salary guideNot provided by employer$91.3K to $116K per year is Indeed's estimated salary for system engineer in Washington, DC 20024.loading surveyCNA fosters an inclusive culture that values diverse backgrounds and perspectives. Our flexible and engaging work environment encourages iterative and creative collaboration at every stage of the problem solving process. Our employees are committed to helping clients develop effective solutions to better manage their programs through scientific, data-driven approaches. We are looking for creative and innovative individuals to help carry out our mission.\n",
      "PRIMARY PURPOSE\n",
      "Assists with systems and operations analysis, requirements and systems development analysis and design. Assists with scientific and technical investigations.\n",
      "JOB DESCRIPTION AND/OR DUTIES\n",
      "1. Assists with the definition and development of system requirements and documentation of the requirements in detailed specifications from which programs will be developed and/or procured, and from which hardware will be developed and/or procured.\n",
      "2. Under direction of project leader, supports formulation and definition of user requirements, system use cases, system specifications and system design based on user needs, research, and fact-finding. Applies standard research methodologies to gather, process, and analyze data. Use relevant database software to effectively organize and present data and generate reports.\n",
      "3. Work somewhat independently on focused well-structured pieces of projects. Work under close supervision on broader strands of the project. Begin to understand project budgeting and financial tracking over the project lifecycle.\n",
      "4. Devises or modifies procedures and specifications to address common functions, computer equipment capacity, or operating time.\n",
      "5. Develop a basic familiarity with the missions and organizational structure of the division or team's major client/sponsors.\n",
      "6. Draft sections of reports, briefings, or other project deliverables. Begin to structure problems of moderate scope, technical assistance or proposal development tasks.\n",
      "7. Under direction of project manager, supports development of independent validation and verification plans and scenarios, following industry standards and system requirements\n",
      "8. Participate in meetings with project team. Support preparation for and contributes to client/sponsor and project team interactions.\n",
      "9. Develop a sufficient understanding or expertise on specific tasks, issues or data so as to make a positive contribution to project outcomes.\n",
      "10. Take responsibility for own actions and outcomes. Is proactive in seeking ways to improve processes and operations and in making CNA a better place.\n",
      "11. Act as a primary data collector and provide substantive inputs into CNA studies and proposals, including project planning and coordination, preparation of reports, memoranda, quality reviews, etc.\n",
      "12. Conduct technical assistance activities such as planning and organizing meetings and seminars.\n",
      "13. Performs other duties as assigned.\n",
      "\n",
      "JOB REQUIREMENTS\n",
      "1. Education: Bachelor's degree in computer science, mathematics, operations research, or a related engineering field or 6 years equivalent experience.\n",
      "2. Experience: Minimum of 2 years strong work experience performing duties similar to those above in a Government contract environment or 4 years of generally related experience.\n",
      "3. Skills: Ability to construct effective briefings using MS PowerPoint and intermediate to advanced skills with MS Word and Excel and other standard software packages. Ability to communicate information concisely, precisely, and in a grammatically correct manner in both oral and written communication. Ability to present and summarize data effectively. Exhibit a positive attitude in interactions with colleagues, clients/sponsors, and staff. Working knowledge of system and software lifecycle processes, tools and techniques, system development and testing documentation and standards; computer system performance estimation and measurement standards and tools; software development lifecycle; Ability to work well with others.\n",
      "CNA is committed to providing equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, religion, color, sex (including pregnancy, gender identity, and sexual orientation), parental status, national origin, age, disability, family medical history or genetic information, political affiliation, military service and protected veterans, or other non-merit based factors. In addition to federal legal requirements, CNA complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. These protections extend to all terms and conditions of employment, including recruiting and hiring practices, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training and career development programs. For more information about EEO protections, please view the EEO is the law posters here: \"EEO is the Law\" Poster\", \"EEO Poster Supplement\". The pay transparency policy is available here: Pay Transparency Nondiscrimination Poster. To be considered for hire, all individuals applying for positions with CNA are subject to a background investigation. For positions requiring access to classified information, U.S. citizenship is required. Individuals will also be subject to an additional government background investigation, and continued employment eligibility is contingent upon the ability to obtain and maintain an active security clearance.Hiring InsightsJob activityPosted 4 days ago\n",
      "Indeed's salary guideNot provided by employer$130K to $165K per year is Indeed's estimated salary for cloud engineer in McLean, VA 22102.loading surveyOverview:\n",
      "\n",
      "Steampunk is looking for a Cloud Data Engineer to join our team to support a federal customer in their efforts to enhance common infrastructure capabilities to help create and execute a diverse cloud migration plan. The ideal candidate must be able to design, develop, test, and/or demonstrate working solutions that meet customer objectives for enhancing infrastructure capabilities within the cloud and deliver documentation to effectively plan and implement those solutions.\n",
      "Contributions:\n",
      "\n",
      "As a Cloud Data Engineer, you will:\n",
      "Identify and leverage best practices implementing the major cloud providers (GCP, Azure, Amazon Web Services (AWS), etc). Mentor small engineering and development team on best practices and service utilization.\n",
      "Utilize cloud tools (such as AWS CLI, CloudFormation, AWS-Roles) to standardize, secure, and automate infrastructure deployment and management activities.\n",
      "Engineer and integrate varying systems in a hybrid cloud environment, to include installation, operations, maintenance, documentation, and disaster recovery of integrated systems.\n",
      "Deploy a multi-layer integrated system leveraging automation and containerization.\n",
      "Customize Splunk and QRadar to fully integrate and leverage log aggregation, ingestion, and reporting capabilities.\n",
      "Demonstrate and exercise operational rigor, documentation of steps, backup of artifacts, validation through unit testing and comparison, and restoration of changes.\n",
      "Participate in Agile team structure to develop and deploy: architectural components and services, application code, patches and configuration changes, and integration capabilities.\n",
      "Improve security posture by configuring and deploying access controls, monitoring and logging, baseline images (such as Amazon Machine Images (AMI)), networking, deployment and compliance automation for both Linux and Windows workloads in the cloud.\n",
      "Provide strategic and engineering guidance to customer, program team, and project managers regarding technology evaluation, planning, and implementation.\n",
      "Develop technology road-maps, providing technical advice and develop solutions to address customer requirements.\n",
      "Conduct Engineering sessions, develop and refine activity sequences and level of effort estimates for project managers as requested to develop project schedules.\n",
      "Qualifications:\n",
      "The ideal candidate will have exceptionally strong written and verbal communication skills and possess 15+ years of experience performing systems engineering and administration, with heavy emphasis on cloud\n",
      "Strong judgment, negotiation skills, organizational, and analytical skills\n",
      "Experience working in a complex engineering environment\n",
      "Ability to establish trust with a variety of stakeholders and customers\n",
      "Self-managed and self-starter, ability to work independently\n",
      "A BS or BA Degree in Computer Science, Information Technology or related field.\n",
      "Experience with cloud service implementations using industry best practices\n",
      "Experience in implementing cloud automation with application deployment\n",
      "Experience in hybrid cloud architecture, integration, and deployment\n",
      "Experience integrating varying infrastructure and business application systems in a hybrid cloud environment; to include installation, operations, maintenance, documentation, and disaster recovery\n",
      "Experience with data pipeline and orchestration tools such as Apache Airflow and Apache NiFi\n",
      "Experience with cloud data services such as AWS Glue, AWS Data Pipeline, AWS Redshift, AWS Athena, AWS RDS, AWS EMR, and AWS SageMaker\n",
      "Experience deploying multi-layer integrated systems, leveraging automation and containerization\n",
      "Experience integrating with on premise logging tools such as Splunk and QRadar\n",
      "Experience integrating with on premise security tools to integrate with and leverage common controls provided by general support systems\n",
      "Experience replacing or augmenting on premise security tools with cloud provided web services and capabilities to provide security controls\n",
      "Experience developing Architecture and Design documentation, implementation and test plans, SOPs, etc.\n",
      "Experience working in an Agile environment – supporting all aspects of the SDLC and processes\n",
      "US Citizenship\n",
      "Cloud certification (e.g. Solutions Architect, DevOps Engineer, SysOps Administrator, Cloud Practitioner) is preferred\n",
      "Steampunk is a federal contractor subject to Executive Order 14042 and Federal Acquisition Regulation (FAR) 52.223-99 implementing the order. Therefore, this position requires full vaccination for COVID-19, except in jurisdictions where the mandate is barred by a court ordered injunction.\n",
      "About steampunk:\n",
      "\n",
      "Steampunk is a Change Agent in the Federal contracting industry, bringing new thinking to clients in the Homeland, Federal Civilian, Health and DoD sectors. Through our Human-Centered delivery methodology, we are fundamentally changing the expectations our Federal clients have for true shared accountability in solving their toughest mission challenges. As an employee owned company, we focus on investing in our employees to enable them to do the greatest work of their careers – and rewarding them for outstanding contributions to our growth. If you want to learn more about our story, visit http://www.steampunk.com.\n",
      "We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. Steampunk participates in the E-Verify program.Hiring InsightsJob activityPosted 3 days ago\n",
      "Job detailsJob TypeFull-timeFull Job Description\n",
      "\n",
      "  In this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence (AI). Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the Government and Public Services marketplace. \n",
      "  \n",
      " Work you'll do \n",
      "  \n",
      " We are looking for experienced Data Engineers to build and deliver innovative, game-changing mission-driven data pipelines. On this project, you will be responsible for leading the architecture and setup of hosted data lakes, as well as the ingestion pipeline and processing for large datasets, working closely with Agile software development team(s). This role includes responsibilities such as creating and managing schedules for data management (migration, integration, etc.) efforts, working with clients to validate migrated data, working with Agile development teams to understand changes and their impacts towards data migration efforts, among other tasks.\n",
      "  \n",
      " The team \n",
      "  \n",
      " Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise. \n",
      "  \n",
      " The GPS Analytics and Cognitive (A&C) offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights. \n",
      "  \n",
      " Qualifications \n",
      "  \n",
      " Required: \n",
      "  \n",
      "\n",
      "Bachelor's degree required \n",
      "Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future \n",
      "Must be able to obtain and maintain the required clearance for this role \n",
      "Travel up to 10% \n",
      "1+ years of experience with extract, transform, and load (ETL) methods and tools \n",
      "1+ years of experience with data modeling, data warehousing, and building ETL pipelines \n",
      "1+ years of experience with SQL queries and JSON objects \n",
      "1+ years of experience with both SQL and NoSQL databases, including PostgreSQL and MongoDB \n",
      "\n",
      "\n",
      " Preferred:\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "Familiarity with microservice architectures \n",
      "Interest in event streaming architectures, such as Apache Kafka \n",
      "Prior professional services or federal consulting experience \n",
      "Knowledge of data mining, machine learning, data visualization and statistical modeling \n",
      "Ability to thrive in a fast-paced work environment with multiple stakeholders \n",
      "Creativity and innovation - desire to learn and apply new technologies, products, and libraries \n",
      "\n",
      "\n",
      " How you'll grow \n",
      "  \n",
      " At Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there's always room to learn. We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.\n",
      " \n",
      "Hiring InsightsJob activityPosted 9 days ago\n",
      "Job detailsSalary$90,000 a yearFull Job Description\n",
      "\n",
      "The role\n",
      " As a Data Engineer at Blue State, you'll play an integral role on a smart and vibrant analytics team servicing a wide range of progressive organizations. You'll design, build, and manage the systems and processes which form the underpinning of Blue State's analytics work, supporting and working alongside data analysts and campaign strategists. But you'll also work directly with Blue State's clients to help solve their data integrity and integration challenges, serving as a trusted advisor to your counterparts within client organizations.\n",
      " Day-to-day responsibilities:\n",
      "\n",
      "Create and support systems and processes for managing, compiling, manipulating, and analyzing data for client and internal projects\n",
      "Work with Blue State's client organizations to solve difficult data migration, management, and integration challenges\n",
      "Build data pipelines, data warehouses, reporting dashboards, automated exports, and synchronization processes\n",
      "Automate workflows and look for further opportunities to improve efficiency in our work\n",
      "Always maintain a high level of data security and privacy\n",
      "\n",
      "The team\n",
      " You will be a part of the global Web and Product Development team working primarily with our creative agency on client projects. You'll work in either the NY or DC office.\n",
      " Once Blue State offices reopen, on-site presence is strongly preferred at a minimum of two days a week. To enter our US offices or attend Blue State events, staff and visitors must be fully vaccinated against COVID-19, including with a booster shot when eligible. Exceptions for protected grounds will be reviewed on a case-by-case basis.\n",
      " Top things we're looking for\n",
      "\n",
      "Good foundational understanding of statistical analysis\n",
      "Extensive experience working with SQL databases in an analytics or business intelligence context\n",
      "Familiarity with common marketing technology platforms like Google Analytics, Google Ads, Facebook Ads, email marketing tools, and other marketing automation tools\n",
      "Experience with ETL/ELT tools, processes, and best practices\n",
      "Strong Python experience:\n",
      "\n",
      "\n",
      "Python should be your go-to tool for solving problems. If the first thing you want to do when you have to do the same thing twice is write a Python script to automate it - we want you!\n",
      "\n",
      "\n",
      "Experience with task automation in a Python context - experience with AirFlow, Prefect, Dask a big plus\n",
      "\n",
      "\n",
      "Experience working with restful APIs - you can competently navigate unfamiliar API documentation and figure out how to accomplish tasks\n",
      " \n",
      "Strong working knowledge of Google BigQuery and the Google Cloud Platform data product ecosystem including:\n",
      "\n",
      "\n",
      "Designing data warehouse schemas for cross-channel marketing analytics\n",
      "\n",
      "\n",
      "Utilizing the suite of Google Cloud Platform tools for the purposes of extracting, processing, manipulating and analysing data\n",
      "\n",
      "\n",
      "Building and running automated tasks within the GCP environment - e.g. Cloud Compute, Cloud Functions, Cloud Run, Cloud Scheduler\n",
      "\n",
      "\n",
      "Comfortable managing GCP IAM policies across projects and teams\n",
      " \n",
      "Comfortable working within a spreadsheet (even if you prefer a database) - preferably in Google Sheets - bonus points if you've extended Google Sheets using Google Apps Script\n",
      "Familiarity with Git and maintains good habits around code maintenance\n",
      "Able to build repeatable and well-documented processes and tools that can be used by other technically-savvy but non-Python developer analytics team members (think easy to use command-line scripts - not GUIs)\n",
      "Good at teaching others what you know.\n",
      "\n",
      "At Blue State, diversity is a necessity, not a nice-to-have. We encourage those from underrepresented communities — women, people of color, LGBTQIA+, immigrants, indigenous folks, those with disabilities and people at all the intersections in between — to apply. Even if you don't think your current skill set checks every box below, but this role seems to align with your strengths, we want to hear from you.\n",
      " The minimum starting salary for this position is $90,000; compensation is otherwise commensurate with experience.\n",
      " The company\n",
      " Blue State is a values-led creative and campaigns agency that partners with leading causes, companies, and campaigns to build better organizations for a better world. We drive real change, make good trouble, put people first and are constantly curious.\n",
      " We believe that there is no force more powerful than people taking collective action on the things they care about. We don't pretend to have all the answers, but we know where to find them: in people. We listen, learn, and uncover new insights that often surprise us and our clients — and move us toward better results. Across clients including UNHCR, Amnesty International, Google, Tesco, Nesta, and Tate. We have offices in New York City, Washington DC, London, Oakland and Chicago.\n",
      "\n",
      "\n",
      "Hiring InsightsJob activityPosted 30+ days ago\n",
      "Job detailsJob TypeFull-timeIndeed's salary guideNot provided by employer$106K to $134K per year is Indeed's estimated salary for data engineer in Washington, DC.loading surveyFull Job Description\n",
      "Data EngineerAArete* is one of a kind when it comes to consulting firm culture*.Why AArete?* *We are a fast-growing strategy, operations and technology consulting firm – due to this the bar is set high at AArete. AArete is guided by our deeply embedded principles: Excellence, Passion, Loyalty to Clients, Stewardship, Family, Community, Sustainability, and Inclusion. We strive to continually improve our work environment to allow for high team member engagement and the ability for all team members to be successful.**AArete builds custom software and data analytics for Global 1000 clients in healthcare, transportation & logistics, retail, financial services, and other industries. We hire talented technologists who share our drive to extract insight from information.\n",
      "A career at AArete provides variety, challenge, and opportunity for advancement. You’ll be entrusted with the success of our strategic clients and the company’s growth each and every day. We believe that any organization can succeed by enriching and empowering its people.\n",
      "*Exciting variety of clients and business challenges – from the largest firms in the world to the largest health plans in the country to colleges and universities\n",
      "\n",
      "A collaborative culture focused on career and professional development, abundant opportunities with meaningful and impactful experiences.\n",
      "Competitive Pay and Benefits – competitive salary, unlimited PTO, 401K match, Employee Stock Ownership Plan\n",
      "\n",
      "At AArete we’re successfully embracing working in a flexible work environment. We have offices across the globe in Chicago, New York, Los Angeles, Dallas, Denver, DC, London and India. Based on preference, AAretians have the opportunity to work remotely, visit nearby offices or client locations.AArete is proud to have earned a Great Place to Work Certification™. We are named in Vault’s Top 50 Firms to Work For, Crain's Chicago Business Fast 50 for a 3rd year, Inc 5000’s Fastest Growing Firms list for 4 consecutive years, Consulting Magazine's Fastest Growing Firms for the 4 consecutive years, and Forbes Magazine’s Best Consulting Firms in America list of 2021.Work you’ll do\n",
      "*Responsible for discussing data extraction needs and ensuring that data extracted meets the needs of the application in order to process it\n",
      "\n",
      "Responsible for validating that data ingested by connectors created by Java/Kafka Developers is ingested correctly and makes sense from a business perspective\n",
      "Work with the account teams to ensure that after initial data is ingested, that data being displayed in the application appears appropriate and explores any anomalies that may exist\n",
      "Design and document data pipelines/transformations required for each unique account connector\n",
      "\n",
      "*Requirements*\n",
      "*An ability to learn and understand data schema and how data is processed\n",
      "\n",
      "An understanding of how data designs work well with product\n",
      "An ability to interact with and understand data extraction pipelines, to suggest changes to meet product requirement needs\n",
      "Jupyter Labs\n",
      "Python\n",
      "OpenAPI\n",
      "JUnit\n",
      "Pytest\n",
      "JMeter\n",
      "SQL\n",
      "\n",
      "*Nice to Have*\n",
      "\n",
      "PySpark\n",
      "ServiceNow\n",
      "Experience with design and documentation of ETL pipelines\n",
      "\n",
      "Job Type: Full-time\n",
      "Hiring InsightsJob activityPosted 30+ days ago\n",
      "Job detailsSalary$130,000 - $160,000 a yearJob TypeFull-timeQualificationsUS work authorization (Required)Spark: 3 years (Preferred)Python: 2 years (Preferred)Hadoop: 3 years (Preferred)Full Job Description\n",
      "Job Description: \n",
      "In this role, you will be responsible for developing ETL processes for on-prem Hadoop and AWS technologies.\n",
      "You will address data migration issues, including validation, clean-up, and gaps, and must understand the importance of data dictionaries.\n",
      "Responsibilities: \n",
      "\n",
      "Design and develop ongoing data ingestion using Python and Spark.\n",
      "Use programming skills to create big data pipelines that can deal with both structured and unstructured data.\n",
      "Support other teams by effectively using big data tools and providing guidance for writing efficient code in SQL, Python, and/or R.\n",
      "Analyze and load data for use by a larger audience.\n",
      "Analyze databases to improve data access speed.\n",
      "Analyze data provided by project consultants and make it available in our database\n",
      "Develop strategies for data acquisitions, archive, recovery, and database implementation.\n",
      "Prepare data for econometricians for further statistical analysis.\n",
      "Design and develop databases, data warehouses, and multidimensional databases.\n",
      "Lead and direct data management work of others as applicable.\n",
      "\n",
      "Qualifications: \n",
      "\n",
      "Bachelor’s degree required.\n",
      "1-3 yrs of experience with big data tools, including Apache Spark or Hadoop.\n",
      "2+ years of developing data ingestion and transformation processes associated with big data technologies (e.g., Hadoop, Spark, SQL, etc.)\n",
      "Hands-on Python, SQL, and/or R coding experience.\n",
      "Experience with data modeling concepts.\n",
      "Experience troubleshooting Spark-related failures.\n",
      "Previous experience working with cloud (e.g., AWS) is a plus.\n",
      "Experience with object-oriented scripting languages: Python (preferred) and/or Java.\n",
      "Data tools knowledge, including hands-on experience with ETL (Extract-Transform-Load) software products.\n",
      "Experience with Databricks is a plus.\n",
      "Experience with performance tuning of ETL jobs.\n",
      "Experience with data modeling, integration, and warehousing.\n",
      "Ability to communicate technical issues to non-technical staff.\n",
      "Ability to think laterally with a wide degree of creativity.\n",
      "May require more than 40 hours per week to perform the essential duties of the position.\n",
      "\n",
      "Benefits: \n",
      "\n",
      "Competitive compensation and benefits including flexible work schedules, tuition reimbursement up to $50,000, low healthcare premiums, and much more!\n",
      "Open culture where your voice is heard, your input is sought, and your contributions are rewarded.\n",
      "Fun and engaging culture including frequent social events.\n",
      "Amenities including standing desks, fitness center, rooftop terrace, espresso, fresh fruit, pool table, and table tennis.\n",
      "Employee-driven community outreach featuring fundraising events (e.g., trivia, game shows, cooking competitions, etc.), volunteer opportunities, and matching funds.\n",
      "Investment in your career through training programs, assigned mentor and peer coach, and frequent feedback.\n",
      "Networking opportunities through employee interest groups, Women’s Network, International Network, and Diversity-Inclusion Council.\n",
      "\n",
      "Job Type: Full-time\n",
      "Pay: $130,000.00 - $160,000.00 per year\n",
      "Benefits:\n",
      "\n",
      "401(k)\n",
      "Dental insurance\n",
      "Health insurance\n",
      "Paid time off\n",
      "Tuition reimbursement\n",
      "Vision insurance\n",
      "\n",
      "Schedule:\n",
      "\n",
      "8 hour shift\n",
      "\n",
      "Experience:\n",
      "\n",
      "Spark: 3 years (Preferred)\n",
      "Working with Large Data: 2 years (Preferred)\n",
      "Troubleshooting and backend work of Spark: 2 years (Preferred)\n",
      "Python: 2 years (Preferred)\n",
      "Hadoop: 3 years (Preferred)\n",
      "\n",
      "Work Location: One location\n",
      "Hiring InsightsApplication response rate: 74%Hiring 10+ candidates for this roleUrgently hiringJob activityEmployer reviewed job 7 days agoPosted 30+ days ago\n",
      "Job detailsSalary$30 - $40 an hourJob TypeFull-timeContractFull Job Description\n",
      "1-5 years of experience. Provides technical direction and engineering knowledge for communications activities including planning, designing, developing, testing, installing, and maintaining large communications networks.\n",
      "As part of the OCFO technology team, this position is responsible for providing support to internal and remote users by installing, configuring, and upgrading OCFO telecommunication products, including Avaya, CISCO, Aspect Unified Communication, Webex Audio\\Video conferencing, VoiP, SIP, analog lines, eFax, and mobile devices.\n",
      "\n",
      "Serve as the first point of contact for customers seeking Telecom related technical assistance over the phone or email\n",
      "Managing Helpdesk Tickets of Telecom related issues using Zen desk.\n",
      "Configuring new hires user profiles for Voicemail and Display name change on desk phones in timely manner\n",
      "Update Equipment Inventory documentation of the telephony infrastructure and Voice network infrastructure.\n",
      "Perform technology refreshes, mobile devices iOS update in accordance with OCTO AirWatch policy\n",
      "Continually update and enhance your basic skills in hardware, software and systems through your own efforts and client training.\n",
      "Performs all duties in accordance with OCFO policies and procedures\n",
      "Maintain inventories of all OCFO Telecom assets using the FCMS inventory and Verizon Portal to secure assets\n",
      "Participate in the development of the documentation of Telecom infrastructure and practices by providing written and/or verbal communications to effectively maintain a resource of standard practices.\n",
      "Participate in meetings as required and directed to insure clear communication within IT Operations.\n",
      "\n",
      "Troubleshoot mobile devices, Familiar with AirWatch (Workspace One application), Call Center Experience, Strong asset management skill, Troubleshoot softphone configuration, Manage mobile device by updating iOS and monitoring compliance, Troubleshoot data \\ voice port.---------------------------------------------CONTRACT JOB DESCRIPTIONResponsibilities:1. Provides technical direction and engineering knowledge for communications activities including planning, designing, developing, testing, installing, and maintaining large communications networks.2. Ensures that adequate and appropriate planning is provided to direct building architects and planners in building communications spaces and media pathways meet industry standards.3. Develops, operates, and maintains voice, wireless, video, and data communications systems.4. Provides complex engineering or analytical tasks and activities associated with one or more technical areas within the communications function.\n",
      "Minimum Education/Certification Requirements:Bachelor’s degree in IT or related field or equivalent experience\n",
      "Job Types: Full-time, Contract\n",
      "Pay: $30.00 - $40.00 per hour\n",
      "Schedule:\n",
      "\n",
      "8 hour shift\n",
      "Monday to Friday\n",
      "\n",
      "Experience:\n",
      "\n",
      "Maintaining voice, wireless video, and data comm. systems: 3 years (Required)\n",
      "AirWatch (Workspace One application): 1 year (Required)\n",
      "\n",
      "Work Location: One location\n",
      "Hiring InsightsHiring 1 candidate for this roleJob activityEmployer reviewed job 27 days agoPosted 30 days ago\n",
      "Job detailsJob TypeFull-timeIndeed's salary guideNot provided by employer$109K to $138K per year is Indeed's estimated salary for data engineer in Silver Spring, MD 20910.loading surveyFull Job Description\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Who We Are\n",
      " What makes Discovery Education a GREAT fit for you? We are the global leader in standards-aligned digital curriculum resources, engaging content, and professional learning for K-12 classrooms, and we partner with districts, states, and like-minded organizations to provide teachers with customized solutions that support the success of all learners. When you join the Discovery Education team, you become part of a fast-growing global organization that is empowering educators with the digital tools and professional learning they need to connect students to the real-world.\n",
      " For candidates interested in taking their next career step in the educational technology space, Discovery Education offers the fast pace and excitement of working for a startup, the support of an established organization, and the opportunity to be on the front lines of innovation in an industry that is always growing and transforming. Team members enjoy a high-energy, purpose-driven work environment — as well as tremendous opportunities to grow, learn and make a difference. We are an organization focused on diversity and inclusivity that provides opportunities to engage with people from variety of backgrounds. If you like working with a curious, collaborative, high-performing team, Discovery Education is the place for you.\n",
      "\n",
      " Living Our Values\n",
      " Discovery Education is a company that lives and breathes its Values. By doing so, we position our organization to continue leading the education technology world.\n",
      " Our Values:\n",
      "\n",
      " INNOVATION: We drive a culture of innovation within our organization and with our partners to prepare leaders of tomorrow.\n",
      " CONTINUOUS IMPROVEMENT: We commit to continuous improvement by anticipating and adapting to the changing needs of our partners and the educational landscape.\n",
      " EMPOWERMENT: We empower all learners by providing highly engaging, relevant experiences our partners’ trust.\n",
      " INTEGRITY: We hold ourselves to the highest-standards and conduct ourselves with integrity in all that we do.\n",
      " COMMUNITY: We connect and support our global community of learners.\n",
      " INCLUSIVITY: We strive to build a company with people from diverse backgrounds, so we can better enable all learners to reach their highest potential regardless of race, gender, socio-economic standing, sexual orientation, language, ability, location, or technology.\n",
      "\n",
      "\n",
      " What You’ll Do\n",
      " The Sr. Data Analytics Engineer will blend business acumen with technical expertise and transition between business strategy and data development to support the Growth Analytics team at Discovery Education. This role is critical because it helps connect the business-facing Data Analyst roles with the technology-focused Data Engineering roles by creating data solutions for both. The Analytics Engineer is a specialist in Snowflake and dbt, which Discovery Education has chosen as the standard for developing trusted data models.\n",
      " Responsibilities:\n",
      "\n",
      " Lead marketing and growth attribution modeling efforts making use of marketing, sales, and product data captured from dozens of different systems to support marketing performance analysis.\n",
      " Work collaboratively with data engineers and data scientists to drive business value through turning data models into actionable insights for business stakeholders.\n",
      " Provide clean, transformed data ready for analysis.\n",
      " Apply engineering best practices to analytics code.\n",
      " Maintain data documentation and definitions.\n",
      " Train/support business users on using data visualization tools.\n",
      " Collaborate with team members to collect business requirements, define successful analytics outcomes, and design data models.\n",
      " Craft code that meets our internal standards for style, maintainability, and best practices for a high-scale database environment. Maintain and advocate for these standards through code review.\n",
      " Demonstrated capacity to clearly and concisely communicate complex business activities, technical requirements, and recommendations.\n",
      " Ability to use Snowflake, dbt, Looker, and git.\n",
      " Ability to thrive and work with remote colleagues.\n",
      " Positive and solution-oriented mindset.\n",
      " Be an analyst:\n",
      "       \n",
      " Analyze customer data to generate insights, recommendations, and iterate on the design growth programs.\n",
      " Develop and present standard, management-level reporting and analysis to multiple stakeholders across the organization detailing what we’ve learned from growth experiments.\n",
      " Participate in data governance initiatives to drive consistent and proper handling of data inside the platform and across the business.\n",
      " Assist in overall design of the data capture, application of metadata, and reporting structure.\n",
      " Conduct unit testing and participate with system testing as required.\n",
      " Follow standards and procedures, and complete required documentation of all work.\n",
      " Refine data collection opportunities along the customer journey to inform adjustments to the customer experience and development of buyer and user personas.\n",
      " Analyze data for errors and inconsistencies and participate in analysis of structured and unstructured data.\n",
      "\n",
      "\n",
      "\n",
      " Who You Are\n",
      " Required Skills & Experience:\n",
      "\n",
      " Bachelors or Masters in computer science, mathematics, statistics, information systems, research, business, or a related quantitative field or equivalent work experience.\n",
      " A minimum of 4-5 years’ experience as an analyst, engineer, data scientist or equivalent.\n",
      " 3+ years' experience building reports and dashboards in a data visualization tool.\n",
      " 2+ years managing the same data model system over time, evolving the model to meet new business requirements.\n",
      " 2+ years working with marketing and sales data.\n",
      " 1+ years creating project plans to identify tasks, milestones, and deliverables.\n",
      " Experience using and integrating an end-to-end customer data platform. Segment experience a plus.\n",
      " Experience taking transactional business data, analyzing that data to answer a core research question and using analytics tools and systems to present the findings and insights.\n",
      " Experience analyzing data with R, Python, and SQL.\n",
      " Experience working with data warehouses, data transformation tools, and writing technical documentation for your work. Snowflake and dbt experience a plus.\n",
      " Experience working with APIs to configure integrations for marketing and sales automations.\n",
      " Experience working with very large data volumes (millions of daily events).\n",
      " Demonstrated ability to learn new systems quickly and master data integrity among multiple systems.\n",
      " Must have strong interpersonal skills – collaboration across multiple business and technology. functions, relationship building and consensus building are a must.\n",
      " Must be able to work on and prioritize multiple tasks while working well under pressure.\n",
      " Always willing to learn something new, not rigid in beliefs or expectations.\n",
      " Have a demonstrated ability to understand, accept and engage with people of diverse backgrounds.\n",
      " A sense of humor because we all need to laugh sometimes.\n",
      " Legal right to work in the United States.\n",
      "\n",
      " Discovery Education is an equal opportunity employer. Discovery Education is committed to being an employer of choice, not just a good place to work, but a great and inclusive place to work. To that end, we strive to recruit and maintain a workforce that meaningfully represents the diverse and culturally rich communities that we serve. Qualified applicants will receive consideration for employment without regard to their race, color, religion, national origin, sex, sexual orientation, gender identity, protected veteran status or disabled status or, genetic information.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hiring InsightsJob activityPosted 30+ days ago\n",
      "Job detailsJob TypeFull-timeIndeed's salary guideNot provided by employer$89.4K to $113K per year is Indeed's estimated salary for data engineer in Reston, VA.loading surveyFull Job Description\n",
      "Graduate Management Admission Council (GMAC) seeks a Data Engineer to develop data solutions that are used by the business for analysis and for the development of data-centric products and services.\n",
      "If you have experience using relational databases, such as SQL Server, experience using and configuring data integration (ETL/ELT) tools, such as MuleSoft, and hands-on software development experience using a programming language such as Java or C#, this may be the role for you!\n",
      "The Impact You Will Have\n",
      "You will be responsible for the design, acquisition, transformation, cleansing and maintenance of quality data solutions.\n",
      "Key Things You Will Be Doing\n",
      "\n",
      "Work with cross-discipline teams to ensure the connectivity and flow of data between various data sources within the enterprise and with external partners.\n",
      "Build and maintain data pipelines using ETL tools, such as MuleSoft, in order to integrate disparate data sources at GMAC.\n",
      "Integrate with internal and external APIs, Web Services, flat files, or other data sources.\n",
      "Work with data consumers in the business to improve functionality and quality of data assets.\n",
      "Implement real-time data solutions that improve our customers’ interactions with our digital tools.\n",
      "Other responsibilities and duties, as assigned.\n",
      "\n",
      "What You Bring\n",
      "\n",
      "Bachelor’s degree in a quantitative or scientific field such as computer science, computer engineering, or data analytics; Or equivalent combination of education, skills, and experience.\n",
      "3 years’ experience in a similar role.\n",
      "3 years’ hands on software development experience, using a programming language such as Java or C#.\n",
      "3 years’ experience using relational databases, such as SQL Server.\n",
      "3 years’ experience using and configuring data integration (ETL/ELT) tools, such as MuleSoft.\n",
      "3 years of working in a development team, using Agile methodologies.\n",
      "Ability to prioritize work to resolve operational or departmental issues.\n",
      "Ability to work independently with minimal supervision and in a team setting, and across external and internal stakeholder groups.\n",
      "Excellent analytical, verbal, and written communication skills; Strong attention to detail, with a keen focus on quality.\n",
      "Experience profiling applications, including threading issues and examining thread dumps.\n",
      "Comfort with multi-tasking.\n",
      "Ability to work in-office and remotely according to GMAC’s hybrid work environment.\n",
      "\n",
      "What We Offer\n",
      "\n",
      "Comprehensive and locally competitive benefits (medical, dental, vision, 403b retirement program, and more!)\n",
      "Generous Paid-time Off\n",
      "Holiday Leave\n",
      "Hybrid Work Environment\n",
      "Free parking\n",
      "Opportunity to utilize your skills and professionally grow and develop\n",
      "\n",
      "If you're committed to Career Excellence and want to work in a collegial, collaborative environment, this is the place for you!\n",
      "FLSA Status: ExemptReport to: Senior Director, Application Development and Integration\n",
      "GMAC’s value proposition offers our talented employees the ideal climate for innovation, and colleagues who are motivated and proactive, with diverse backgrounds and approaches.\n",
      "As a global organization, we understand and appreciate the benefits of myriad cultural perspectives. GMAC is wholly committed to recruiting, developing, and retaining a diverse group of talented people, and providing equal employment opportunities to all employees and applicants without regard to the basis of actual or perceived race, creed, color, religion, national origin, ancestry, age, disability, sex (including pregnancy, childbirth, and related medical conditions), marital status, veteran status, sexual orientation, gender identity, genetic information, or any other characteristic protected by applicable federal, state or local laws.\n",
      "Additionally, to ensure a safe office environment, recognizing the tremendous contributions that vaccinations play in ensuring our mutual wellbeing, GMAC has implemented a mandatory vaccination policy. All employees must be fully vaccinated against the COVID-19 virus. GMAC may make accommodations or allow for exemption from this requirement for medical or religious reasons.\n",
      "Job Type: Full-time\n",
      "Hiring InsightsJob activityPosted 27 days ago\n",
      "Indeed's salary guideNot provided by employer$123K to $156K per year is Indeed's estimated salary for cloud engineer in Silver Spring, MD.loading surveyTitle: Sr. AWS Data Engineer\n",
      "\n",
      "Location: Remote\n",
      "\n",
      "\n",
      "Who We Are:\n",
      "\n",
      "Rackner is a software consultancy that builds cloud-native solutions for startups, enterprises, and the public sector. We are an energetic, growing consultancy with a passion for solving big problems for both startups and enterprises. We are always learning and incorporating new things. We stay on the bleeding edge, appraising new technologies and incorporating them if they provide additional value to our customers. Our customers hail from a diverse, ever growing list of industries. We work with small startups, hypergrowth companies, and some of the largest enterprises.\n",
      "\n",
      "\n",
      "Essential Functions:\n",
      "\n",
      "Experience developing cloud-based software services and solutions.\n",
      "Experience creating and driving large scale ETL pipelines in AWS based environment.\n",
      "Experience with integration of data from multiple data sources.\n",
      "Experience creating and driving large scale big data analytics pipelines.\n",
      "Strong software development and programming skills with focus on data using Java, Python or other object-oriented languages.\n",
      "Must Have Python.\n",
      "Strong software development and programming skills using Python(PySpark)\n",
      "Experience with AWS big data technologies : S3, Glue, EMR, Kinesis, RDS, Redshift, Athena\n",
      "Experience with Hadoop and Apache Spark cluster and management\n",
      "Strong SQL and database development skills, using RDBMS such as MySQL, PostgreSQL, AWS RDS\n",
      "Experience with NoSQL databases such as AWS DynamoDB\n",
      "AWS Services:EC2, S3, RDS, RedShift, KMS, Athena, Glue, Elastic Search, Lambda and EMR\n",
      "Must Have: Python, AWS\n",
      "\n",
      "\n",
      "Core Competencies:\n",
      "\n",
      "Customer Service\n",
      "Building Relationships\n",
      "Business Knowledge / Organizational Acumen\n",
      "Self-Motivation/Self Starter\n",
      "Leading Self and Others\n",
      "\n",
      "\n",
      "Benefits:\n",
      "\n",
      "401K with employer matching 100 percent up to 6 percent of employee 401K contribution\n",
      "15 Days PTO (Paid Time Off) prorated based on your start date\n",
      "10 Days Holidays\n",
      "Health insurance (medical, dental and vision)\n",
      "Basic Life Insurance, Short-Term and Long-Term Disability\n",
      "Weekly Pay schedule (Fridays)\n",
      "\n",
      "\n",
      "Rackner provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.Hiring InsightsJob activityPosted 27 days ago\n",
      "Job detailsSalary$90,000 a yearJob TypeFull-timeFull Job Description\n",
      "WASHINGTON, DC - REMOTE FLEXIBILITY /DATA SCIENCE /FULL TIME\n",
      "At MissionWired, we help clients create revolutionary digital strategies that advance their mission, change our country, and have a positive impact on the world.\n",
      "We’re digital-obsessed, tech-savvy do-gooders who care deeply about social change. We’ve brought digital strategies to life for nonprofit organizations working around the world, including Save the Children, Sandy Hook Promise, and Friends of the Earth, as well as progressive political organizations, campaigns and candidates. This cycle, we're excited to support the DGA in flipping and protecting governorships across the country while expanding the Democratic majority in the Senate via our work with the DSCC, Sen. Raphael Warnock, Rep. Val Demings, Sen. Catherine Cortez Masto and Sen. Maggie Hassan.\n",
      "We’re an equal-opportunity employer and take seriously our commitment to equality and equity. Our efforts to be inclusive and create opportunity don’t end when someone joins us – they begin.\n",
      "We’ve set our sights on changing the world through our work and with our clients, and representation is at the foundation of what we do. We know that diversity of thought and background makes us stronger. That’s why we’re committed to building and maintaining a diverse community.\n",
      "Every new team member broadens our perspective and allows us to think bigger. We’ll be at our best when people from underrepresented communities and people with a range of perspectives and lived experiences want to come, stay, and push the boundaries of what’s possible.\n",
      "*Overview: * We are looking for a Principal Data Engineer to transform millions of data points into unparalleled opportunities – supporting everything from electing Democrats to combating climate change throughout the world. With us, you’ll put your skills to use for disruptive innovation that powers social good. You’ll do it as part of a team of analysts and data scientists developing first-of-their-kind strategies and creating new products. Join us. Let’s go.\n",
      "You will be responsible for: \n",
      "\n",
      "Building data-intensive applications to extract, transform, and load massive data sets from a variety of internal, external, and public data sources;\n",
      "Assembling large and complex data sets that meet project needs;\n",
      "Developing processes for data mining, data modeling, and data production;\n",
      "Using an array of technological languages and tools to connect systems;\n",
      "Developing robust testing and monitoring systems for scheduled processes;\n",
      "Collaborating with cross-functional teams to support their data infrastructure needs.\n",
      "\n",
      "Must-have qualifications: \n",
      "\n",
      "Experience with one or more key data analytics tools: (pandas, PySpark)\n",
      "Experience extracting data from public APIs;\n",
      "Ability to build and optimize data pipelines, architectures, and data sets;\n",
      "Experience managing big data resources through Amazon Web Services or another cloud provider;\n",
      "Experience with SQL;\n",
      "Attention to detail;\n",
      "Intellectual curiosity to innovate on ways to solve data management issues;\n",
      "Passion, energy, and excitement for progressive and philanthropic causes and all things digital.\n",
      "\n",
      "Nice-to-have qualifications: \n",
      "\n",
      "5+ years of professional experience;\n",
      "Experience building data-intensive applications that collect data from diverse sources in the service of creating high-performance algorithms and predictive models;\n",
      "Experience building and deploying deep-learning models;\n",
      "Experience managing data warehouses and/or data lakes;\n",
      "Experience working with cross-functional teams in a dynamic environment.\n",
      "\n",
      "We are looking for candidates in a range of seniority levels, including very experienced engineers. The salary floor for this role is $90,000 per year and goes up depending on experience.\n",
      "If you feel you can do the job and are excited about this opportunity but are not sure if you meet all the qualifications, consider applying anyway. We’d love to hear from you!\n",
      "Job Type: Full-time\n",
      "Hiring InsightsJob activityPosted 30+ days ago\n",
      "Job detailsJob TypeFull-timeFull Job Description\n",
      "\n",
      "Data Analytics Engineer \n",
      "\n",
      " Do you want to build your brand by working for a leading consulting firm that drives eminence in the marketplace? Are you interested in leveraging your analytical skills and strategic ideas to improve mission execution? If so, Deloitte could be the place for you! Our Government and Public Services Strategy and Analytics team brings deep industry expertise, rigorous analytical capabilities and a pragmatic mindset to help solve our client's most complex business problems. Join our team and play a key role in helping to design our clients' roadmap to the future and help transform the Federal marketplace. \n",
      "  \n",
      "\n",
      "Work you'll do \n",
      "\n",
      " The Data Analytics Architect will have overall responsibility of planning how work within different teams will integrate into one solution. The Data Analytics Architect will also have overall responsibility of being the primary representative on all architecture matters and the leading member of the Architecture Team. The Architect will: \n",
      "  \n",
      "\n",
      "Work closely with various software development team(s) to migrate and architect data to meet client needs \n",
      "Work directly with clients to validate migrated data \n",
      "Work with Agile development teams to understand changes and their impacts towards data migration efforts \n",
      "Leading developers, managing database administrators' workload and activities, among other tasks. \n",
      "Create and manage schedules for data management (e.g. migration, integration, etc.) efforts \n",
      "Build processes and scripts required to transform and stage data necessary to develop products and analyses \n",
      "\n",
      "\n",
      "\n",
      "The team \n",
      "\n",
      " Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise. \n",
      "  \n",
      " The GPS Analytics and Cognitive (A&C) offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights. \n",
      "  \n",
      "\n",
      "Qualifications \n",
      "\n",
      " Required: \n",
      "  \n",
      "\n",
      "\n",
      "Ability to obtain and maintain a government security clearance \n",
      "\n",
      "\n",
      "\n",
      "2+ years of hands-on experience with ETL/data pipeline development experience, leveraging industry-standard tools, ideally Informatica \n",
      "\n",
      "\n",
      "\n",
      "2+ years of experience working with relational databases and data lakes, with an emphasis on data warehousing, performance tuning, and analytics use cases \n",
      "Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future. \n",
      "\n",
      "\n",
      " Preferred: \n",
      "  \n",
      "\n",
      "\n",
      "Experience integrating them into custom web applications \n",
      "\n",
      "\n",
      "\n",
      "Data modeling and solution design experience \n",
      "\n",
      "\n",
      "\n",
      "Familiarity programming in languages commonly used for data management and data science/statistics, such as Python \n",
      "\n",
      "\n",
      "\n",
      "Excellent problem identification, analysis and solving skills; an innate ability to utilize all resources at your disposal to find a creative solution to a problem, whether business/functional or technical in nature \n",
      "\n",
      "\n",
      "\n",
      "A desire to take initiative and continuously work on improving the products you are responsible for \n",
      "\n",
      "\n",
      "\n",
      "A general interest in relevant emerging technologies such as cloud-native services, and a constant thirst to further your own technical abilities \n",
      "\n",
      "\n",
      "\n",
      "Experience working in an Agile development environment \n",
      "\n",
      "\n",
      "\n",
      "Hands-on experience with full suite of software lifecycle tools (Confluence, Jira, Stash, Jenkins, Artifactory, etc.) \n",
      "\n",
      "\n",
      "\n",
      "The ability to work well independently and as a team player \n",
      "\n",
      "\n",
      "\n",
      "Excellent conversational and written communication skills \n",
      "\n",
      "\n",
      "How you'll grow \n",
      "\n",
      " At Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there's always room to learn. We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs at Deloitte University, our professionals have a variety of opportunities to continue to grow throughout their career. Explore Deloitte University, The Leadership Center. \n",
      "  \n",
      "\n",
      "Benefits \n",
      "\n",
      " At Deloitte, we know that great people make a great organization. We value our people and offer employees a broad range of benefits. Learn more about what working at Deloitte can mean for you. \n",
      "  \n",
      "\n",
      "Deloitte's culture \n",
      "\n",
      " Our positive and supportive culture encourages our people to do their best work every day. We celebrate individuals by recognizing their uniqueness and offering them the flexibility to make daily choices that can help them to be healthy, centered, confident, and aware. We offer well-being programs and are continuously looking for new ways to maintain a culture where our people excel and lead healthy, happy lives. Learn more about Life at Deloitte. \n",
      "  \n",
      "\n",
      "Corporate citizenship \n",
      "\n",
      " Deloitte is led by a purpose: to make an impact that matters. This purpose defines who we are and extends to relationships with our clients, our people and our communities. We believe that business has the power to inspire and transform. We focus on education, giving, skill-based volunteerism, and leadership to help drive positive social impact in our communities. Learn more about Deloitte's impact on the world. \n",
      "  \n",
      "\n",
      "Recruiter tips \n",
      "\n",
      " We want job seekers exploring opportunities at Deloitte to feel prepared and confident. To help you with your interview, we suggest that you do your research: know some background about the organization and the business area you're applying to. Check out recruiting tips from Deloitte professionals.\n",
      " \n",
      "Hiring InsightsJob activityPosted 16 days ago\n",
      "Job detailsSalary$90,000 a yearJob TypeFull-timeFull Job Description\n",
      "WASHINGTON, DC - REMOTE FLEXIBILITY /DATA SCIENCE /FULL TIME\n",
      "At MissionWired, we help clients create revolutionary digital strategies that advance their mission, change our country, and have a positive impact on the world.\n",
      "We’re digital-obsessed, tech-savvy do-gooders who care deeply about social change. We’ve brought digital strategies to life for nonprofit organizations working around the world, including Save the Children, Sandy Hook Promise, and Friends of the Earth, as well as progressive political organizations, campaigns and candidates. This cycle, we're excited to support the DGA in flipping and protecting governorships across the country while expanding the Democratic majority in the Senate via our work with the DSCC, Sen. Raphael Warnock, Rep. Val Demings, Sen. Catherine Cortez Masto and Sen. Maggie Hassan.\n",
      "We’re an equal-opportunity employer and take seriously our commitment to equality and equity. Our efforts to be inclusive and create opportunity don’t end when someone joins us – they begin.\n",
      "We’ve set our sights on changing the world through our work and with our clients, and representation is at the foundation of what we do. We know that diversity of thought and background makes us stronger. That’s why we’re committed to building and maintaining a diverse community.\n",
      "Every new team member broadens our perspective and allows us to think bigger. We’ll be at our best when people from underrepresented communities and people with a range of perspectives and lived experiences want to come, stay, and push the boundaries of what’s possible.\n",
      "*Overview: * We are looking for a Principal Data Engineer to transform millions of data points into unparalleled opportunities – supporting everything from electing Democrats to combating climate change throughout the world. With us, you’ll put your skills to use for disruptive innovation that powers social good. You’ll do it as part of a team of analysts and data scientists developing first-of-their-kind strategies and creating new products. Join us. Let’s go.\n",
      "You will be responsible for: \n",
      "\n",
      "Building data-intensive applications to extract, transform, and load massive data sets from a variety of internal, external, and public data sources;\n",
      "Assembling large and complex data sets that meet project needs;\n",
      "Developing processes for data mining, data modeling, and data production;\n",
      "Using an array of technological languages and tools to connect systems;\n",
      "Developing robust testing and monitoring systems for scheduled processes;\n",
      "Collaborating with cross-functional teams to support their data infrastructure needs.\n",
      "\n",
      "Must-have qualifications: \n",
      "\n",
      "Experience with one or more key data analytics tools: (pandas, PySpark)\n",
      "Experience extracting data from public APIs;\n",
      "Ability to build and optimize data pipelines, architectures, and data sets;\n",
      "Experience managing big data resources through Amazon Web Services or another cloud provider;\n",
      "Experience with SQL;\n",
      "Attention to detail;\n",
      "Intellectual curiosity to innovate on ways to solve data management issues;\n",
      "Passion, energy, and excitement for progressive and philanthropic causes and all things digital.\n",
      "\n",
      "Nice-to-have qualifications: \n",
      "\n",
      "5+ years of professional experience;\n",
      "Experience building data-intensive applications that collect data from diverse sources in the service of creating high-performance algorithms and predictive models;\n",
      "Experience building and deploying deep-learning models;\n",
      "Experience managing data warehouses and/or data lakes;\n",
      "Experience working with cross-functional teams in a dynamic environment.\n",
      "\n",
      "We are looking for candidates in a range of seniority levels, including very experienced engineers. The salary floor for this role is $90,000 per year and goes up depending on experience.\n",
      "If you feel you can do the job and are excited about this opportunity but are not sure if you meet all the qualifications, consider applying anyway. We’d love to hear from you!\n",
      "Job Type: Full-time\n",
      "Hiring InsightsJob activityPosted 30+ days ago\n",
      "Job detailsJob TypeFull-timeFull Job Description\n",
      "\n",
      "\n",
      "   Job Description\n",
      "  \n",
      "\n",
      " The Elevator Pitch: Why will you enjoy this new opportunity?\n",
      " VMware, the global leader in virtualization and cloud infrastructure, delivers customer-proven solutions that accelerate IT by reducing complexity and enabling more flexible, agile service delivery. A socially responsible company with a vision to imagine, design, and create a better world who is also recognized as top places to work for in Silicon Valley. We are looking for talented Data Engineer who is excited about redefining, reimagining, and contributing towards building a modern data infrastructure. We believe data engineering is about harnessing the power of data, built on solid foundation of software engineering, data modeling, devops skills & more. We recognize that you may have varied mix of skills, experiences & strengths, be it, big data, cloud data warehouse, stream processing or data modeling. We want to talk to you.\n",
      " Success in the Role: What are the performance goals over the first 6-12 months you will work toward completing? \n",
      "As a Data Engineer, you will build end-to-end analytical solutions that are highly scalable, performant, secure, and resilient. You rely on sound judgement, critical thinking, and creativity to deliver customer-focused data solutions that create meaningful business impact. You are experienced with various patterns of data ingestion, processing, and curation. You understand criticality of data quality, security & governance practices and are adept at it. You design solutions with strategic and long-term focus on code quality, reliability, reusability, maintainability and dataops. You are experienced in building efficient and scalable data services.\n",
      "\n",
      " What type of work will you be doing? What assignments, requirements, or skills will you be performing on a regular basis? \n",
      "\n",
      "Work closely with Product owners/ Leads to understand the business requirements and convert them into Technical stories\n",
      " Hands-on development work on all aspects of data analysis, data provisioning, modeling, performance tuning, and optimization.\n",
      " Design, implement and operate large-scale, high-volume, high-performance data structures for analytics\n",
      " Build solutions in Hadoop - HDFS, Hive, Sqoop, Spark, Kafka, MongoDB, Python\n",
      " Perform data analysis using Python, complex SQLs, and other tools.\n",
      " Data analysis in a wide variety of database technologies, from relational databases like Postgres, Oracle to NoSQL systems such as MongoDB, Elasticsearch, and can explain their varied use cases\n",
      " Build scalable data pipelines for both real time and batch using best practices in data modeling, ETL/ELT processes utilizing various technologies such as Spark, Kafka, Python, Airflow, Informatica.\n",
      " Understanding of any of the data visualizations & reporting tools like Tableau, SAP BOBJ and other open-source technologies.\n",
      " Perform root cause analysis of issues that hinder the data quality. Work with data source owner to increase quality and accuracy of the source data.\n",
      " Understand and influence best practices for observability & dataops.\n",
      " Help continually improve ongoing reporting and analysis processes, automating or simplifying self-service modeling and production support for customers.\n",
      " Collaborate with engineers to drive best practices in code quality & reusability, data integrity, test design, analysis, validation, and documentation\n",
      "\n",
      " What is the leadership like for this role? What is the structure and culture of the team like?\n",
      " You will be joining the Data team, comprised of 90+ engineers spread throughout VMware offices including Palo Alto, CA, Austin, TX, India, and Costa Rica. This Data Engineer role will report to one of the leaders in the Data Engineering & Analytics team with extensive experience and business domain knowledge. The team culture is based on building trust, on-going development through coaching, and giving back to the community through service learning. We believe in creating a psychologically safe and inclusive workplace and building compassionate relationships with the people we work with.\n",
      " “This job requisition is not eligible for employment-based immigration sponsorship by VMware.”\n",
      " What are the benefits and perks of working at VMware?\n",
      " You and your loved ones will be supported with a competitive and comprehensive benefits package. Below are some highlights, or you can view the complete benefits package by visiting www.benefits.vmware.com.\n",
      "\n",
      " Employee Stock Purchase Plan\n",
      " Medical Coverage, Retirement, and Parental Leave Plans for All Family Types\n",
      " Generous Time Off Programs\n",
      " 40 hours of paid time to volunteer in your community\n",
      " Rethink's Neurodiversity program to support parents raising children with learning or behavior challenges, or developmental disabilities\n",
      " Financial contributions to your ongoing development (conference participation, trainings, course work, etc.)\n",
      " Healthy and local inspired snacks in all our on-site pantries\n",
      "\n",
      "\n",
      " This job may require the candidate to comply with travel restrictions and/or work from a facility that requires full vaccination prior to entry.\n",
      " Category : Engineering and Technology Subcategory: Software Engineering Experience: Manager and Professional Full Time/ Part Time: Full Time Posted Date: 2022-04-01\n",
      " VMware Company Overview: At VMware, we believe that software has the power to unlock new opportunities for people and our planet. We look beyond the barriers of compromise to engineer new ways to make technologies work together seamlessly. Our cloud, mobility, and security software form a flexible, consistent digital foundation for securely delivering the apps, services and experiences that are transforming business innovation around the globe. At the core of what we do are our people who deeply value execution, passion, integrity, customers, and community. Shape what’s possible today at http://careers.vmware.com.\n",
      "  \n",
      " Equal Employment Opportunity Statement: VMware is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: VMware is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at VMware are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. VMware will not tolerate discrimination or harassment based on any of these characteristics. VMware encourages applicants of all ages. Vmware will provide reasonable accommodation to employees who have protected disabilities consistent with local law.\n",
      " \n",
      "Hiring InsightsJob activityPosted 30+ days ago\n",
      "Job detailsJob TypeFull-timeFull Job Description\n",
      "\n",
      "Data Analytics Engineer \n",
      "\n",
      " Do you want to build your brand by working for a leading consulting firm that drives eminence in the marketplace? Are you interested in leveraging your analytical skills and strategic ideas to improve mission execution? If so, Deloitte could be the place for you! Our Government and Public Services Strategy and Analytics team brings deep industry expertise, rigorous analytical capabilities and a pragmatic mindset to help solve our client's most complex business problems. Join our team and play a key role in helping to design our clients' roadmap to the future and help transform the Federal marketplace. \n",
      "  \n",
      "\n",
      "Work you'll do \n",
      "\n",
      " The Data Analytics Architect will have overall responsibility of planning how work within different teams will integrate into one solution. The Data Analytics Architect will also have overall responsibility of being the primary representative on all architecture matters and the leading member of the Architecture Team. The Architect will: \n",
      "  \n",
      "\n",
      "Work closely with various software development team(s) to migrate and architect data to meet client needs \n",
      "Work directly with clients to validate migrated data \n",
      "Work with Agile development teams to understand changes and their impacts towards data migration efforts \n",
      "Leading developers, managing database administrators' workload and activities, among other tasks. \n",
      "Create and manage schedules for data management (e.g. migration, integration, etc.) efforts \n",
      "Build processes and scripts required to transform and stage data necessary to develop products and analyses \n",
      "\n",
      "\n",
      "\n",
      "The team \n",
      "\n",
      " Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise. \n",
      "  \n",
      " The GPS Analytics and Cognitive (A&C) offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights. \n",
      "  \n",
      "\n",
      "Qualifications \n",
      "\n",
      " Required: \n",
      "  \n",
      "\n",
      "\n",
      "Ability to obtain and maintain a government security clearance \n",
      "\n",
      "\n",
      "\n",
      "2+ years of hands-on experience with ETL/data pipeline development experience, leveraging industry-standard tools, ideally Informatica \n",
      "\n",
      "\n",
      "\n",
      "2+ years of experience working with relational databases and data lakes, with an emphasis on data warehousing, performance tuning, and analytics use cases \n",
      "Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future. \n",
      "\n",
      "\n",
      " Preferred: \n",
      "  \n",
      "\n",
      "\n",
      "Experience integrating them into custom web applications \n",
      "\n",
      "\n",
      "\n",
      "Data modeling and solution design experience \n",
      "\n",
      "\n",
      "\n",
      "Familiarity programming in languages commonly used for data management and data science/statistics, such as Python \n",
      "\n",
      "\n",
      "\n",
      "Excellent problem identification, analysis and solving skills; an innate ability to utilize all resources at your disposal to find a creative solution to a problem, whether business/functional or technical in nature \n",
      "\n",
      "\n",
      "\n",
      "A desire to take initiative and continuously work on improving the products you are responsible for \n",
      "\n",
      "\n",
      "\n",
      "A general interest in relevant emerging technologies such as cloud-native services, and a constant thirst to further your own technical abilities \n",
      "\n",
      "\n",
      "\n",
      "Experience working in an Agile development environment \n",
      "\n",
      "\n",
      "\n",
      "Hands-on experience with full suite of software lifecycle tools (Confluence, Jira, Stash, Jenkins, Artifactory, etc.) \n",
      "\n",
      "\n",
      "\n",
      "The ability to work well independently and as a team player \n",
      "\n",
      "\n",
      "\n",
      "Excellent conversational and written communication skills \n",
      "\n",
      "\n",
      "How you'll grow \n",
      "\n",
      " At Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there's always room to learn. We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs at Deloitte University, our professionals have a variety of opportunities to continue to grow throughout their career. Explore Deloitte University, The Leadership Center. \n",
      "  \n",
      "\n",
      "Benefits \n",
      "\n",
      " At Deloitte, we know that great people make a great organization. We value our people and offer employees a broad range of benefits. Learn more about what working at Deloitte can mean for you. \n",
      "  \n",
      "\n",
      "Deloitte's culture \n",
      "\n",
      " Our positive and supportive culture encourages our people to do their best work every day. We celebrate individuals by recognizing their uniqueness and offering them the flexibility to make daily choices that can help them to be healthy, centered, confident, and aware. We offer well-being programs and are continuously looking for new ways to maintain a culture where our people excel and lead healthy, happy lives. Learn more about Life at Deloitte. \n",
      "  \n",
      "\n",
      "Corporate citizenship \n",
      "\n",
      " Deloitte is led by a purpose: to make an impact that matters. This purpose defines who we are and extends to relationships with our clients, our people and our communities. We believe that business has the power to inspire and transform. We focus on education, giving, skill-based volunteerism, and leadership to help drive positive social impact in our communities. Learn more about Deloitte's impact on the world. \n",
      "  \n",
      "\n",
      "Recruiter tips \n",
      "\n",
      " We want job seekers exploring opportunities at Deloitte to feel prepared and confident. To help you with your interview, we suggest that you do your research: know some background about the organization and the business area you're applying to. Check out recruiting tips from Deloitte professionals.\n",
      " \n",
      "Hiring InsightsJob activityPosted 16 days ago\n",
      "Job detailsJob TypeFull-timeFull Job Description\n",
      " Master Software Engineer II Big Data for Government Employees Insurance Company (GEICO) to work at our Chevy Chase, MD loc. May telecommute up to one day a week and more frequently as necessary. Review & analyze program req’s; code, debug, test & doc programs for int customers, & determine the best approach to create &/or modify programs. Advise int customers as SME on implementing syst’s &/or programming apps. \n",
      " \n",
      " Occasional weekend support. May undergo background checks incl. drug screen and credit check. Requires communication skills. \n",
      " \n",
      " Must have Bach in Comp Sci or rel field and 5 yrs relevant tech exp. Requires the following skills (3 yrs exp): internal and external system design, and working with Spark, Scala, Java, Hadoop, SQL, no-SQL platforms, various data types, and app and tech infrastructure. Apply at geico.com/careers and refer to job R0033802. EOE\n",
      "Hiring InsightsJob activityPosted 20 days ago\n",
      "Indeed's salary guideNot provided by employer$115K to $146K per year is Indeed's estimated salary for data engineer in Washington, DC 20006.loading surveySimple Technology Solutions (STS) is looking for a Data Engineer to add to our team.\n",
      "\n",
      "Quick Position Overview:\n",
      "\n",
      "US Citizenship is required\n",
      "A Bachelor's degree is required\n",
      "5 years' position related experience\n",
      "Microsoft Azure Platform experience\n",
      "\n",
      "The Role:\n",
      "\n",
      "Assigned to the Data and Platform team, this role would be responsible for analyzing and understanding the data and data structure and responsible for creating the ETL scripts for data movement to the new platform.\n",
      "\n",
      "The Data Engineer at STS will:\n",
      "\n",
      "Supports the development, test, and management of cloud environments providing high availability, scalable, fault-tolerant Platform as a Service (PaaS) / Software as a service (SaaS) / Infrastructure as a Service (IaaS) platforms\n",
      "Responsible for organizing and maintaining CI and deployment of solutioning in accordance with governance and business objectives\n",
      "Prepares compute and storage requirements in support of optimized cloud solutions\n",
      "Provides direct support for the planning, designing, and developing infrastructure for cloud-based applications\n",
      "Ensures adherence to the security requirements for all cloud environments\n",
      "\n",
      "Experience and Education:\n",
      "\n",
      "Required\n",
      "\n",
      "US Citizenship\n",
      "A Bachelor's degree in Computer Science, Engineering or related field\n",
      "5years' position related experience\n",
      "Microsoft Azure Platform experience\n",
      "Experience with IaaS, SaaS and PaaS platforms\n",
      "Experience conducting data analysis reports\n",
      "Experience building data systems and pipelines\n",
      "Our Team\n",
      "STS team members are motivated and assist each other in delivering remarkable solutions every day. We are lifelong learners, value outcomes over busy-ness and cultivate collaboration over individual contributions. We have in-depth experience helping government agencies in their installation, configuration, and optimization of leading Agile Software Development, DevOps, and Cloud Migration tools.\n",
      "\n",
      "Our growing team has an exciting startup feel and, in addition to being experienced government contractors, we are experienced coaches and thought-leaders.\n",
      "\n",
      "A Little More About STS\n",
      "STS values innovation in all that we do, value-orientation in all choices and decisions, and has an employee-centric company focus.\n",
      "\n",
      "We have been named a \"Best Place to Work\" by the Washington Business Journal in 2019 and 2021; received the Washington Technology magazine's FAST50 status in 2019; and achieved Inc Magazine's \"Inc 500\" status in 2019 and 2020. We offer best in our industry benefits as well as extensive learning and development opportunities.\n",
      "\n",
      "Our team members value the flexibility STS offers which allows them to balance their personal lives while contributing quality work products. Additionally, the team benefits from our partnerships with AWS, Google, Microsoft and CloudBees – with access to improved knowledge and the opportunity to become a SME with one or more of our above partners.\n",
      "\n",
      "Simple Technology Solutions, Inc. (STS) requires all team members to be fully vaccinated against COVID-19 unless a medical or religious exemption is approved by STS. Being fully vaccinated means that an individual is at least two weeks past their final dose of an authorized COVID-19 vaccine regimen. As a condition of employment, newly hired employees will be required to provide proof of their COVID-19 vaccination OR apply for a religious/medical accommodation prior to the first day of employment. Failure to meet these requirements will affect your employment eligibility with STS.\n",
      "\n",
      "STS is committed to equal employment opportunity. STS provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination, harassment, and retaliation of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, marital status, family responsibilities, matriculation, personal appearance, political affiliation, gender identity or expression, or any other characteristic protected by federal, state or local laws.\n",
      "\n",
      "This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.\n",
      "-\n",
      "Applicants may request removal from our applicant database, or specific information about how the data is used by contacting recruting@simpletechnology.io.Hiring InsightsJob activityPosted today\n",
      "Job detailsJob TypeFull-timeFull Job Description\n",
      "\n",
      "The Cyber Security Cryptography team at GEICO is seeking an experienced Data Encryption Software Engineer with knowledge of and desire to improve element-level data encryption integration layers. This engineer will be part of team supporting the MicroFocus Voltage data encryption solution and will directly support the Data Security Integration tier (Voltage Wrapper). The ideal candidate wants to not only write/support an exceptional and solid software encryption library but also become a domain expert in data-element security and for our Voltage Encryption solution.\n",
      "\n",
      " Responsibilities: Work as a software architect and subject matter expert for the Voltage integration tier (wrapper) Promote software design excellence and focus on integration with systems, policies, and practices. Work with Enterprise Architecture and Application Security to promote data security best practices in code. Work with data governance tools to ease the integration of this tooling into the rest of our data security/governance lifecycle. Develop reference architectures for application security controls to protect data-in-motion, data at rest, and identity and access management. Consult with teams implementing the wrapper when questions arise. Ensure documentation addresses common confusion and issues. Promote consistency and best practices and standards; enhance those best practices and standards, and provide measurable plans to ensure consistency. Manage risk appropriately Take a leadership role in planning and communicating changes to the Data security integration tier and Voltage ecosystem Seek out root cause and correction of errors for operational events. Maintain current understanding of security threats, changing security landscape, technological changes, and emerging trends. Mentor and train peers on operational and technical excellence.  Requirements: 3-5 years experience in application development, data security, or a combination of the two. Bachelor’s Degree in Software Engineer, Computer Science, Cyber Security, or related field or relevant work experience Advanced understanding and experience writing code in either .NET or Java. The ideal candidate has knowledge of multiple programming language paradigms and is comfortable consulting with other teams on their code. Experience with REST APIs, automation frameworks, cloud services, and micro services Experience with infrastructure engineering a plus. Must be highly flexible and adaptable to change\n",
      "\n",
      " Benefits:\n",
      " At GEICO, we make sure you have the support and resources to leverage and develop your skills, secure your financial future, and take care of your health and well-being. GEICO continually seeks to provide a workplace where everyone can be their authentic self. To help achieve this goal, we support associate-led Employee Resource Groups that foster a true sense of community. Through GEICO’s competitive benefits offerings and various training and development opportunities, we have you covered with our Total Rewards Program* that includes:\n",
      "\n",
      " Premier Medical, Dental and Vision Insurance with no waiting period**\n",
      " Paid Vacation, Sick and Parental Leave\n",
      " 401(k) Plan with Profit Sharing\n",
      " Tuition Reimbursement\n",
      " Paid Training and Licensures\n",
      "\n",
      "\n",
      "\n",
      "Benefits may be different by location. Benefit eligibility requirements vary and may include length of service.\n",
      "\n",
      " **Coverage begins with the pay period after hire date. Must enroll in New Hire Benefits within 30 days of the date of hire for coverage to take effect.\n",
      "\n",
      " The safety of our associates, both current and future, is GEICO’s highest priority. At this time, most of our associates are working remotely due to the current COVID-19 pandemic. Candidates who are selected for this position will be trained remotely and must be able to work from home in a designated work area.\n",
      "\n",
      " GEICO is proud to be an equal opportunity employer. We are committed to cultivating an environment where equal employment opportunities are available to all associates and job applicants regardless of race, color, religious creed, national origin, ancestry, age, gender, pregnancy, sexual orientation, gender identity, marital status, familial status, disability or genetic information, in compliance with applicable federal, state and local law. GEICO celebrates diversity and believes it is critical to our success. As such, we are committed to recruit, develop and retain the most talented individuals to join our team.\n",
      " #LI-DP1\n",
      "\n",
      "\n",
      "Hiring InsightsJob activityPosted 5 days ago\n",
      "Job detailsJob TypeFull-timeIndeed's salary guideNot provided by employer$96.4K to $122K per year is Indeed's estimated salary for data engineer in Washington, DC 20004.loading surveyFull Job Description\n",
      "Job Description\n",
      "Data Reporting Engineer\n",
      "Council for Logistics Research, Inc. Vienna, VA\n",
      "Benefits Offered: Medical, Life Insurance, 401k, Dental\n",
      "Employment Type Part or Full-Time\n",
      "Location: Washington, D.C. 2-3 days per week and remote \n",
      "Supervises: No\n",
      "Must be US Citizen and be able to pass a DHS Full Scope Background Investigation\n",
      "Description of Work: \n",
      "Due to our continuous growth on two multi-year contracts within the Office of the Chief Medical Officer at Customs and Border Protection we are seeking a Data Reporting Engineer. The candidate is expected to demonstrate expertise drafting reports using SAP Business Objects, Qlik, and provide information reporting to the functional team supporting the OCMO. The Data Reporting Engineer will support the reporting team by authoring scheduled and ad-hoc reports according to policy and procedural guidance.\n",
      "Duties & Responsibilities: \n",
      "\n",
      "Design and develop complex reports using SAP Business Object, and tools like Web Intelligence.\n",
      "Plan and implement automated bursting of reports via publication services and scheduling.\n",
      "Perform report requirements analysis; provide effort estimation; create dashboards and draft scheduled as well as ad-hoc reports.\n",
      "Comprehensive knowledge of Data Reporting methodologies and deliverables.\n",
      "\n",
      "Required Education, Skills, and Experience: \n",
      "\n",
      "Bachelor’s Degree or higher in a business or technical discipline\n",
      "5+ years of development experience with SAP Business Objects including Web Intelligence, and relevant experience as a Data and Report Engineer\n",
      "Excellent communication and consulting skills with ability to work independently.\n",
      "Strong Knowledge in Qlik\n",
      "Experience with trouble shooting production issues.\n",
      "SAP Business Objects Reporting and Data Visualization experience using Web Intelligence and Dashboards.\n",
      "Expertise in dimensional data modeling and knowledgeable in writing SQL.\n",
      "Good understanding of User Security in Business Objects.\n",
      "Experience with migrating reports and enhancing report performance.\n",
      "\n",
      "CLR and its subcontractors shall abide by the requirements of 41CFR 60-1.4(a), 60-300.5(a) and 60-741.5(a). These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities and prohibit discrimination against all individuals based on their race, color, religion, sex, national origin, sexual orientation, and gender identity. Moreover, these regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sex, national origin, gender identity and sexual orientation, protected veteran status or disability.\n",
      "Job Type: Full-time\n",
      "Benefits:\n",
      "\n",
      "401(k)\n",
      "Dental insurance\n",
      "Health insurance\n",
      "Life insurance\n",
      "Paid time off\n",
      "\n",
      "Schedule:\n",
      "\n",
      "Monday to Friday\n",
      "\n",
      "Supplemental Pay:\n",
      "\n",
      "Bonus pay\n",
      "\n",
      "Work Location: One location\n",
      "Hiring InsightsHiring 1 candidate for this roleUrgently hiringJob activityEmployer reviewed job 6 days agoPosted 23 days ago\n",
      "Indeed's salary guideNot provided by employer$112K to $141K per year is Indeed's estimated salary for data engineer in Washington, DC 20005.loading surveyJob Summary\n",
      "\n",
      "Data Engineer\n",
      "\n",
      "SUMMARY\n",
      "\n",
      "The Data Engineer is responsible for expanding and optimizing the MSRB’s data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.\n",
      "\n",
      "ESSENTIAL DUTIES AND RESPONSIBILITIES\n",
      "\n",
      "Create and maintain optimal data pipeline architecture,\n",
      "Assemble structured, semi-structure and unstructured data sets to meet functional / non-functional business requirements.\n",
      "Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Familiarity DataOps and/or DevOps.\n",
      "Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.\n",
      "Build analytics tools that utilize the data pipeline to provide actionable insights into market insights and transparency, operational efficiency and other key business performance metrics.\n",
      "Work with stakeholders including the Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.\n",
      "Keep our data separated and secure across regional boundaries through multiple data centers and AWS regions.\n",
      "Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.\n",
      "Work with data and analytics experts to strive for greater functionality in our data systems.\n",
      "Other duties as assigned.\n",
      "EDUCATION/QUALIFICATIONS\n",
      "\n",
      "5 years experience in a Data Engineer role. Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytic skills related to working with unstructured datasets. A successful history of manipulating, processing and extracting value from large disconnected datasets. Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores. Strong project management and organizational skills. Experience with AWS cloud services: S3, Athena, Aurora, RDS, Redshift, Glue, Lambda, EventBridge, SQS, SNS. Experience with relational SQL and NoSQL databases, including Postgres and DynamoDB. Experience with scripting languages: Python, R, etc. Experience in AWS Technologies like EMR, S3, Batch ingestion. Experience in debugging and performance tuning of spark jobs. Experience working with multiple file formats especially with Parquet and Avro. Experience implementing Hybrid/Multi Data Warehousing. Experience in microservices APIs.Hiring InsightsJob activityPosted 30+ days ago\n",
      "Job detailsJob TypeContractIndeed's salary guideNot provided by employer$98.1K to $124K per year is Indeed's estimated salary for data engineer in Lanham, MD 20706.loading surveyFull Job Description\n",
      "\n",
      "Role: Data Engineer\n",
      " Location: Lanham, MD\n",
      " Duration: Long term\n",
      "\n",
      "Basic Qualifications:\n",
      "\n",
      "3 years experience with Oracle databases3 years of experience with PLSQLExperience with Agile methods in the development or support of a systemAbility to review and write UNIX Shell ScriptsAbility to obtain a security clearanceBA or BS degree\n",
      "\n",
      "\n",
      "Hiring InsightsJob activityPosted 30+ days ago\n",
      "Job detailsSalary$55 - $60 an hourJob TypeContractFull Job Description\n",
      "\n",
      "\n",
      "Job Overview\n",
      "\n",
      "\n",
      "Short Description\n",
      " Big Data Engineer (Hadoop Java or Spark) Eastern Technology World Wide Solutions, Inc. (VOSB) – Chevy Chase, MD Duration: 2 years+ contract (nice and stable) PHONE and Skype H1B, GC and Citizens Must Speak Well Required SKILLS are in bold. \n",
      "   Detailed Description\n",
      "\n",
      "\n",
      "\n",
      "Location: Chevy Chase, MD\n",
      " Duration: 2 years+ contract (nice and stable)\n",
      " PHONE and Skype H1B, GC and Citizens Must Speak Well Required\n",
      " SKILLS are in bold.\n",
      "\n",
      "Minimum Requirements 3 years of hands-on experience in the Hadoop ecosystem (HDFS, YARN, MapReduce, Oozie, AND Hive)\n",
      "1 year of hands-on experience in Spark core AND Spark SQL\n",
      "5 years of hands-on programming experience in either core Java OR Spark\n",
      "3 years of hands-on experience in Data Warehousing AND Data Marts AND Data/Dimensional Modeling AND ETL\n",
      "1 years of hands-on experience in HBase OR Cassandra OR any other NoSQL DB\n",
      "Understanding of Distributed computing design patterns AND algorithms AND data structures AND security protocols\n",
      "\n",
      "Desired Skills Understanding of Kafka AND Spark Streaming Experience in any one of the ETL tools such as Talend, Kettle, Informatica OR Ab Initio Exposure to Hadoop OR NoSQL performance optimization and benchmarking using tools such as HiBench OR YCSB Experience in performance monitoring tools such as Ganglia OR Nagios OR Splunk OR DynaTrace Experience on continuous build and test process using tools such as Maven AND Jenkins Certification in HortonWorks OR Cloudera preferred- not required but strongly desired\n",
      " Murray Newcomb\n",
      " Technical Laison\n",
      " Eastern Technology World Wide Solutions, Inc. a Certified Veteran Owned Small Business.\n",
      " Unlike so much of the competition, I have a degree in CS and 35 years of UNIX/LINUX experience and might be more technical then most the recruiters you work with.\n",
      " 703-501-8395\n",
      " www.etwws.com\n",
      " Job Type: Contract\n",
      " Salary: $55.00 to $60.00 /hour\n",
      "\n",
      "\n",
      "\n",
      "Application Questions\n",
      " You have requested that Indeed ask candidates the following questions:\n",
      "\n",
      "\n",
      "How many years of Data Warehousing and Big Data Marts and Data/Dimensional experience do you have?\n",
      "How many years of Hadaoop (HDFS, YARN, MapReduce, Oozie, and Hive) experience do you have?\n",
      "How many years of HBase or Cassandra or any other NoSQL DB experience do you have?\n",
      "How many years of Java and or Spark experience do you have?\n",
      "How many years of Spark core and Spark SQL experience do you have?\n",
      "Have you completed the following level of education: Bachelor's?\n",
      "Are you in Chevy Chase, MD?\n",
      "Are you authorized to work in the following country: United States?\n",
      "Do you have the following license or certification: read that as certifications - HortonWorks or Coludera?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hiring InsightsJob activityPosted 30+ days ago\n",
      "Job detailsJob TypeFull-timeIndeed's salary guideNot provided by employer$94.1K to $119K per year is Indeed's estimated salary for data engineer in Washington, DC 20301.loading surveyFull Job Description\n",
      "\n",
      "The Logistics Information Technology Branch (LPI) provides administrative oversight and functional management of USMC Logistics information technology (IT) and data (compliance, governance, and modernization) in order to meet the needs of the Marine Corps in Joint, Coalition, and expeditionary environments also known as Information Technology Portfolio Management (IT PfM).\n",
      " The scope of this contract will include various types of professional services to support the LPI Branch. Task Areas include; Information Technology Portfolio Management (IT PfM), Data Management & Analytics Support, War Reserve and Prepositioning Support and Business Process Reengineering, and Program Management. The Contractor will provide policy guidance, study current programs, make program improvement recommendations, perform database development and analysis, conduct modeling and simulation, provide Operational Advisory Group (OAG) participation and management support, develop training requirements, perform information management and technical services, logistics information management system software analysis and support.\n",
      " DSD Labs is seeking a Journeyman Data Engineer to work with the Marine Corps LPM-3 Division in developing metadata services to support enterprise-level data analytics capabilities. This aspect of data management will assist the logistics community by establishing hierarchy, cleansing, and curating hundreds of data injects from multiple Marine Corps data sources. This will enable the Marine Corps to effectively manage and maintain logistics-specific data that provide valuable readiness insight, increase decision making speed, serve as the building blocks for enhanced analytics visualizations, and set conditions for predictive analysis through artificial intelligence and machine learning. Once established, a metadata repository will need routine administrative and maintenance.\n",
      " Primary Duties/Responsibilities:\n",
      "\n",
      "Support LPI business needs of an enterprise-owned metadata repository through providing standard data definitions, accurate business rules/calculations, and complete traceability and lineage of governed data. \n",
      "Provide standard and ad-hoc reports to facilitate the analysis of the Metadata and its user community. Develop and maintain user community interaction models in support of the Metadata Repository. \n",
      "Assist in writing business definitions of tables, entities, files, columns, attributes, and fields that are to be captured and published in the Metadata Tool user guide and Metadata Plan; ensure understanding of business and technical metadata specific to Logistics data lineage, and data models and methods in order to document for both technical and business users. \n",
      "Assist in the development of processes and procedures for metadata management and administration, including metadata configuration management, adopting metadata schemas, and parent/child metadata. \n",
      "Support LPI with metadata aspects of data curation, profiling, and tagging techniques.\n",
      "Work with the metadata Manager and Logistics Data Services technical team to build upon the Metadata Tool User Guide. Provide navigation assistance to new metadata users and develop a mechanism to track requests for support and open issues.\n",
      "Assist the metadata manager in drafting definitions of data falling outside of the established data dictionary.\n",
      "Assist in generating written communication of both business and technical metadata, data lineage, and data models and methods are documented and understand by both technical and business users. \n",
      "Sync with cross-functional teams and capture action items as they relate to metadata management and data integration within the Logistics IT portfolio.\n",
      "Working with stakeholders, data, and design teams to support their data infrastructure needs and assisting with technical issues.\n",
      "\n",
      " Knowledge and Skills Required:\n",
      "\n",
      "Solid understanding of data analytics, metadata cataloging and building data dictionaries, analytics, forecasting and modeling\n",
      "Demonstrated and specialized experience with data integration, cataloging and Data as a Service cloud technologies\n",
      "Ability to build processes that support data transformation, workload management, data structures, dependency and metadata\n",
      "Excellent analytical skills associated with working on unstructured datasets\n",
      "Understanding of logistics portfolio and technology development and maturation a plus\n",
      "\n",
      " Education and Experience Required:\n",
      " \n",
      "\n",
      "Bachelor’s Degree in Computer Science, Information Systems, Engineering or related scientific or technical discipline preferred but not required\n",
      "2-3 years of Data Management, Analytics, or Data Engineering experience\n",
      "Experience working with different database technologies, querying/scripting languages, in order to update data systems\n",
      "Experience working with large, complex sets of data that meet non-functional and functional business requirements\n",
      "Experience working within the DoD, and in particular the USMC or Navy preferred\n",
      "Secret Security Clearance required\n",
      "\n",
      " This position is telework/remote for now, but may require onsite support at the Pentagon occasionally.\n",
      "\n",
      "Hiring InsightsJob activityPosted 30+ days ago\n",
      "COVID-19 continues to significantly impact our employees, families and communities. With employee health and safety as our top priority, and as a federal contractor, Lockheed Martin is taking action to address the increased risk and uncertainty COVID variants pose in the workplace and ensuring we meet our commitments to national security.\n",
      "\n",
      "To uphold safety for all employees, we will continue to request vaccination status for all Lockheed Martin employees including new hires. All current and newly hired employees who are unvaccinated will be required to adhere to onsite safety protocols.\n",
      "Description:This position will be an DevSecOps Associate manager within the Lockheed Martin (LM) Chief Data & Analytics Office (LM CDAO)\n",
      "\n",
      "The work location for this position is virtual.\n",
      "\n",
      "Duties and responsibilities include, but are not limited to:\n",
      "\n",
      "Key responsibility of the role is to manage a team of DevSecOps Engineers deployments, security in support of business solutions.\n",
      "Guides the team to deliver quality service to Business Area stakeholders and users.Establish metrics and drive overall engineering productivity for release velocity, CI/CD, quality, reliability, and DevSecOps effectiveness.We deliver business-critical services with high expectations for availability & performance. We measure customer experience to identify areas for improvement.Collaborate with peer managers to understand current and future business needs and advocate for business stakeholders.Build relationships across the enterprise to tackle technical challenges and contribute to the development of common methodologies & solutionsFunctional and program management responsibility for Data Delivery; Data, Analytics, & AI platforms; Analytics User Community Support; and Production OperationsDemonstrate Full Spectrum Leadership behaviors. Build mentoring relationships within organization. Provide career path opportunities for personnel within the department. Recognize achievements. Direct, coordinate, perform and exercise authority of employee actions, including employee job assignments and rotations, merit planning, promotion planning, compliance & skills training, and regular performance assessment.\n",
      "Basic Qualifications:\n",
      "Proven leadership skills including one or more of the following: project management, team leadership, program management, or people management.Strong working knowledge of and experience with DevSecOps and the Agile FrameworkUnderstanding of/experience with open-source tools and CI/CD best practicesFamiliarity with AWS/Cloud TechnologiesLeverage open-source cloud software tools, security tools and full-stack cloud platformBuild and implement serverless applicationsBuild docker containers and microservices in Amazon Web Services (AWS)Evaluate AWS cloud cost savings initiatives, strategies, and practices.Ability to implement technical strategyStrong communication skills with proven record to convey objectives and results to business and technical executives in a clear and concise manner; ability to explain sophisticated technical concepts in business-friendly terms\n",
      "MUST BE U.S. CITIZEN\n",
      "Desired Skills:\n",
      "Prior management consulting experience or technology consulting experienceDemonstrate growth mindset approach with ability to challenge the status-quo and bring new ideas to the tableDemonstrated ability to perform and multi-task in a fast-paced environment.Working knowledge of Git and repository providers such as GitHub, GitLab, BitbucketExperience implementing container and orchestration infrastructure utilizing platforms such as Docker and KubernetesEye for business and ability to balance technical requirements and techniques to improve customer experienceProven ability to coordinate effectively across both Information Technology and Business Functional organizations.Staff management experience (performance management, merit, promotions, hiring, training skill development, etc.)Experience implementing, upgrading, migrating, and/or retiring data, analytics, or AI platforms.Proven experience leading an agile product team or agile service team using a framework like Scrum, SAFe, or Kanban.Prior experience implementing DevSecOps and Continuous Integration – Continuous Delivery methodologies.\n",
      "BASIC QUALIFICATIONS:\n",
      "job.Qualifications\n",
      "\n",
      "Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.\n",
      "Join us at Lockheed Martin, where your mission is ours. Our customers tackle the hardest missions. Those that demand extraordinary amounts of courage, resilience and precision. They’re dangerous. Critical. Sometimes they even provide an opportunity to change the world and save lives. Those are the missions we care about.\n",
      "\n",
      "As a leading technology innovation company, Lockheed Martin’s vast team works with partners around the world to bring proven performance to our customers’ toughest challenges. Lockheed Martin has employees based in many states throughout the U.S., and Internationally, with business locations in many nations and territories.\n",
      "EXPERIENCE LEVEL:\n",
      "Experienced ProfessionalHiring InsightsJob activityPosted 30+ days ago\n",
      "Job detailsJob TypeFull-timeIndeed's salary guideNot provided by employer$93.5K to $118K per year is Indeed's estimated salary for data engineer in Washington, DC.loading surveyFull Job Description\n",
      "\n",
      "SUMMARY: Reporting to the Executive Director of Product Management, the Data Engineer devises a system to help analyze videos identifying and annotating data points to determine best learning practices, automate some aspects of assessments, and be used for future machine learning projects.\n",
      "\n",
      " PRINCIPAL ACCOUNTABILITIES:\n",
      "\n",
      "\n",
      "Constructs, maintains, tests and optimizes scalable data architectures for all of CBO’s initiatives and business entities such as ASL Connect and the Bilingual Evaluation, Testing, and Assessment (BETA) Center, ensuring they will also support the business requirements via the lens of bilingualism, diversity, equity and inclusion.\n",
      "\n",
      "\n",
      "Builds data processes, workflows and modeling pipelines based on spatial concepts and grammatical knowledge of American Sign Language.\n",
      "\n",
      "\n",
      "Discovers opportunities for data acquisition, develops dataset processes for data modeling, mining and production.\n",
      "\n",
      "\n",
      "Employs a variety of scripting languages and tools to intertwine systems in order to recommend ways to improve data reliability, efficiency and quality.\n",
      "\n",
      "\n",
      "Trains and deploys machine learning and deep learning models as well as statistical methods to prepare data for use in predictive and prescriptive modeling.\n",
      "\n",
      "\n",
      "Works closely with ASL annotators and translators to better understand how ASL is structured and integrated in bilingual practices.\n",
      "\n",
      "\n",
      "Leverages large volumes of ASL data from internal and external sources, exploring and examining data to find hidden patterns.\n",
      "\n",
      "\n",
      "Conducts independent and high-quality work from loose specifications and provides analysis and recommendations to stakeholders outside of the Office of the Chief Bilingual Officer.\n",
      "\n",
      "\n",
      "Establishes and maintains a positive and supportive working relationship with co-workers and supervisor.\n",
      "\n",
      "\n",
      "Shows a genuine commitment to diversity, equity and inclusion in the workplace; and participates in activities and workshops to foster continuous learning.\n",
      "\n",
      "\n",
      "Serves as a mandatory Title IX reporter; and takes annual Title IX training as part of the compliance effort.\n",
      "\n",
      "\n",
      "Other duties as assigned.\n",
      "\n",
      "\n",
      "\n",
      " SPECIFICATIONS:\n",
      " Required Minimum Qualifications (When the candidate’s resume meets these qualifications, it will be screened in.):\n",
      "\n",
      "Bachelor’s degree in Computer Science, Business Administration, Mathematics, or related field.\n",
      "A minimum of four years of professional experience in programming, business development or a related field.\n",
      "Fluency in American Sign Language.\n",
      "\n",
      " Preferred Qualifications (While not required, it is an advantage for what the position needs.)\n",
      "\n",
      "Experience in a higher education setting.\n",
      "\n",
      " Knowledge, Skills, and Abilities (Qualities that will help the applicant be more successful in the position):\n",
      "\n",
      "Strong organizational and time management skills.\n",
      "Strong coding background in Python, R, or similar languages.\n",
      "Strong understanding of how most databases (relational, document, wide-column) work and has demonstrative use of basic query concepts.\n",
      "Strong ability to negotiate and influence in order to achieve business objectives.\n",
      "Strong knowledge of software development life cycle and use of version control, unit testing, and code review.\n",
      "Strong ability to work independently and exercise professional judgment.\n",
      "Strong ability to manage multiple projects and workflows in a fast-paced, deadline-driven environment.\n",
      "Strong ability to function well under pressure and meet project deadlines.\n",
      "Demonstrated experience in generating models and data visualizations.\n",
      "Demonstrated experience with deploying and maintaining models in a production environment.\n",
      "Strong organizational and time management skills.\n",
      "Demonstrated ability to work with and across University departments, outside constituents and groups.\n",
      "Demonstrated commitment to valuing diversity and contributing to an inclusive working and learning environment.\n",
      "\n",
      " Other Important Information\n",
      "\n",
      "Selected candidates will be required to provide samples during the interview.\n",
      "All employees are expected to be fully vaccinated against COVID-19 and Influenza (flu). They also will be required to submit their vaccination record within the first week of employment. If they cannot be fully vaccinated, they may apply for a medical or religious exemption.\n",
      "The successful candidate will undergo a background check that must be cleared prior to working at Gallaudet University.\n",
      "\n",
      "\n",
      " Compensation:\n",
      " Salary: Commensurate with skills, qualifications, and experience\n",
      " FLSA status: Exempt\n",
      "\n",
      " Gallaudet University is an equal opportunity employer/educational institution and does not discriminate on the basis of race, sex, national origin, religion, age, hearing status, disability, genetic information, covered veteran status, marital status, personal appearance, sexual orientation, family responsibilities, matriculation, political affiliation, source of income, place of business or residence, pregnancy, childbirth, or any other unlawful basis. This policy is in compliance with Title VII of the Civil Rights Act, the Americans with Disabilities Act, the Rehabilitation Act, the Age Discrimination in Employment Act, the District of Columbia Human Rights Act, and other applicable laws and applies to all procedures affecting applicants and employees including, but not necessarily limited to: recruitment, hiring, placement, promotion, transfer, reassignment, reappointment, tenure, demotion, selection for training, layoff, furlough, and termination, compensation, and all other conditions or privileges of employment.\n",
      "\n",
      "Hiring InsightsJob activityPosted 8 days ago\n",
      "Job detailsSalary$140,000 - $200,000 a yearFull Job Description\n",
      "\n",
      "\n",
      "Who is Recruiting from Scratch: \n",
      "Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n",
      "If you are a fit, the team will reach out to you about this role or any others that may be a fit for our clients. \n",
      "\n",
      "Our Client \n",
      "Our client helps organizations globally to build trust and speed into their business by matching the Speed of PrivacyOps to the Speed of Dev/BusinessOps. They have clients including Coinbase, Samsara, Twilio, Robinhood, and Flexport. \n",
      "\n",
      "\n",
      "The Role \n",
      "The role requires you to think critically and design from the first principles. You should be comfortable with multiple moving parts and microservices architectures. Given you are constructing the foundation on which our global data infrastructure will be built, you need to pay close attention to detail and maintain a forward-thinking outlook as well as scrappiness for the present needs. You are very comfortable learning new technologies and systems. You thrive in an iterative but heavily test-driven development environment. You obsess over model performance and thrive on applying machine learning techniques to business problems. \n",
      "\n",
      "Responsibilities \n",
      "\n",
      "Design machine learning pipelines to solve the highest impact business problems in the simplest way \n",
      "Gather training data, and train and evaluate state-of-the-art models \n",
      "Work with cross-functional teams, including lawyers, data protection and security researchers \n",
      "Work with backend developers \n",
      "\n",
      "You Are A Good Fit If \n",
      "\n",
      "Have strong experience building natural language processing (NLP) systems, specifically in text classification, entity and relation extraction, summarization, and knowledge base construction \n",
      "Have strong software engineering skills, are comfortable with Python, and have experience with machine learning and NLP tools and libraries such as scikit-learn, PyTorch, TensorFlow, Keras, spaCy, HuggingFace, Gensim, etc. \n",
      "Have experience building end-to-end ML pipelines and deploying models to production \n",
      "Thrive in a self-directed environment with full ownership to design features from scratch and the accountability that comes along \n",
      "Are motivated by bringing the most value as possible to users, whether this means designing a new feature, training a state-of-the-art model, building an ETL pipeline, recruiting a data labeling vendor, etc. \n",
      "Learn new ways of thinking about age-old problems \n",
      "\n",
      "\n",
      "\n",
      "Benefits: PTO, Healthcare, and More! \n",
      "    \n",
      "\n",
      "Base Salary Range: $140,000 to $200,000\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "Hiring InsightsJob activityPosted 19 days ago\n",
      "Job detailsJob TypeFull-timeIndeed's salary guideNot provided by employer$118K to $149K per year is Indeed's estimated salary for data engineer in Reston, VA.loading surveyFull Job Description\n",
      "Data Engineer\n",
      "About the OrganizationNow is a great time to join Redhorse Corporation. Redhorse specializes in developing and implementing creative strategies and solutions with private, state, and federal customers in the areas of cultural and environmental resources services, climate and energy change, information technology, and intelligence services. We are hiring creative, motivated, and talented people with a passion for doing what's right, what's smart, and what works.\n",
      "Position DescriptionRedhorse is hiring a Data Engineer with an active TS/SCI clearance. Under general direction, the Data Engineer will participate as a high-level, technical expert in data pipeline and script development as well as data analysis. The ideal candidate will interface with the client, stakeholders, military personnel, and data providers to ensure that the Intelligence, Surveillance and Reconnaissance (ISR) Analysis Team within the OUSD(I&S) has maximal buy-in for its activities and can identify and collect data it needs. The work location for this role will be in Reston, VA.\n",
      "Minimum Basic Requirements for Skills, Experience, Education and Credentials include: \n",
      "\n",
      "Active TOP SECRET (TS) with Sensitive Compartmented Information (SCI) access, required. Individuals who do not have an active TS clearance with SCI access will not be considered for this opportunity.\n",
      "Ability to apply comprehension of data engineering-specific technologies and services, leverage expertise in databases and employ a variety of approaches to structuring and retrieving data.\n",
      "Ability to support the configuration and ingestion of designated structured ETL (Extract, Transform, Load) script development, including merging and deconflicting related data sources using a general-purpose programming language: e.g., Python.\n",
      "Programming experience in NodeJS, Python and other Object-Oriented Languages.\n",
      "Experience with legacy web service APIs such as SOAP as well as text-based and web-based data scraping using Python.\n",
      "Experience developing databases, preferably MongoDB.\n",
      "Ability to work in a small, agile team environment, including on government site where availability of advanced development/database tools may be limited.\n",
      "Bachelor’s Degree is Highly Desired.\n",
      "\n",
      "Executive Order Requirement: In accordance with Executive Order 14042 as a Federal Contractor Redhorse requires all U.S. new hires to be fully vaccinated for COVID-19 by December 8, 2021 or prior to the first date of employment, whichever is later. As required by the Executive Order, Redhorse will work in coordination with applicable contract agencies to consider requests for Reasonable Accommodations.\n",
      "Redhorse Corporation shall, in its discretion, modify or adjust the position to meet Redhorse’s changing needs.This job description is not a contract and may be adjusted as deemed appropriate in Redhorse’s sole discretion.EOE/M/F/Vet/Disabled\n",
      "Job Type: Full-time\n",
      "Hiring InsightsApplication response rate: 66%Job activityEmployer reviewed job 28 days agoPosted 30+ days ago\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "page_body_text = []\n",
    "\n",
    "for job_page in job_links:\n",
    "    loaded_page = requests.get(job_page)\n",
    "    soup = BeautifulSoup(loaded_page.text, \"html.parser\")\n",
    "        \n",
    "    \n",
    "    page_body = soup.find_all(\"div\", class_=\"jobsearch-JobComponent-description\")\n",
    "        \n",
    "    for elements in page_body:\n",
    "        text = elements.get_text()\n",
    "        \n",
    "        page_body_text.append(text)\n",
    "        counter += 1\n",
    "        \n",
    "print(len(job_links))\n",
    "print(\"Total Texts: \", len(page_body_text))\n",
    "print(\"DONE\")\n",
    "\n",
    "for items in page_body_text:\n",
    "    print(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7a066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "unwanted_chars = [\" \", \",\", \"/\", \"'\\'\", \".\", \"(\", \")\", \";\", '\"', \"'\", \":\", \"-\", \"_\", \"&\", \"[\", \"]\", \"*\", \"?\", \"#\", \"!\", \"%\", \"®\"]\n",
    "additional_splitting = [\"/\", \"(\", \")\"]\n",
    "final_list = []\n",
    "word_frequency = {}\n",
    "\n",
    "for items in page_body_text:\n",
    "    text = re.sub(\"\\n\", \" \", items)\n",
    "    clean_list = text.split()\n",
    "    \n",
    "    for word in clean_list:\n",
    "        split_words = []\n",
    "        if word != \"\":\n",
    "                \n",
    "            if len(word) > 1:\n",
    "                \n",
    "                cleaned = False\n",
    "                print(\"Word Going Into Machine: \", word)\n",
    "                while cleaned is False:\n",
    "                    \n",
    "                    if len(word) > 1 and word[len(word)-1] in unwanted_chars:\n",
    "                        word = word[:-1]\n",
    "                \n",
    "                        if len(word) > 1 and word[0] in unwanted_chars:\n",
    "                            word = word[1:]\n",
    "                    \n",
    "                    \n",
    "                    if len(word) > 1 and word[0] in unwanted_chars:\n",
    "                        word = word[1:]\n",
    "                \n",
    "                        if len(word) > 1 and word[len(word)-1] in unwanted_chars:\n",
    "                            word = word[:-1]\n",
    "                    \n",
    "                    \n",
    "                    if len(word) == 1:\n",
    "                        if word in unwanted_chars:\n",
    "                            print(\"Word Deleted: \", word)\n",
    "                            cleaned = True\n",
    "                        \n",
    "                        else:\n",
    "                            print(\"Passed WORD = 1: \", word)\n",
    "                            print(\"   \")\n",
    "                            final_list.append(word.lower().strip())\n",
    "                            cleaned = True\n",
    "                        \n",
    "                    elif word[0] not in unwanted_chars and word[len(word) - 1] not in unwanted_chars:\n",
    "                        print(\"Passed ELIF: \", word)\n",
    "                        print(\"   \")\n",
    "                        if word[-2:] == \"'s\" or word[-2:] == \"’s\":\n",
    "                            print(\"Machine Processing S Condition: \", word)\n",
    "                            word = word[:-2] + \"s\"\n",
    "                            print(\"Passed Condition: \", word)\n",
    "                            print(\"   \")\n",
    "            \n",
    "                        if \"$\" in word:\n",
    "                            print(\"Machine Processing Money Condition: \", word)\n",
    "                            word = \"$\" + word.split(\"$\", 1)[1]\n",
    "                            print(\"Passed Condition: \", word)\n",
    "                            print(\"   \")\n",
    "                        \n",
    "                        for symbols in additional_splitting:\n",
    "                            if symbols in word: \n",
    "                                split_words = word.split(symbols)\n",
    "                                print(\"Machine Processing Extra Symbols in Word Condition: \", word)\n",
    "                                print(\"Passed Condition: \", split_words)\n",
    "                                print(\"   \")\n",
    "                        \n",
    "                        if len(split_words) == 0: \n",
    "                            final_list.append(word.lower().strip())\n",
    "                            cleaned = True\n",
    "                        else: \n",
    "                            for words in split_words:\n",
    "                                print(\"Word Added Based On Extra Symbol Condition: \", words)\n",
    "                                print(\"     \")\n",
    "                                final_list.append(words.lower().strip())\n",
    "                                cleaned = True\n",
    "                    \n",
    "                    else: \n",
    "                        cleaned = False\n",
    "                        \n",
    "            else: \n",
    "                if word not in unwanted_chars:\n",
    "                    print(\"Passed SINGLE LETTER NOT IN CHARS: \", word)\n",
    "                    print(\"   \")\n",
    "                    final_list.append(word.lower().strip())\n",
    "                \n",
    "            \n",
    "        \n",
    "print(\"Done\")\n",
    "print(len(final_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9a92714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5516"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " for words in final_list:\n",
    "        if words not in word_frequency:\n",
    "            word_frequency[words] = 0\n",
    "        word_frequency[words] += 1\n",
    "\n",
    "len(word_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78f32990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job 232\n",
      "$116,800 2\n",
      "$163,500 4\n",
      "a 764\n",
      "yearjob 17\n",
      "typefull-timefull 27\n",
      "description 87\n",
      "your 169\n",
      "life's 2\n",
      "mission 36\n",
      "possible 21\n",
      "you 356\n",
      "have 147\n",
      "goals 11\n",
      "dreams 2\n",
      "hobbies 2\n",
      "and 2666\n",
      "things 13\n",
      "you’re 2\n",
      "passionate 12\n",
      "about 75\n",
      "whats 10\n",
      "important 12\n",
      "to 1440\n",
      "is 343\n",
      "us 48\n",
      "we’re 15\n",
      "looking 42\n",
      "for 634\n",
      "people 53\n",
      "who 75\n",
      "not 71\n",
      "only 11\n",
      "want 22\n",
      "do 61\n",
      "meaningful 6\n",
      "challenging 7\n",
      "work 300\n",
      "keep 8\n",
      "their 92\n",
      "skills 131\n",
      "sharp 2\n",
      "move 5\n",
      "ahead 5\n",
      "but 28\n",
      "also 34\n",
      "take 30\n",
      "time 63\n",
      "the 1264\n",
      "that 239\n",
      "matter 7\n",
      "them—friends 2\n",
      "family 20\n",
      "passions 2\n",
      "we're 14\n",
      "team 187\n",
      "members 23\n",
      "are 246\n",
      "our 332\n",
      "mission—making 2\n",
      "difference 3\n",
      "in 759\n",
      "military 11\n",
      "families 5\n",
      "lives 10\n",
      "together 13\n",
      "we 285\n",
      "can 46\n",
      "make 40\n",
      "it 61\n",
      "happen 2\n",
      "don’t 5\n",
      "word 6\n",
      "times 2\n",
      "2021 7\n",
      "best 75\n",
      "vets 1\n",
      "employers 4\n",
      "wayup 1\n",
      "top 18\n",
      "100 13\n",
      "internship 1\n",
      "programs 30\n",
      "forbes 4\n",
      "new 76\n",
      "grads 1\n",
      "americas 5\n",
      "newsweek 1\n",
      "most 31\n",
      "loved 3\n",
      "workplaces 8\n",
      "companies 14\n",
      "care 16\n",
      "fortune 5\n",
      "women 3\n",
      "millennials 3\n",
      "computerworld 2\n",
      "places 6\n",
      "basic 18\n",
      "purpose 8\n",
      "optimize 8\n",
      "performance 47\n",
      "of 989\n",
      "business 184\n",
      "operations 24\n",
      "by 159\n",
      "analyzing 10\n",
      "current 22\n",
      "forecasting 2\n",
      "future 26\n",
      "as 310\n",
      "relates 1\n",
      "systems 151\n",
      "system 63\n",
      "integrations 2\n",
      "processes 60\n",
      "apply 37\n",
      "various 29\n",
      "analytical 27\n",
      "techniques 20\n",
      "solve 18\n",
      "operational 24\n",
      "issues 31\n",
      "support 111\n",
      "strategic 10\n",
      "initiatives 11\n",
      "under 18\n",
      "minimal 6\n",
      "supervision 8\n",
      "develop 69\n",
      "strategies 11\n",
      "data 1049\n",
      "engineering 129\n",
      "reporting 30\n",
      "analytics 116\n",
      "responsible 33\n",
      "designing 27\n",
      "building 68\n",
      "integrating 12\n",
      "from 134\n",
      "resources 19\n",
      "managing 23\n",
      "big 45\n",
      "write 7\n",
      "complex 48\n",
      "queries 5\n",
      "ensure 26\n",
      "they 33\n",
      "smoothly 1\n",
      "with 672\n",
      "goal 5\n",
      "optimizing 22\n",
      "navy 16\n",
      "federals 1\n",
      "ecosystem 6\n",
      "highly 29\n",
      "skilled 4\n",
      "proficient 2\n",
      "generating 4\n",
      "reports 20\n",
      "visualizations 8\n",
      "considered 15\n",
      "senior 19\n",
      "level 38\n",
      "position 109\n",
      "conduct 13\n",
      "essential 17\n",
      "wide 15\n",
      "latitude 2\n",
      "independent 8\n",
      "judgment 7\n",
      "individual 13\n",
      "contributor 4\n",
      "mentor 9\n",
      "junior 4\n",
      "staff 18\n",
      "responsibilities 40\n",
      "provide 54\n",
      "intelligence 32\n",
      "bi 19\n",
      "warehousing 19\n",
      "dw 4\n",
      "solutions 109\n",
      "leveraging 9\n",
      "project 52\n",
      "standards 22\n",
      "leading 29\n",
      "platforms 23\n",
      "evaluate 8\n",
      "collaborate 12\n",
      "on 231\n",
      "functional 20\n",
      "requirements 119\n",
      "define 4\n",
      "build 64\n",
      "integration 42\n",
      "be 263\n",
      "used 17\n",
      "across 38\n",
      "organization 25\n",
      "conceptual 3\n",
      "logical 3\n",
      "models 27\n",
      "stakeholders 28\n",
      "management 91\n",
      "directly 13\n",
      "leadership 18\n",
      "understand 28\n",
      "propose 3\n",
      "enable 18\n",
      "effective 9\n",
      "decision-making 3\n",
      "drives 4\n",
      "objectives 14\n",
      "prepare 10\n",
      "advanced 28\n",
      "implementation 29\n",
      "plans 18\n",
      "which 34\n",
      "highlight 1\n",
      "major 11\n",
      "milestones 2\n",
      "deliverables 7\n",
      "standard 18\n",
      "methods 9\n",
      "planning 34\n",
      "tools 104\n",
      "implement 26\n",
      "practices 40\n",
      "educate 2\n",
      "users 10\n",
      "evangelize 1\n",
      "self-service 5\n",
      "capabilities 17\n",
      "enterprise 22\n",
      "present 14\n",
      "trainings 3\n",
      "webinars 1\n",
      "community 30\n",
      "regular 7\n",
      "basis 16\n",
      "analyze 21\n",
      "validate 4\n",
      "accuracy 4\n",
      "report 12\n",
      "results 12\n",
      "interpret 3\n",
      "collected 1\n",
      "spotting 1\n",
      "trends 8\n",
      "writing 14\n",
      "recommendations 9\n",
      "internal 29\n",
      "or 471\n",
      "external 19\n",
      "clients 56\n",
      "recognize 5\n",
      "potential 3\n",
      "risks 4\n",
      "during 11\n",
      "suggest 4\n",
      "mitigation 1\n",
      "carrying 1\n",
      "out 26\n",
      "activities 31\n",
      "high 19\n",
      "quality 37\n",
      "valued 3\n",
      "them 27\n",
      "such 71\n",
      "manner 13\n",
      "easily 2\n",
      "understood 1\n",
      "presented 4\n",
      "charts 1\n",
      "tables 3\n",
      "transform 21\n",
      "into 41\n",
      "format 2\n",
      "useful 2\n",
      "promotes 3\n",
      "decision 8\n",
      "making 11\n",
      "use 42\n",
      "statistical 15\n",
      "historical 1\n",
      "predictions 2\n",
      "identify 30\n",
      "opportunities 55\n",
      "enabling 3\n",
      "better 23\n",
      "decisions 18\n",
      "planned 1\n",
      "planned/future 1\n",
      "events 13\n",
      "improvements 5\n",
      "way 11\n",
      "services 78\n",
      "an 187\n",
      "entire 3\n",
      "function 5\n",
      "communicate 16\n",
      "own 12\n",
      "process 26\n",
      "manipulating 9\n",
      "merging 2\n",
      "large 37\n",
      "datasets 15\n",
      "key 25\n",
      "point 6\n",
      "contact 12\n",
      "between 12\n",
      "analyst 5\n",
      "analyst/data 1\n",
      "scientist 10\n",
      "project/functional 1\n",
      "leads 5\n",
      "perform 38\n",
      "other 115\n",
      "duties 24\n",
      "assigned 15\n",
      "qualifications 71\n",
      "education 70\n",
      "bachelors 39\n",
      "degree 54\n",
      "information 91\n",
      "computer 44\n",
      "science 61\n",
      "related 65\n",
      "field 27\n",
      "equivalent 28\n",
      "combination 11\n",
      "training 40\n",
      "experience 505\n",
      "knowledge 89\n",
      "structures 14\n",
      "ability 128\n",
      "manipulate 4\n",
      "within 56\n",
      "visualization 15\n",
      "power 15\n",
      "tableau 11\n",
      "etl 67\n",
      "provisioning 9\n",
      "using 81\n",
      "azure 22\n",
      "databricks 3\n",
      "factory 7\n",
      "synapse 1\n",
      "programming 37\n",
      "sql 82\n",
      "python 72\n",
      "r 11\n",
      "extract 10\n",
      "sources 31\n",
      "warehouse 24\n",
      "lake 5\n",
      "hubs 1\n",
      "cleansing 3\n",
      "pipelines 62\n",
      "required 155\n",
      "usage 4\n",
      "mapping 2\n",
      "understands 4\n",
      "technical 97\n",
      "business/technical 1\n",
      "languages 27\n",
      "libraries 5\n",
      "catalog 1\n",
      "plan 31\n",
      "cloud 83\n",
      "administration 12\n",
      "migration 20\n",
      "infrastructure 43\n",
      "problem 16\n",
      "determine 7\n",
      "what 44\n",
      "aspects 8\n",
      "require 15\n",
      "optimization 7\n",
      "articulate 5\n",
      "those 17\n",
      "clear 9\n",
      "concise 4\n",
      "predict 2\n",
      "probability 2\n",
      "outcome 2\n",
      "projects 31\n",
      "areas 15\n",
      "consolidate 1\n",
      "needs 50\n",
      "demonstrates 4\n",
      "passion 13\n",
      "educating 1\n",
      "customer 28\n",
      "enablement 2\n",
      "comfort 2\n",
      "speaking 1\n",
      "front 2\n",
      "audiences 8\n",
      "possesses 4\n",
      "executive 10\n",
      "presence 2\n",
      "change 19\n",
      "and/or 49\n",
      "communication 33\n",
      "skill 9\n",
      "sourcing 1\n",
      "maintaining 25\n",
      "updating 5\n",
      "raw 4\n",
      "dashboards 9\n",
      "end 11\n",
      "outcomes 13\n",
      "visually 2\n",
      "manage 18\n",
      "source 11\n",
      "implementing 25\n",
      "desired 13\n",
      "analysis 53\n",
      "measures 6\n",
      "central 4\n",
      "tendency 1\n",
      "normal 2\n",
      "distribution 1\n",
      "variance 1\n",
      "deviation 1\n",
      "tests 5\n",
      "correlation 1\n",
      "regression 2\n",
      "federal 62\n",
      "credit 7\n",
      "union 7\n",
      "instructions 5\n",
      "procedures 20\n",
      "hours 20\n",
      "monday 8\n",
      "friday 8\n",
      "8:00am 1\n",
      "4:30pm 1\n",
      "location 61\n",
      "820 1\n",
      "follin 1\n",
      "lane 1\n",
      "vienna 3\n",
      "va 12\n",
      "22180 1\n",
      "due 13\n",
      "covid-19 37\n",
      "social 15\n",
      "distancing 4\n",
      "this 191\n",
      "will 264\n",
      "temporarily 4\n",
      "working 121\n",
      "home 7\n",
      "return 4\n",
      "campus 8\n",
      "at 159\n",
      "listed 9\n",
      "once 7\n",
      "back 5\n",
      "specific 18\n",
      "logistics 12\n",
      "returning 1\n",
      "determined 3\n",
      "date 23\n",
      "salary 87\n",
      "assesses 2\n",
      "market 7\n",
      "establish 5\n",
      "ranges 2\n",
      "remain 3\n",
      "competitive 33\n",
      "paid 43\n",
      "range 32\n",
      "based 64\n",
      "equal 47\n",
      "employment 76\n",
      "opportunity 65\n",
      "values 13\n",
      "celebrates 5\n",
      "enacts 2\n",
      "diversity 24\n",
      "workplace 15\n",
      "takes 6\n",
      "affirmative 11\n",
      "action 18\n",
      "employ 5\n",
      "advance 9\n",
      "qualified 31\n",
      "individuals 25\n",
      "disabilities 15\n",
      "disabled 6\n",
      "veterans 18\n",
      "armed 2\n",
      "forces 3\n",
      "service 37\n",
      "medal 2\n",
      "recently 5\n",
      "separated 3\n",
      "protected 40\n",
      "eoe 4\n",
      "aa 3\n",
      "m 4\n",
      "f 4\n",
      "veteran 32\n",
      "disability 51\n",
      "eoe/aa/m/f/veteran/disability 2\n",
      "vaccine 12\n",
      "safety 16\n",
      "measure 6\n",
      "employees 62\n",
      "must 80\n",
      "either 12\n",
      "proof 18\n",
      "vaccination 19\n",
      "follow 8\n",
      "additional 17\n",
      "protocols 8\n",
      "including 105\n",
      "testing 28\n",
      "disclaimer 3\n",
      "reserves 2\n",
      "right 11\n",
      "fill 3\n",
      "role 60\n",
      "higher 17\n",
      "lower 3\n",
      "higher/lower 2\n",
      "grade 5\n",
      "need 32\n",
      "assessment 19\n",
      "may 83\n",
      "compete 3\n",
      "bank 4\n",
      "secrecy 4\n",
      "act 18\n",
      "remains 2\n",
      "cognizant 2\n",
      "adheres 2\n",
      "policies 14\n",
      "regulations 11\n",
      "pertaining 2\n",
      "employee 45\n",
      "referrals 2\n",
      "eligible 14\n",
      "talentquest 2\n",
      "referral 9\n",
      "program 46\n",
      "if 73\n",
      "referred 3\n",
      "please 39\n",
      "system-generated 2\n",
      "link 4\n",
      "was 6\n",
      "sent 5\n",
      "hiring 79\n",
      "insightsjob 60\n",
      "activityposted 65\n",
      "30+ 23\n",
      "days 91\n",
      "ago 64\n",
      "$95,600 2\n",
      "seeking 19\n",
      "engineer 145\n",
      "join 27\n",
      "protection 8\n",
      "storage 23\n",
      "dpss 3\n",
      "provides 28\n",
      "design 108\n",
      "block 3\n",
      "object 5\n",
      "file 6\n",
      "throughout 15\n",
      "nfcu 2\n",
      "form 9\n",
      "backup 4\n",
      "copy 5\n",
      "resilient 3\n",
      "research 36\n",
      "maintain 43\n",
      "product 29\n",
      "applying 18\n",
      "principles 7\n",
      "direction 10\n",
      "expert 18\n",
      "evolving 3\n",
      "industry 30\n",
      "technologies 75\n",
      "competition 3\n",
      "technologies/competition 1\n",
      "concepts 15\n",
      "successful 14\n",
      "candidate 43\n",
      "broad 8\n",
      "both 38\n",
      "independently 20\n",
      "environment 78\n",
      "possess 3\n",
      "least 14\n",
      "five 4\n",
      "years 131\n",
      "relevant 19\n",
      "ten 2\n",
      "direct 9\n",
      "attributes 4\n",
      "include 35\n",
      "strong 62\n",
      "modern 17\n",
      "legacy 6\n",
      "i.e 9\n",
      "rubrik 1\n",
      "cohesity 1\n",
      "commvault 1\n",
      "tsm 1\n",
      "etc 39\n",
      "multi-petabyte 1\n",
      "distributed 8\n",
      "preference 14\n",
      "candidates 33\n",
      "experienced 26\n",
      "protecting 8\n",
      "on-prem 2\n",
      "cloud-based 9\n",
      "good 18\n",
      "understanding 32\n",
      "physical 17\n",
      "tape 2\n",
      "security 59\n",
      "managers 8\n",
      "primary 11\n",
      "secondary 3\n",
      "operation 10\n",
      "should 16\n",
      "san-based 1\n",
      "ibm 4\n",
      "platform 39\n",
      "threats 2\n",
      "ransomware 1\n",
      "attacks 1\n",
      "creating 19\n",
      "protect 7\n",
      "against 13\n",
      "desirable 4\n",
      "storwize 1\n",
      "spectrum 2\n",
      "storwize/spectrum 1\n",
      "virtualize 1\n",
      "flash 2\n",
      "a9000 1\n",
      "9100 1\n",
      "9200 1\n",
      "9100/9200 1\n",
      "netapp 1\n",
      "clustered 1\n",
      "ontap 1\n",
      "demonstrated 20\n",
      "scripting 15\n",
      "microsoft 13\n",
      "onedrive 1\n",
      "certifications 10\n",
      "one 77\n",
      "more 62\n",
      "preferred 84\n",
      "linux 9\n",
      "aix 1\n",
      "windows 3\n",
      "server 12\n",
      "vmware 31\n",
      "cisco 16\n",
      "ucs 1\n",
      "automation 16\n",
      "orchestration 7\n",
      "automation/orchestration 1\n",
      "products 32\n",
      "vulnerability 3\n",
      "full 41\n",
      "life-cycle 1\n",
      "o 7\n",
      "lead 17\n",
      "teams 56\n",
      "scope 6\n",
      "schedule 22\n",
      "cost 4\n",
      "communications 22\n",
      "plan/scope/schedule/cost/communications 1\n",
      "procure 1\n",
      "timelines 1\n",
      "deadlines 7\n",
      "resources/timelines/deadlines/quality 1\n",
      "risk 6\n",
      "issue 4\n",
      "responsibility 10\n",
      "guide 6\n",
      "less 2\n",
      "input 4\n",
      "budgetary 2\n",
      "regarding 7\n",
      "staffing 2\n",
      "equipment 14\n",
      "enhancement 1\n",
      "existing 14\n",
      "document 16\n",
      "components 6\n",
      "modifications 1\n",
      "integrity 12\n",
      "compliance 21\n",
      "tasks 21\n",
      "assignments 8\n",
      "technology 72\n",
      "procurement 1\n",
      "deployment 14\n",
      "configuration 10\n",
      "modified 1\n",
      "architecture 34\n",
      "discipline 7\n",
      "development 115\n",
      "organized 3\n",
      "all 143\n",
      "through 45\n",
      "variety 33\n",
      "media 7\n",
      "significant 3\n",
      "guiding 2\n",
      "coaching 3\n",
      "professional 40\n",
      "organizational 14\n",
      "exercising 1\n",
      "initiative 5\n",
      "sound 2\n",
      "database 36\n",
      "presentation 4\n",
      "software 75\n",
      "solving 17\n",
      "verbal 13\n",
      "written 19\n",
      "processing 28\n",
      "spreadsheet 2\n",
      "0800 1\n",
      "– 34\n",
      "1630 1\n",
      "participate 14\n",
      "rotation 3\n",
      "requiring 3\n",
      "periodic 1\n",
      "24x7 3\n",
      "on-call 1\n",
      "coverage 11\n",
      "off-hours 1\n",
      "weekend 4\n",
      "maintenance 27\n",
      "needed 11\n",
      "onsite 5\n",
      "campuses 2\n",
      "virginia 5\n",
      "pensacola 1\n",
      "florida 1\n",
      "teleworking 2\n",
      "case-by-case 3\n",
      "annual 9\n",
      "24 3\n",
      "$70,000 1\n",
      "$110,000 2\n",
      "jnr 1\n",
      "read 6\n",
      "beautiful 1\n",
      "bethesda 5\n",
      "md 17\n",
      "centric 1\n",
      "driven 7\n",
      "tech 13\n",
      "company 43\n",
      "specializes 3\n",
      "serving 5\n",
      "institutions 8\n",
      "empower 7\n",
      "institutional 2\n",
      "effectiveness 3\n",
      "benchmarking 3\n",
      "via 11\n",
      "growth 23\n",
      "demand 3\n",
      "doing 7\n",
      "joining 6\n",
      "impressive 1\n",
      "fast 10\n",
      "paced 4\n",
      "collaborative 14\n",
      "built 3\n",
      "developers 13\n",
      "analysts 14\n",
      "dedicated 3\n",
      "success 19\n",
      "currently 12\n",
      "fully 19\n",
      "remote 40\n",
      "covid 3\n",
      "occasional 3\n",
      "when 21\n",
      "1+ 10\n",
      "year 64\n",
      "s 12\n",
      "year(s 1\n",
      "$80k 1\n",
      "$110k 1\n",
      "health 38\n",
      "vision 37\n",
      "dental 28\n",
      "401 22\n",
      "k 22\n",
      "401(k 22\n",
      "w 2\n",
      "comapny 1\n",
      "w/comapny 1\n",
      "match 8\n",
      "wfh 1\n",
      "flexibility 12\n",
      "pto 9\n",
      "package 27\n",
      "interested 6\n",
      "orientated 1\n",
      "cutting 1\n",
      "edge 4\n",
      "incredible 2\n",
      "benefits 97\n",
      "flexible 31\n",
      "come 4\n",
      "show 5\n",
      "off 23\n",
      "see 10\n",
      "how 42\n",
      "department 4\n",
      "even 7\n",
      "than 10\n",
      "already 1\n",
      "go 8\n",
      "now 7\n",
      "colorado 4\n",
      "receive 25\n",
      "sick 8\n",
      "leave 24\n",
      "available 25\n",
      "andy 1\n",
      "prickett 1\n",
      "applicants 43\n",
      "authorized 7\n",
      "u.s 27\n",
      "cybercoders 1\n",
      "inc 11\n",
      "proud 9\n",
      "employer 37\n",
      "consideration 25\n",
      "without 25\n",
      "regard 22\n",
      "race 36\n",
      "color 31\n",
      "religion 27\n",
      "sex 28\n",
      "national 38\n",
      "origin 33\n",
      "status 94\n",
      "any 53\n",
      "characteristic 7\n",
      "law 17\n",
      "persons 2\n",
      "hired 7\n",
      "verify 5\n",
      "identity 31\n",
      "eligibility 17\n",
      "united 24\n",
      "states 29\n",
      "complete 27\n",
      "verification 6\n",
      "upon 10\n",
      "hire 31\n",
      "today 17\n",
      "$82,400 1\n",
      "$123,600 1\n",
      "requisition 2\n",
      "id 1\n",
      "r10038357 1\n",
      "category 13\n",
      "falls 2\n",
      "church 2\n",
      "america 16\n",
      "citizenship 14\n",
      "clearance 24\n",
      "type 27\n",
      "none 1\n",
      "telecommute 2\n",
      "yes 8\n",
      "consider 8\n",
      "shift 17\n",
      "1st 1\n",
      "travel 8\n",
      "no 20\n",
      "positions 9\n",
      "3 31\n",
      "northrop 6\n",
      "grumman 5\n",
      "revolutionary 3\n",
      "impact 25\n",
      "peoples 2\n",
      "around 16\n",
      "world 35\n",
      "generations 1\n",
      "pioneering 4\n",
      "inventive 1\n",
      "spirit 2\n",
      "has 39\n",
      "enabled 1\n",
      "forefront 2\n",
      "many 12\n",
      "technological 6\n",
      "advancements 1\n",
      "nations 6\n",
      "history 10\n",
      "first 17\n",
      "flight 6\n",
      "atlantic 1\n",
      "ocean 1\n",
      "stealth 1\n",
      "bombers 1\n",
      "landing 1\n",
      "moon 1\n",
      "look 4\n",
      "bold 4\n",
      "ideas 10\n",
      "courage 2\n",
      "invent 2\n",
      "fun 6\n",
      "along 9\n",
      "culture 29\n",
      "thrives 1\n",
      "intellectual 5\n",
      "curiosity 6\n",
      "cognitive 5\n",
      "bringing 8\n",
      "whole 1\n",
      "self 7\n",
      "— 6\n",
      "insatiable 1\n",
      "drive 18\n",
      "others 15\n",
      "think 13\n",
      "impossible 1\n",
      "part 28\n",
      "they're 1\n",
      "continued 5\n",
      "push 8\n",
      "boundaries 4\n",
      "land 1\n",
      "sea 1\n",
      "air 1\n",
      "space 10\n",
      "cyberspace 1\n",
      "enjoy 4\n",
      "where 33\n",
      "voice 9\n",
      "start 8\n",
      "contributing 5\n",
      "professionals 15\n",
      "providing 21\n",
      "real-life 1\n",
      "worlds 5\n",
      "biggest 2\n",
      "challenges 21\n",
      "pride 2\n",
      "purposeful 1\n",
      "allowing 2\n",
      "grow 13\n",
      "achieve 10\n",
      "every 27\n",
      "day 21\n",
      "defining 2\n",
      "pay 32\n",
      "comprehensive 19\n",
      "fit 8\n",
      "life 37\n",
      "launch 1\n",
      "career 27\n",
      "engineers 32\n",
      "located 7\n",
      "sector 4\n",
      "pathways 3\n",
      "rotational 1\n",
      "there 5\n",
      "three 5\n",
      "become 9\n",
      "grummans 1\n",
      "next 10\n",
      "gen 1\n",
      "meet 50\n",
      "below 13\n",
      "criteria 5\n",
      "completing 4\n",
      "completed 10\n",
      "masters 7\n",
      "accredited 10\n",
      "institution 5\n",
      "overall 13\n",
      "cumulative 2\n",
      "gpa 3\n",
      "3.0 2\n",
      "4.0 2\n",
      "unofficial 4\n",
      "academic 6\n",
      "transcripts 2\n",
      "provided 37\n",
      "application 86\n",
      "uploading 1\n",
      "documents 27\n",
      "profile 2\n",
      "able 22\n",
      "obtain 14\n",
      "government 41\n",
      "pre-requisite 1\n",
      "3.70 1\n",
      "3.70/4.0 1\n",
      "82,400 1\n",
      "123,600 1\n",
      "discretionary 2\n",
      "bonus 10\n",
      "addition 17\n",
      "base 5\n",
      "bonuses 2\n",
      "designed 15\n",
      "reward 2\n",
      "contributions 10\n",
      "well 47\n",
      "allow 5\n",
      "share 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vice 1\n",
      "president 1\n",
      "director 4\n",
      "long 5\n",
      "term 5\n",
      "incentives 3\n",
      "insurance 55\n",
      "savings 8\n",
      "holidays 8\n",
      "vacation 6\n",
      "personal 13\n",
      "priority 6\n",
      "continuing 2\n",
      "impacts 4\n",
      "taking 6\n",
      "well-being 8\n",
      "colleagues 7\n",
      "communities 14\n",
      "operate 9\n",
      "contractor 7\n",
      "consistent 8\n",
      "order 21\n",
      "14042 3\n",
      "https: 15\n",
      " 21\n",
      "www.saferfederalworkforce.gov 1\n",
      "contractors 5\n",
      "https://www.saferfederalworkforce.gov/contractors 1\n",
      "newly 4\n",
      "vaccinated 16\n",
      "guidance 15\n",
      "allows 4\n",
      "medical 43\n",
      "disability/medical 1\n",
      "religious 15\n",
      "accommodations 10\n",
      "respect 3\n",
      "requirement 9\n",
      "requested 3\n",
      "reviewed 13\n",
      "approved 3\n",
      "applicable 18\n",
      "committed 27\n",
      "retaining 3\n",
      "diverse 31\n",
      "workforce 3\n",
      "opportunity/affirmative 6\n",
      "creed 10\n",
      "sexual 29\n",
      "orientation 32\n",
      "gender 44\n",
      "marital 16\n",
      "age 27\n",
      "class 6\n",
      "eeo 8\n",
      "eeo/aa 1\n",
      "transparency 5\n",
      "statement 15\n",
      "visit 13\n",
      "http: 6\n",
      "www.northropgrumman.com 1\n",
      "http://www.northropgrumman.com/eeo 1\n",
      "$140,000 6\n",
      "yearfull 6\n",
      "addison 1\n",
      "group 12\n",
      "client 24\n",
      "arlington 6\n",
      "bring 11\n",
      "sr 5\n",
      "administrators 3\n",
      "modernizing 1\n",
      "utilizes 1\n",
      "google 14\n",
      "gcp 8\n",
      "snowflake 13\n",
      "involved 2\n",
      "evolution 4\n",
      "ideal 13\n",
      "sets 31\n",
      "hands 11\n",
      "desire 12\n",
      "continue 9\n",
      "learning 47\n",
      "problems 33\n",
      "ownership 6\n",
      "efficient 8\n",
      "subject 8\n",
      "layer 3\n",
      "deep 8\n",
      "pipeline 24\n",
      "play 11\n",
      "discussions 2\n",
      "high-volume 2\n",
      "low-latency 1\n",
      "applications 30\n",
      "mission-critical 3\n",
      "delivering 9\n",
      "high-availability 1\n",
      "established 7\n",
      "champion 4\n",
      "continuous 15\n",
      "improvement 17\n",
      "delegate 1\n",
      "appropriate 9\n",
      "contribute 7\n",
      "phases 5\n",
      "lifecycle 7\n",
      "deliver 18\n",
      "timely 4\n",
      "testable 1\n",
      "code 25\n",
      "designs 3\n",
      "specifications 12\n",
      "dev-ops 1\n",
      "mindset 6\n",
      "investigating 1\n",
      "alternatives 4\n",
      "presenting 2\n",
      "these 24\n",
      "architectural 2\n",
      "review 17\n",
      "minimum 32\n",
      "4+ 3\n",
      "commercial 6\n",
      "warehouses 11\n",
      "marts 4\n",
      "2+ 13\n",
      "bigquery 5\n",
      "redshift 20\n",
      "apis 10\n",
      "hands-on 26\n",
      "proficiency 6\n",
      "ssis 3\n",
      "jobs 3\n",
      "stored 2\n",
      "track 5\n",
      "record 12\n",
      "shipping 1\n",
      "learn 31\n",
      "belief 4\n",
      "automated 11\n",
      "agile 29\n",
      "sdlc 5\n",
      "access 28\n",
      "private 4\n",
      "quiet 1\n",
      "high-speed 1\n",
      "internet 4\n",
      "effectively 18\n",
      "remotely 11\n",
      "interpersonal 6\n",
      "collaboratively 6\n",
      "multi-location 1\n",
      "cross-functional 11\n",
      "levels 5\n",
      "excellent 22\n",
      "necessary 13\n",
      "interact 7\n",
      "owners 2\n",
      "competing 1\n",
      "priorities 7\n",
      "attention 16\n",
      "detail 14\n",
      "problem-solving 3\n",
      "adaptable 3\n",
      "ind 1\n",
      "005-009 1\n",
      "zr 1\n",
      "detailssalaryfrom 1\n",
      "$75 1\n",
      "hourjob 6\n",
      "typefull-timecontractqualificationsbachelors 1\n",
      "required)full 3\n",
      "aws 90\n",
      "immediate 2\n",
      "opening 1\n",
      "specializing 1\n",
      "creative 21\n",
      "engagement 5\n",
      "saas 3\n",
      "paas 3\n",
      "implementations 3\n",
      "focus 15\n",
      "environments 11\n",
      "hosted 2\n",
      "forward-thinking 2\n",
      "cloud-focused 1\n",
      "architect 22\n",
      "specifically 5\n",
      "focusing 3\n",
      "hosting 3\n",
      "being 13\n",
      "balanced 3\n",
      "mix 2\n",
      "“as 1\n",
      "service” 1\n",
      "integral 5\n",
      "member 9\n",
      "context 5\n",
      "customers 33\n",
      "functions 13\n",
      "elicit 1\n",
      "alignment 1\n",
      "translate 2\n",
      "feasible 1\n",
      "solution 13\n",
      "deployments 4\n",
      "assist 18\n",
      "relational 18\n",
      "non-relational 3\n",
      "databases 45\n",
      "mysql 6\n",
      "ms 9\n",
      "rds 11\n",
      "nosql 12\n",
      "packages 9\n",
      "connecting 4\n",
      "running 5\n",
      "production 23\n",
      "workload 7\n",
      "transition 4\n",
      "retired 1\n",
      "proposed 4\n",
      "to‐be 1\n",
      "consisting 1\n",
      "staging 2\n",
      "leverages 2\n",
      "virtualization 3\n",
      "computing 2\n",
      "associate 3\n",
      "certification 21\n",
      "past 5\n",
      "certified 7\n",
      "specialty 4\n",
      "emphasis 7\n",
      "executing 4\n",
      "supporting 27\n",
      "lakes 7\n",
      "scale 12\n",
      "workloads 2\n",
      "movement 2\n",
      "informatica 9\n",
      "glue 9\n",
      "cognos 1\n",
      "pass 6\n",
      "background 24\n",
      "check 12\n",
      "cjis 1\n",
      "willingness 4\n",
      "self-study 1\n",
      "multi-task 4\n",
      "prioritize 4\n",
      "mentors 1\n",
      "coach 4\n",
      "colleague 1\n",
      "seeks 5\n",
      "great 14\n",
      "scrum 4\n",
      "agile/scrum 1\n",
      "avid 6\n",
      "washington 35\n",
      "dc 23\n",
      "global 39\n",
      "managed 4\n",
      "provider 10\n",
      "mobility 3\n",
      "cyber 5\n",
      "combines 2\n",
      "unparalleled 4\n",
      "industries 3\n",
      "innovation 20\n",
      "rapid 6\n",
      "transformation 11\n",
      "been 10\n",
      "themes 1\n",
      "systems’ 1\n",
      "traces 1\n",
      "2004 2\n",
      "quite 1\n",
      "simple 3\n",
      "highest 6\n",
      "consulting 19\n",
      "rates 1\n",
      "while 16\n",
      "dedication 1\n",
      "rare 1\n",
      "expertise 25\n",
      "everyday 2\n",
      "face 2\n",
      "succeed 4\n",
      "failed 1\n",
      "closing 5\n",
      "gap 1\n",
      "todays 1\n",
      "enhance 9\n",
      "corporate 5\n",
      "focused 6\n",
      "anticipate 5\n",
      "efficiency 8\n",
      "relentless 2\n",
      "exceeding 1\n",
      "expectations 4\n",
      "principle 3\n",
      "commitment 14\n",
      "earned 10\n",
      "trust 15\n",
      "earn 2\n",
      "ethical 1\n",
      "traditional 5\n",
      "honesty 3\n",
      "reasons 3\n",
      "why 9\n",
      "place 17\n",
      "believe 17\n",
      "starts 2\n",
      "ends 1\n",
      "get 12\n",
      "classes 2\n",
      "latest 5\n",
      "types 14\n",
      "full-time 28\n",
      "contract 19\n",
      "$75.00 1\n",
      "per 47\n",
      "hour 16\n",
      "assistance 25\n",
      "8 17\n",
      "commute 8\n",
      "relocate 10\n",
      "commute/relocate 4\n",
      "20001 1\n",
      "reliably 4\n",
      "before 7\n",
      "starting 9\n",
      "question 4\n",
      "question(s 3\n",
      "license 7\n",
      "license/certification 3\n",
      "insightshiring 9\n",
      "1 28\n",
      "roleurgently 7\n",
      "hiringjob 7\n",
      "4 22\n",
      "$126,233 1\n",
      "$164,102 3\n",
      "efforts 17\n",
      "oversee 1\n",
      "projects/programs 1\n",
      "involve 2\n",
      "ground 11\n",
      "definition 4\n",
      "hardware 11\n",
      "test 20\n",
      "evaluation 8\n",
      "segment 2\n",
      "associated 9\n",
      "simulators 2\n",
      "baseline 3\n",
      "approach 9\n",
      "monitoring 19\n",
      "multi-disciplinary 3\n",
      "long-term 13\n",
      "integrate 9\n",
      "coordinate 5\n",
      "agency 14\n",
      "personnel 8\n",
      "subsystem 2\n",
      "assess 1\n",
      "progress 3\n",
      "relation 4\n",
      "allotted 1\n",
      "offices 11\n",
      "content 5\n",
      "resource 6\n",
      "budget 1\n",
      "schedules 9\n",
      "conditions 9\n",
      "open 18\n",
      "citizens 4\n",
      "nationals 2\n",
      "owe 2\n",
      "allegiance 2\n",
      "pre-employment 1\n",
      "investigation 10\n",
      "announcement 23\n",
      "selected 9\n",
      "financial 22\n",
      "disclosure 1\n",
      "trial 1\n",
      "period 14\n",
      "section 5\n",
      "qualify 4\n",
      "specialized 7\n",
      "equipped 1\n",
      "particular 2\n",
      "competencies 7\n",
      "successfully 6\n",
      "described 3\n",
      "above 17\n",
      "gs-14 1\n",
      "gs-13 1\n",
      "assisting 2\n",
      "hardware/software 2\n",
      "interfaces 1\n",
      "prototype 2\n",
      "prototype/test 1\n",
      "bed 1\n",
      "preparing 3\n",
      "reviewing 3\n",
      "expected 6\n",
      "estimates 2\n",
      "establishing 3\n",
      "long-range 1\n",
      "agendas 1\n",
      "evaluations 1\n",
      "trade 1\n",
      "studies 3\n",
      "advising 1\n",
      "advances 1\n",
      "resume 21\n",
      "detailed 4\n",
      "narrative 1\n",
      "words 1\n",
      "statements 2\n",
      "copied 1\n",
      "vacancy 8\n",
      "reference 2\n",
      "material 1\n",
      "constitutes 1\n",
      "plagiarism 1\n",
      "result 8\n",
      "disqualification 3\n",
      "losing 1\n",
      "selections 1\n",
      "made 8\n",
      "similar 12\n",
      "nasa 7\n",
      "local 20\n",
      "commuting 3\n",
      "area 12\n",
      "area(s 1\n",
      "location(s 1\n",
      "identified 2\n",
      "agree 3\n",
      "shared 4\n",
      "selecting 1\n",
      "official 6\n",
      "official(s 1\n",
      "ctap 9\n",
      "ictap 9\n",
      "ctap/ictap 5\n",
      "cleared 2\n",
      "selection 5\n",
      "college 11\n",
      "university 22\n",
      "abet 3\n",
      "b 1\n",
      "mathematics 12\n",
      "note 4\n",
      "curriculum 2\n",
      "30 8\n",
      "semester 6\n",
      "course 9\n",
      "statistics 10\n",
      "15 2\n",
      "includes 20\n",
      "differential 1\n",
      "calculus 1\n",
      "did 1\n",
      "qualifying 7\n",
      "obtained 1\n",
      "graduate 2\n",
      "ast 1\n",
      "degrees 10\n",
      "find 9\n",
      "school 6\n",
      "www.abet.org 2\n",
      "http://www.abet.org 1\n",
      "outside 9\n",
      "recognized 6\n",
      "mutual 2\n",
      "recognition 1\n",
      "agreement 1\n",
      "mra 1\n",
      "often 2\n",
      "known 3\n",
      "accords 1\n",
      "non-governmental 1\n",
      "agreements 1\n",
      "among 6\n",
      "organizations 21\n",
      "accredit 1\n",
      "mras 1\n",
      "substantial 4\n",
      "equivalence 1\n",
      "mature 3\n",
      "accreditation 4\n",
      "signatory 1\n",
      "jurisdictions 2\n",
      "listing 1\n",
      "signatories 1\n",
      "global-presence 1\n",
      "mutual-recognition-agreements 1\n",
      "is-your-program-recognized 1\n",
      "https://www.abet.org/global-presence/mutual-recognition-agreements/is-your-program-recognized 1\n",
      "awarded 1\n",
      "colleges 3\n",
      "universities 3\n",
      "accrediting 1\n",
      "list 7\n",
      "schools 3\n",
      "ope.ed.gov 1\n",
      "http://ope.ed.gov/accreditation 1\n",
      "foreign 3\n",
      "qualification 1\n",
      "credentials 4\n",
      "evaluated 7\n",
      "interpretation 2\n",
      "deemed 2\n",
      "gained 1\n",
      "given 4\n",
      "courses 4\n",
      "further 6\n",
      "www2.ed.gov 1\n",
      "ous 1\n",
      "international 7\n",
      "usnei 1\n",
      "edlite-visitus-forrecog.html 1\n",
      "https://www2.ed.gov/about/offices/list/ous/international/usnei/us/edlite-visitus-forrecog.html 1\n",
      "received 3\n",
      "subsequent 2\n",
      "original 2\n",
      "request 16\n",
      "purposes 2\n",
      "masking 3\n",
      "quarantine 1\n",
      "expanded 1\n",
      "telework 5\n",
      "posture 2\n",
      "permitted 1\n",
      "office 7\n",
      "duty 7\n",
      "station 2\n",
      "depending 5\n",
      "terms 4\n",
      "agencys 1\n",
      "policy 12\n",
      "appointed 1\n",
      "converted 1\n",
      "permanent 4\n",
      "appointment 4\n",
      "non-competitively 1\n",
      "placement 4\n",
      "conversion 1\n",
      "guaranteed 1\n",
      "contingent 3\n",
      "meeting 4\n",
      "legal 6\n",
      "nasapeople.nasa.gov 1\n",
      "hclwp 1\n",
      "term-appointments.htm 1\n",
      "nasapeople.nasa.gov/hclwp/term-appointments.htm 1\n",
      "civilian 4\n",
      "break 1\n",
      "calendar 1\n",
      "prior 21\n",
      "special 6\n",
      "rights 4\n",
      "interagency 2\n",
      "indicate 2\n",
      "questionnaire 14\n",
      "asks 1\n",
      "ictap/ctap 1\n",
      "rated 1\n",
      "well-qualified 1\n",
      "submit 22\n",
      "indicated 1\n",
      "click 5\n",
      "www.opm.gov 1\n",
      "policy-data-oversight 1\n",
      "workforce-restructuring 1\n",
      "employee-guide-to-career-transition 1\n",
      "#ictap 1\n",
      "https://www.opm.gov/policy-data-oversight/workforce-restructuring/employee-guide-to-career-transition/#ictap 1\n",
      "reasonable 21\n",
      "accommodation 23\n",
      "requests 9\n",
      "mental 9\n",
      "covered 7\n",
      "rehabilitation 2\n",
      "1973 1\n",
      "amended 2\n",
      "americans 3\n",
      "1990 1\n",
      "would 5\n",
      "interfere 1\n",
      "usa 16\n",
      "competency 10\n",
      "assessments 21\n",
      "granted 2\n",
      "online 19\n",
      "documentation 43\n",
      "after 14\n",
      "notification 4\n",
      "adjudication 1\n",
      "email 12\n",
      "invitation 2\n",
      "48 2\n",
      "receiving 2\n",
      "url 3\n",
      "close 5\n",
      "requesting 3\n",
      "here 8\n",
      "help.usastaffing.gov 4\n",
      "index.php?title=reasonable_accommodations_for_usa_hire 3\n",
      "https://help.usastaffing.gov/apply/index.php?title=reasonable_accommodations_for_usa_hire 3\n",
      "very 7\n",
      "rewarding 3\n",
      "opens 2\n",
      "windowlearn 2\n",
      "depends 3\n",
      "hold 3\n",
      "whether 9\n",
      "part-time 4\n",
      "intermittent 3\n",
      "offered 4\n",
      "compare 1\n",
      "responses 4\n",
      "materials 6\n",
      "e.g 31\n",
      "assessed 2\n",
      "following 27\n",
      "evaluating 1\n",
      "competence 1\n",
      "program/project 1\n",
      "integrity/honesty 1\n",
      "reading 2\n",
      "reasoning 4\n",
      "self-management 1\n",
      "achievement 2\n",
      "stress 1\n",
      "tolerance 1\n",
      "teamwork 2\n",
      "steps 3\n",
      "requires 13\n",
      "critical 28\n",
      "general 6\n",
      "overstating 1\n",
      "removal 3\n",
      "cheating 1\n",
      "considers 1\n",
      "unpaid 2\n",
      "volunteer 7\n",
      "done 2\n",
      "peace 1\n",
      "corps 5\n",
      "americorps 1\n",
      "philanthropic 3\n",
      "spiritual 5\n",
      "student 5\n",
      "helps 5\n",
      "valuable 3\n",
      "translates 1\n",
      "nasas 1\n",
      "rating 3\n",
      "placed 1\n",
      "categories 1\n",
      "defined 8\n",
      "demonstrate 15\n",
      "superior 2\n",
      "satisfactory 1\n",
      "abilities 8\n",
      "names 2\n",
      "unless 3\n",
      "sufficient 2\n",
      "number 9\n",
      "found 5\n",
      "case 4\n",
      "initially 1\n",
      "over 18\n",
      "non-veteran 1\n",
      "eligibles 1\n",
      "depend 1\n",
      "you're 5\n",
      "temporary 1\n",
      "however 4\n",
      "sure 8\n",
      "completion 7\n",
      "describe 4\n",
      "answers 5\n",
      "transcript 8\n",
      "items 4\n",
      "picture 2\n",
      "scan 3\n",
      "credited 2\n",
      "completed/credited 2\n",
      "title 8\n",
      "quarter 2\n",
      "classroom 2\n",
      "each 11\n",
      "buad 2\n",
      "101-introduction 2\n",
      "lose 4\n",
      "incomplete 2\n",
      "coursework 2\n",
      "licenses 3\n",
      "surplus 2\n",
      "displaced 2\n",
      "copies 2\n",
      "notice 2\n",
      "recent 4\n",
      "sf-50 2\n",
      "noting 2\n",
      "claiming 2\n",
      "dd214 2\n",
      "certificate 3\n",
      "release 5\n",
      "active 14\n",
      "shows 6\n",
      "dates 2\n",
      "discharge 2\n",
      "honorable 2\n",
      "fedshirevets 2\n",
      "begin 6\n",
      "encourage 6\n",
      "educational 10\n",
      "achievements 3\n",
      "non-paid 1\n",
      "portion 1\n",
      "does 11\n",
      "contain 2\n",
      "initial 3\n",
      "submission 2\n",
      "specified 3\n",
      "submitted 4\n",
      "11:59 1\n",
      "pm 2\n",
      "et 2\n",
      "follows 3\n",
      "button 2\n",
      "logged 1\n",
      "usajobs 8\n",
      "account 19\n",
      "create 38\n",
      "beginning 2\n",
      "2 20\n",
      "prompts 1\n",
      "select 2\n",
      "included 2\n",
      "answer 6\n",
      "questions 16\n",
      "attach 1\n",
      "edit 1\n",
      "delete 1\n",
      "update 9\n",
      "we'll 1\n",
      "automatically 2\n",
      "save 4\n",
      "so 8\n",
      "won't 2\n",
      "changes 11\n",
      "uploaded 1\n",
      "several 2\n",
      "virus 2\n",
      "acknowledging 1\n",
      "deem 1\n",
      "taken 1\n",
      "11:59pm 1\n",
      "5 20\n",
      "submitting 2\n",
      "notified 1\n",
      "message 2\n",
      "delivered 2\n",
      "routed 1\n",
      "spam 1\n",
      "junk 1\n",
      "folder 1\n",
      "6 10\n",
      "asked 2\n",
      "unique 4\n",
      "login 3\n",
      "index.php?title=usa_hire_system_requirements 1\n",
      "https://help.usastaffing.gov/apply/index.php?title=usa_hire_system_requirements 1\n",
      "7 7\n",
      "set 13\n",
      "aside 1\n",
      "stop 1\n",
      "later 2\n",
      "re-use 1\n",
      "page 4\n",
      "some 12\n",
      "assessing 2\n",
      "characteristics 5\n",
      "mentioned 3\n",
      "allowed 1\n",
      "my.usajobs.gov 2\n",
      "https://my.usajobs.gov/account/login 2\n",
      "option 6\n",
      "longer 1\n",
      "closed 1\n",
      "toll 1\n",
      "free 6\n",
      "phone 6\n",
      "advised 1\n",
      "faxed 1\n",
      "emailed 1\n",
      "mailed 1\n",
      "goddard 2\n",
      "center 46\n",
      "accepted 2\n",
      "1-877-677-2123 1\n",
      "fax 1\n",
      "1-866-779-6772 1\n",
      "nssc-contactcenter@mail.nasa.gov 1\n",
      "address 12\n",
      "8800 1\n",
      "greenbelt 2\n",
      "rd 1\n",
      "20771 1\n",
      "ada 1\n",
      "updated 4\n",
      "last 3\n",
      "12 7\n",
      "months 4\n",
      "invited 1\n",
      "again 2\n",
      "previous 4\n",
      "scores 1\n",
      "utilized 1\n",
      "upgraded 3\n",
      "kept 2\n",
      "toward 4\n",
      "might 2\n",
      "same 4\n",
      "acknowledgement 1\n",
      "updates 6\n",
      "log 2\n",
      "appear 2\n",
      "welcome 1\n",
      "correspondence 1\n",
      "means 4\n",
      "www.usajobs.gov 1\n",
      "help 58\n",
      "how-to 1\n",
      "https://www.usajobs.gov/help/how-to/application/status 1\n",
      "manager 13\n",
      "contacted 1\n",
      "interview 11\n",
      "fair 6\n",
      "transparent 4\n",
      "setup 2\n",
      "suitability 1\n",
      "selective 1\n",
      "probationary 1\n",
      "signature 1\n",
      "false 1\n",
      "privacy 7\n",
      "public 29\n",
      "$66,077 2\n",
      "consumers 7\n",
      "populate 2\n",
      "optimal 9\n",
      "architectures 20\n",
      "cias 2\n",
      "domestic 5\n",
      "cia 6\n",
      "consumed 1\n",
      "integrated 10\n",
      "different 14\n",
      "entities 5\n",
      "digital 17\n",
      "throughput 1\n",
      "query 10\n",
      "constantly 4\n",
      "network 20\n",
      "bandwidth 1\n",
      "bus 1\n",
      "implications 2\n",
      "additionally 6\n",
      "backend 3\n",
      "hpc 1\n",
      "utilization 2\n",
      "actual 3\n",
      "volume 2\n",
      "periodicity 1\n",
      "intended 1\n",
      "kinds 1\n",
      "responsiveness 1\n",
      "you’ll 19\n",
      "strength 4\n",
      "comes 4\n",
      "its 16\n",
      "backgrounds 11\n",
      "viewpoints 1\n",
      "reason 1\n",
      "country 8\n",
      "safe 8\n",
      "inclusion 10\n",
      "aspect 3\n",
      "wellness 3\n",
      "finances 1\n",
      "sought-after 1\n",
      "childcare 3\n",
      "cases 8\n",
      "offer 24\n",
      "sign-on 1\n",
      "cover 6\n",
      "moving 2\n",
      "expenses 2\n",
      "satisfaction 1\n",
      "knowing 1\n",
      "something 2\n",
      "bigger 3\n",
      "yourself 2\n",
      "nation 2\n",
      "fields 3\n",
      "archives 1\n",
      "digitization 1\n",
      "archives/digitization 1\n",
      "computer/data 1\n",
      "information/data/knowledge 1\n",
      "4-point 1\n",
      "manipulation 1\n",
      "letter 5\n",
      "specify 1\n",
      "differentiates 1\n",
      "detailsjob 35\n",
      "assume 1\n",
      "properly 2\n",
      "correctly 2\n",
      "plant 1\n",
      "electrical 9\n",
      "mechanical 5\n",
      "availability 11\n",
      "delivery 18\n",
      "consistently 4\n",
      "supports 11\n",
      "kaiser 5\n",
      "permanentes 2\n",
      "adhering 2\n",
      "state 27\n",
      "laws 10\n",
      "licenser 1\n",
      "accountable 6\n",
      "demonstrating 3\n",
      "behaviors 4\n",
      "permanente 6\n",
      "credo 1\n",
      "kp 1\n",
      "departmental 2\n",
      "departmental/organizational 1\n",
      "culturally 3\n",
      "sensitive 2\n",
      "purchasers 1\n",
      "contracted 1\n",
      "providers 5\n",
      "vendors 3\n",
      "engineering-related 2\n",
      "limited 9\n",
      "hvac 1\n",
      "chillers 2\n",
      "boilers 1\n",
      "room 4\n",
      "ac 2\n",
      "units 2\n",
      "pumps 1\n",
      "strainers 1\n",
      "controls 7\n",
      "water 1\n",
      "treatment 1\n",
      "ups 2\n",
      "pdus 1\n",
      "generators 2\n",
      "switchgear 1\n",
      "plumbing 2\n",
      "condensate 1\n",
      "fuel 1\n",
      "oil 1\n",
      "control 13\n",
      "bas 1\n",
      "bms 1\n",
      "fire 2\n",
      "fire/life 1\n",
      "alarms 1\n",
      "suppression 1\n",
      "pc 1\n",
      "tracking 3\n",
      "accordance 10\n",
      "designated 3\n",
      "awareness 1\n",
      "carry 4\n",
      "routine 3\n",
      "preventive 1\n",
      "directed 7\n",
      "corrective 1\n",
      "facility 10\n",
      "facility/building 1\n",
      "rounds 1\n",
      "scheduled 5\n",
      "promptly 1\n",
      "equipment/system 1\n",
      "anomalies 3\n",
      "noted 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "immediately 1\n",
      "hazardous 1\n",
      "encountered 3\n",
      "unsafe 1\n",
      "observed 1\n",
      "logs 1\n",
      "readings 1\n",
      "histories 2\n",
      "store 2\n",
      "spare 1\n",
      "parts 4\n",
      "general-use 1\n",
      "prescribed 1\n",
      "escort 1\n",
      "access/escort 1\n",
      "subcontractors 3\n",
      "actively 1\n",
      "emergency 6\n",
      "drills 1\n",
      "scenario 1\n",
      "exercises 1\n",
      "respond 2\n",
      "quickly 5\n",
      "appropriately 2\n",
      "emergencies 1\n",
      "occurring 1\n",
      "accidents 1\n",
      "courteously 1\n",
      "evening 2\n",
      "weekend/evening 1\n",
      "shifts 3\n",
      "repairs 3\n",
      "said 2\n",
      "authorization 9\n",
      "cfwa 1\n",
      "procedure 3\n",
      "mop 1\n",
      "operating 10\n",
      "sop 1\n",
      "eop 1\n",
      "maintenance/operations 1\n",
      "accompanying 1\n",
      "took 1\n",
      "mandated 1\n",
      "maryland 12\n",
      "performs 5\n",
      "supervisor 2\n",
      "eight 1\n",
      "centers 12\n",
      "hub 1\n",
      "diploma 3\n",
      "heating 1\n",
      "cooling 1\n",
      "in-depth 3\n",
      "codes 1\n",
      "registration 1\n",
      "stationary 1\n",
      "universal 1\n",
      "cfc 2\n",
      "licensing 1\n",
      "dc/va 1\n",
      "blueprints 1\n",
      "schematic 1\n",
      "drawings 1\n",
      "manuals 1\n",
      "attained 1\n",
      "willing 3\n",
      "iuoe 1\n",
      "four-year 2\n",
      "apprentice 1\n",
      "journeyman 2\n",
      "electrical/mechanical 1\n",
      "crafts 1\n",
      "documented 4\n",
      "fundamentals 1\n",
      "primarylocation 1\n",
      "maryland,silver 1\n",
      "spring,silver 1\n",
      "spring 4\n",
      "hoursperweek 1\n",
      "40 5\n",
      "night 2\n",
      "workdays 1\n",
      "tue 1\n",
      "wed 1\n",
      "thu 1\n",
      "fri 1\n",
      "sat 1\n",
      "workinghoursstart 1\n",
      "10:00 1\n",
      "workinghoursend 1\n",
      "06:30 1\n",
      "am 2\n",
      "group/union 1\n",
      "affiliation 7\n",
      "m41|iuoe|local 1\n",
      "99 1\n",
      "silver 3\n",
      "ito 1\n",
      "ips 1\n",
      "dco 1\n",
      "fm 1\n",
      "ssdc 1\n",
      "1808 1\n",
      "inclusive 10\n",
      "pregnancy 16\n",
      "parental 15\n",
      "ancestry 7\n",
      "genetic 13\n",
      "distinguishing 1\n",
      "$90,000 8\n",
      "posting 2\n",
      "details 3\n",
      "127092 1\n",
      "33-exempt 1\n",
      "applicant 4\n",
      "search 3\n",
      "fte 1\n",
      "1.00 1\n",
      "unit 7\n",
      "dit-ati-academic 1\n",
      "lte 1\n",
      "campus/college 1\n",
      "founded 2\n",
      "1856 1\n",
      "park 3\n",
      "flagship 1\n",
      "1,250-acre 1\n",
      "just 4\n",
      "minutes 2\n",
      "away 1\n",
      "d.c 3\n",
      "nexus 9\n",
      "legislative 1\n",
      "judicial 1\n",
      "proximity 1\n",
      "leaders 11\n",
      "departments 7\n",
      "agencies 10\n",
      "myriad 2\n",
      "embassies 1\n",
      "tanks 1\n",
      "cultural 4\n",
      "non-profit 3\n",
      "simply 2\n",
      "synergistic 1\n",
      "faculty 5\n",
      "students 6\n",
      "abound 1\n",
      "virtually 1\n",
      "limitless 1\n",
      "capital 6\n",
      "surrounding 2\n",
      "attracting 1\n",
      "outstanding 3\n",
      "stature 1\n",
      "preeminence 1\n",
      "missions 5\n",
      "teaching 2\n",
      "scholarship 1\n",
      "checks 5\n",
      "offers 10\n",
      "reported 1\n",
      "disqualify 1\n",
      "protocol 2\n",
      "usm 2\n",
      "announced 1\n",
      "fall 1\n",
      "umd 2\n",
      "prospective 3\n",
      "comply 3\n",
      "universitys 3\n",
      "seek 8\n",
      "exemption 7\n",
      "return.umd.edu 1\n",
      "failure 2\n",
      "approval 1\n",
      "rescinded 1\n",
      "summary 9\n",
      "summary/purpose 1\n",
      "division 4\n",
      "atex 4\n",
      "enterprise-wide 3\n",
      "experiences 15\n",
      "employs 3\n",
      "quantitative 5\n",
      "evaluation-based 1\n",
      "evidence-based 1\n",
      "insights 21\n",
      "concerning 1\n",
      "efficacy 1\n",
      "dit 2\n",
      "incumbent 1\n",
      "interfacing 1\n",
      "closely 13\n",
      "creation 5\n",
      "overseen 1\n",
      "eds 1\n",
      "aligned 1\n",
      "strategy 8\n",
      "utmost 1\n",
      "importance 3\n",
      "elt 14\n",
      "storing 1\n",
      "structured 10\n",
      "files 3\n",
      "non-technical 7\n",
      "2-4 3\n",
      "user-friendly 1\n",
      "language 20\n",
      "orally 1\n",
      "comfortable 11\n",
      "varied 3\n",
      "persuade 1\n",
      "critically 2\n",
      "self-motivated 3\n",
      "energetic 2\n",
      "oriented 1\n",
      "player 9\n",
      "preferences 1\n",
      "ideally 4\n",
      "object-oriented 5\n",
      "object-oriented/object 1\n",
      "java 23\n",
      "scala 8\n",
      "interest 9\n",
      "mining 5\n",
      "json 4\n",
      "amazon 21\n",
      "mpp 3\n",
      "ec2 3\n",
      "lambda 6\n",
      "s3 10\n",
      "streaming 8\n",
      "formats 2\n",
      "sponsorship 11\n",
      "visas 1\n",
      "$90,000s 1\n",
      "demands 1\n",
      "exerting 1\n",
      "up 19\n",
      "10 14\n",
      "pounds 1\n",
      "force 3\n",
      "occasionally 2\n",
      "negligible 1\n",
      "amount 1\n",
      "frequently 2\n",
      "lift 1\n",
      "pull 1\n",
      "otherwise 2\n",
      "objects 6\n",
      "movements 1\n",
      "motions 1\n",
      "wrists 1\n",
      "fingers 1\n",
      "worker 1\n",
      "visual 1\n",
      "acuity 1\n",
      "activity 3\n",
      "figures 1\n",
      "transcribing 1\n",
      "viewing 1\n",
      "terminal 1\n",
      "extensive 4\n",
      "02 1\n",
      "25 4\n",
      "2022 3\n",
      "02/25/2022 1\n",
      "until 2\n",
      "filled 1\n",
      "03 1\n",
      "17 2\n",
      "03/17/2022 1\n",
      "complies 2\n",
      "nondiscrimination 3\n",
      "discriminate 4\n",
      "expression 11\n",
      "political 9\n",
      "appearance 3\n",
      "secured 1\n",
      "amendment 1\n",
      "admissions 1\n",
      "$150,000 1\n",
      "$250,000 1\n",
      "typefull-timecontractqualificationshigh 1\n",
      "preferred)computer 1\n",
      "networking 10\n",
      "preferred)data 3\n",
      "ccnp 2\n",
      "preferred)ccnp 1\n",
      "ccna 2\n",
      "preferred)ccna 1\n",
      "preferred)full 6\n",
      "motivated 8\n",
      "talented 9\n",
      "lines 4\n",
      "aci 21\n",
      "plus 18\n",
      "bench 1\n",
      "pre 1\n",
      "post 4\n",
      "sales 6\n",
      "partners 16\n",
      "majority 3\n",
      "compensation 20\n",
      "choices 4\n",
      "upside.''contract 1\n",
      "length 5\n",
      "renewal 1\n",
      "likely 1\n",
      "precaution 1\n",
      "precaution(s 1\n",
      "virtual 2\n",
      "meetings 7\n",
      "sanitizing 1\n",
      "disinfecting 1\n",
      "cleaning 2\n",
      "encouraged 2\n",
      "ged 1\n",
      "diploma/ged 1\n",
      "ages 3\n",
      "older 1\n",
      "seekers 3\n",
      "visa 4\n",
      "potentially 1\n",
      "h-1b 1\n",
      "immigrant 1\n",
      "green 3\n",
      "card 3\n",
      "$150,000.00 1\n",
      "$250,000.00 1\n",
      "supplemental 3\n",
      "commission 1\n",
      "rolejob 7\n",
      "activityemployer 10\n",
      "13 5\n",
      "agoposted 10\n",
      "29 1\n",
      "$85,000 2\n",
      "$115,000 1\n",
      "typefull-timequalificationsus 3\n",
      "required)sql 1\n",
      "preferred)python 2\n",
      "empowerk12 2\n",
      "regardless 6\n",
      "socioeconomic 1\n",
      "high-quality 3\n",
      "teachers 2\n",
      "proper 5\n",
      "continuously 7\n",
      "improve 24\n",
      "dashboarding 3\n",
      "developed 7\n",
      "common 10\n",
      "structure 7\n",
      "phase-in 1\n",
      "predictive 9\n",
      "19 3\n",
      "networks 4\n",
      "strive 11\n",
      "dcs 1\n",
      "broader 2\n",
      "cross-sector 1\n",
      "citywide 1\n",
      "honoring 1\n",
      "tight-knit 1\n",
      "prides 1\n",
      "ourselves 3\n",
      "figuring 1\n",
      "overcome 1\n",
      "pursuit 1\n",
      "anything 2\n",
      "serve 11\n",
      "partners’ 2\n",
      "interests 3\n",
      "vary 8\n",
      "diy 1\n",
      "renovation 1\n",
      "astronomy 1\n",
      "march 1\n",
      "madness 1\n",
      "reality 1\n",
      "tv 1\n",
      "modeling 30\n",
      "check-ins 1\n",
      "happy 3\n",
      "codenames 1\n",
      "trivia 2\n",
      "games 1\n",
      "know 13\n",
      "sharing 8\n",
      "overview 11\n",
      "full-stack 2\n",
      "analyses 6\n",
      "inflection 1\n",
      "double 1\n",
      "size 1\n",
      "two 10\n",
      "maximize 1\n",
      "scalable 13\n",
      "dramatic 1\n",
      "gains 1\n",
      "helping 10\n",
      "hence 1\n",
      "equity 8\n",
      "empowerk12s 2\n",
      "ways 12\n",
      "error-proof 3\n",
      "primarily 3\n",
      "internal-facing 1\n",
      "client-facing 2\n",
      "v1.0 1\n",
      "v2.0 1\n",
      "increasing 1\n",
      "scalability 6\n",
      "developing 43\n",
      "error 1\n",
      "robust 11\n",
      "modular 2\n",
      "stack 7\n",
      "educators 2\n",
      "efficiently 1\n",
      "modify 4\n",
      "real 5\n",
      "train 5\n",
      "specialists 1\n",
      "strongly 3\n",
      "meticulous 1\n",
      "well-commented 1\n",
      "systematic 1\n",
      "thinker 2\n",
      "error-handling 1\n",
      "interactive 5\n",
      "collaborating 5\n",
      "metrics 7\n",
      "user 15\n",
      "communicator 1\n",
      "listen 2\n",
      "teammates 1\n",
      "explain 3\n",
      "excited 11\n",
      "startup 3\n",
      "arise 3\n",
      "daily 6\n",
      "self-directed 3\n",
      "self-starter 6\n",
      "high-priority 1\n",
      "whatever 1\n",
      "partner 8\n",
      "feedback 3\n",
      "self-development 1\n",
      "improving 6\n",
      "tenacity 1\n",
      "ask 3\n",
      "signal 1\n",
      "smarter 2\n",
      "creatively 2\n",
      "multiple 21\n",
      "amid 1\n",
      "ambiguity 1\n",
      "relationships 10\n",
      "value 28\n",
      "alternative 2\n",
      "paths 1\n",
      "generous 9\n",
      "suite 4\n",
      "smarttrip 1\n",
      "short 7\n",
      "term-disability 1\n",
      "$85,000-115,000 1\n",
      "commensurate 4\n",
      "wish 1\n",
      "website 2\n",
      "www.empowerk12.org 1\n",
      "team#careers 1\n",
      "https://www.empowerk12.org/team#careers 1\n",
      "$85,000.00 2\n",
      "$115,000.00 1\n",
      "matching 7\n",
      "retirement 14\n",
      "considerations:we 1\n",
      "guidelines 1\n",
      "k-12 2\n",
      "typefull-timeindeeds 17\n",
      "guidenot 27\n",
      "$122k 3\n",
      "$155k 2\n",
      "indeeds 36\n",
      "estimated 27\n",
      "dc.loading 10\n",
      "surveyfull 18\n",
      "contract-to-contract 2\n",
      "i'm 2\n",
      "partnering 2\n",
      "news 3\n",
      "readers 2\n",
      "countrys 2\n",
      "reliable 2\n",
      "data-driven 4\n",
      "searching 2\n",
      "fully-remote 2\n",
      "residing 2\n",
      "coming 2\n",
      "clean 5\n",
      "merge 2\n",
      "optimized 5\n",
      "transformed 3\n",
      "organize 3\n",
      "load 11\n",
      "deploy 11\n",
      "extensively 2\n",
      "etl/elt 10\n",
      "options 6\n",
      "401k 11\n",
      "tuition 11\n",
      "reimbursement 14\n",
      "pretax 2\n",
      "fsa 2\n",
      "commuter 7\n",
      "employer-paid 2\n",
      "gym 2\n",
      "exercise 5\n",
      "discounts 2\n",
      "adoption 4\n",
      "parent 5\n",
      "caregivers 2\n",
      "scholarships 2\n",
      "children 6\n",
      "26 3\n",
      "geico 26\n",
      "machine 22\n",
      "ai 20\n",
      "experimentation 4\n",
      "iterations 2\n",
      "feedbacks 2\n",
      "lean 2\n",
      "complimented 2\n",
      "partnership 6\n",
      "collaboration 8\n",
      "marketing 15\n",
      "connected 4\n",
      "feature 14\n",
      "mlops 2\n",
      "shape 4\n",
      "adaptive 2\n",
      "construct 5\n",
      "features 11\n",
      "nested 2\n",
      "time-series 2\n",
      "time-travel 2\n",
      "adapted 2\n",
      "targets 2\n",
      "stores 5\n",
      "construction 4\n",
      "repository 6\n",
      "model 12\n",
      "retraining 2\n",
      "graph 2\n",
      "graph-based 2\n",
      "ml 5\n",
      "instantiation 2\n",
      "largest 11\n",
      "carrier 2\n",
      "3+ 13\n",
      "spark 37\n",
      "parsing 2\n",
      "semi-structured 2\n",
      "deploying 12\n",
      "organizing 4\n",
      "persisting 2\n",
      "adls 2\n",
      "bricks 2\n",
      "cosmosdb 2\n",
      "ado 2\n",
      "dbt 9\n",
      "like 35\n",
      "kafka 7\n",
      "capability 3\n",
      "event-based 2\n",
      "metrics-based 2\n",
      "alerting 2\n",
      "exploration 3\n",
      "big-date 2\n",
      "associates 9\n",
      "excel 8\n",
      "thrive 7\n",
      "generally 3\n",
      "limit 3\n",
      "spread 4\n",
      "leverage 11\n",
      "secure 12\n",
      "continually 7\n",
      "everyone 4\n",
      "authentic 3\n",
      "associate-led 3\n",
      "groups 15\n",
      "foster 4\n",
      "true 4\n",
      "sense 6\n",
      "geicos 4\n",
      "offerings 5\n",
      "total 9\n",
      "rewards 7\n",
      "premier 8\n",
      "waiting 5\n",
      "profit 5\n",
      "licensures 3\n",
      "benefit 5\n",
      "begins 3\n",
      "enroll 3\n",
      "effect 3\n",
      "conducts 4\n",
      "drug 4\n",
      "screens 2\n",
      "accept 7\n",
      "cultivating 3\n",
      "familial 3\n",
      "believes 3\n",
      "recruit 4\n",
      "retain 4\n",
      "li-am1 2\n",
      "$101k 2\n",
      "$128k 2\n",
      "surveydata 2\n",
      "bear 2\n",
      "crime 2\n",
      "unstructured 11\n",
      "transactional 4\n",
      "approaches 12\n",
      "second 3\n",
      "first-party 2\n",
      "investigative 2\n",
      "enforcement 2\n",
      "eastport 6\n",
      "small 16\n",
      "growing 16\n",
      "professionalism 2\n",
      "gives 5\n",
      "eastports 2\n",
      "domain 7\n",
      "experts 8\n",
      "technologists 5\n",
      "fraud 2\n",
      "actionable 5\n",
      "novel 3\n",
      "align 4\n",
      "acquisition 7\n",
      "reliability 7\n",
      "proven 11\n",
      "oracle 6\n",
      "large-scale 8\n",
      "olap 2\n",
      "modelling 2\n",
      "intensive 2\n",
      "unfortunately 2\n",
      "core 17\n",
      "eastern 4\n",
      "extracting 9\n",
      "coding 7\n",
      "ruby 2\n",
      "extraction 10\n",
      "ingestion 12\n",
      "fintech 2\n",
      "interaction 3\n",
      "sometimes 4\n",
      "perfect 2\n",
      "doesn't 2\n",
      "exist 3\n",
      "put 6\n",
      "don't 6\n",
      "corner 3\n",
      "thriving 2\n",
      "dc-based 2\n",
      "offering 8\n",
      "work-life 3\n",
      "monthly 5\n",
      "parking 5\n",
      "transit 2\n",
      "spending 5\n",
      "radical 3\n",
      "flex 2\n",
      "quarterly 4\n",
      "person 6\n",
      "balance 7\n",
      "stereotyping 2\n",
      "transgender 2\n",
      "merit 5\n",
      "third 2\n",
      "parties 2\n",
      "please.hiring 2\n",
      "$92k 1\n",
      "$117k 2\n",
      "fort 2\n",
      "meade 2\n",
      "20755.loading 1\n",
      "definitive 4\n",
      "logic 4\n",
      "mid 3\n",
      "2-3 3\n",
      "appreciates 1\n",
      "challenged 2\n",
      "curious 5\n",
      "mind 1\n",
      "innovative 18\n",
      "table 4\n",
      "applies 6\n",
      "nature 3\n",
      "originality 1\n",
      "determining 1\n",
      "accomplish 2\n",
      "operates 7\n",
      "appreciable 1\n",
      "methodology 5\n",
      "contributes 3\n",
      "interim 1\n",
      "secret 9\n",
      "four 2\n",
      "low 2\n",
      "latency 1\n",
      "nifi 2\n",
      "streamsets 1\n",
      "display 3\n",
      "positive 12\n",
      "can-do 1\n",
      "attitude 3\n",
      "firm 7\n",
      "roi 1\n",
      "agencies’ 1\n",
      "delivers 4\n",
      "performance-based 1\n",
      "outcome-driven 1\n",
      "intent 1\n",
      "defense 2\n",
      "homeland 2\n",
      "app 2\n",
      "dev 2\n",
      "devsecops 7\n",
      "front-line 1\n",
      "back-office 1\n",
      "trusted 4\n",
      "advisors 1\n",
      "objective 1\n",
      "fact-based 1\n",
      "vendor 3\n",
      "technology-neutral 1\n",
      "ultimately 1\n",
      "solvers 1\n",
      "thought 3\n",
      "coders 1\n",
      "enthusiasts 1\n",
      "technophiles 1\n",
      "exciting 5\n",
      "resulted 1\n",
      "validation 5\n",
      "7-time 1\n",
      "winner 1\n",
      "| 4\n",
      "midsize 1\n",
      "2019 5\n",
      "$90 2\n",
      "$100 1\n",
      "typefull-timecontractfull 3\n",
      "routing 4\n",
      "switching 4\n",
      "troubleshooting 9\n",
      "elements 4\n",
      "consultative 2\n",
      "minor 2\n",
      "9k 8\n",
      "leaf 2\n",
      "spine 2\n",
      "switch 2\n",
      "fabric 6\n",
      "multi-site 6\n",
      "interconnectivity 2\n",
      "multi-pod 2\n",
      "execution 6\n",
      "ip 2\n",
      "endpoint 2\n",
      "classification 3\n",
      "categorization 2\n",
      "naming 2\n",
      "constructs 5\n",
      "scenarios 5\n",
      "site 5\n",
      "configurations 2\n",
      "firewalls 2\n",
      "isp 2\n",
      "business-to-business 2\n",
      "b2b 2\n",
      "extranet 2\n",
      "wireless 6\n",
      "mpls 2\n",
      "out-of-band 2\n",
      "oob 2\n",
      "segments 1\n",
      "apic 2\n",
      "mso 2\n",
      "automating 6\n",
      "considerations 2\n",
      "tenant 1\n",
      "profiles 3\n",
      "epgs 2\n",
      "contracts 6\n",
      "subjects 2\n",
      "filters 2\n",
      "rest 7\n",
      "api 4\n",
      "ansible 2\n",
      "curl 2\n",
      "solid 5\n",
      "hypervisor 2\n",
      "esxi 2\n",
      "vmm 2\n",
      "configuring 7\n",
      "7k 2\n",
      "5k 2\n",
      "nx-os 2\n",
      "$90.00 2\n",
      "$100.00 1\n",
      "5k,7k,and 2\n",
      "switches 2\n",
      "insightsapplication 6\n",
      "response 6\n",
      "rate 7\n",
      "64%hiring 1\n",
      "$84.8k 1\n",
      "$107k 1\n",
      "20001.loading 1\n",
      "surveymonumental 1\n",
      "sports 10\n",
      "entertainment 8\n",
      "mse 6\n",
      "owns 3\n",
      "wnba 1\n",
      "mystics 3\n",
      "2018 2\n",
      "nhl 1\n",
      "stanley 1\n",
      "cup 1\n",
      "capitals 3\n",
      "nbas 1\n",
      "wizards 4\n",
      "nba 2\n",
      "g 1\n",
      "leagues 2\n",
      "city 2\n",
      "go-go 3\n",
      "2k 1\n",
      "district 6\n",
      "gaming 1\n",
      "co-owner 1\n",
      "axiomatic 1\n",
      "controlling 1\n",
      "esports 1\n",
      "franchise 1\n",
      "liquid 1\n",
      "arena 3\n",
      "manages 2\n",
      "medstar 2\n",
      "iceplex 1\n",
      "state-of-the-art 4\n",
      "eaglebank 1\n",
      "george 1\n",
      "mason 1\n",
      "conjunction 1\n",
      "columbia 7\n",
      "southeast 1\n",
      "st 1\n",
      "elizabeths 1\n",
      "east 1\n",
      "opened 1\n",
      "september 1\n",
      "highlights 3\n",
      "brand-new 1\n",
      "4,200-seat 1\n",
      "serves 6\n",
      "co-owns 1\n",
      "monumental 4\n",
      "msn 2\n",
      "nbc 1\n",
      "mid-atlantic 3\n",
      "regions 2\n",
      "destination 1\n",
      "exclusive 1\n",
      "fan 1\n",
      "desktop 2\n",
      "tablet 1\n",
      "mobile 5\n",
      "ott 1\n",
      "devices 5\n",
      "www.monumentalsports.com 1\n",
      "proudly 1\n",
      "first-class 1\n",
      "fans 2\n",
      "double-bottom 1\n",
      "line 1\n",
      "engages 1\n",
      "unifies 1\n",
      "tirelessly 1\n",
      "generationally 1\n",
      "exceptional 7\n",
      "championships 1\n",
      "lifelong 2\n",
      "memories 1\n",
      "compelled 1\n",
      "prize 1\n",
      "treat 1\n",
      "humble 2\n",
      "innovate 4\n",
      "nimble 1\n",
      "averse 1\n",
      "happiness 1\n",
      "basketball 3\n",
      "extend 3\n",
      "basketballs 1\n",
      "collecting 1\n",
      "redefining 2\n",
      "distributing 1\n",
      "consumption 3\n",
      "builder 2\n",
      "excels 1\n",
      "we'd 1\n",
      "love 8\n",
      "hear 7\n",
      "resolve 6\n",
      "workflows 8\n",
      "postgresql 4\n",
      "c 6\n",
      "airflow 5\n",
      "composer 1\n",
      "prefect 2\n",
      "dependencies 1\n",
      "telemetry 1\n",
      "graphs 1\n",
      "xml 2\n",
      "csv 1\n",
      "unstructured-text 1\n",
      "git 6\n",
      "familiarity 16\n",
      "evenings 1\n",
      "weekends 2\n",
      "commencing 1\n",
      "conditional 1\n",
      "produce 8\n",
      "unable 1\n",
      "individualized 1\n",
      "law.hiring 1\n",
      "mapmg 3\n",
      "multispecialty 1\n",
      "1980 1\n",
      "1,700 1\n",
      "physicians 5\n",
      "spanning 2\n",
      "50 4\n",
      "subspecialties 1\n",
      "approximately 1\n",
      "800,000 1\n",
      "34 1\n",
      "hospitals 1\n",
      "nursing 1\n",
      "facilities 4\n",
      "i 5\n",
      "finance 4\n",
      "automate 6\n",
      "identifying 4\n",
      "workflow 5\n",
      "replacement 1\n",
      "sites 1\n",
      "web 24\n",
      "microservice 2\n",
      "docker 9\n",
      "runtimes 1\n",
      "calls 1\n",
      "backends 1\n",
      "recovery 14\n",
      "restoration 3\n",
      "bulk 1\n",
      "schemas 4\n",
      "ad-hoc 4\n",
      "performing 13\n",
      "facilitate 3\n",
      "typically 1\n",
      "reusable 1\n",
      "frameworks 2\n",
      "functionality 4\n",
      "effort 4\n",
      "reduction 1\n",
      "complexity 3\n",
      "troubleshoot 7\n",
      "failures 2\n",
      "clearly 2\n",
      "regularly 1\n",
      "bs 5\n",
      "ba 2\n",
      "bs/ba 1\n",
      "html 1\n",
      "css 1\n",
      "javascript 1\n",
      "end-to-end 5\n",
      "cli-based 1\n",
      "audience 3\n",
      "detail-oriented 2\n",
      "naturally 1\n",
      "fast-paced 6\n",
      "varying 4\n",
      "learner 2\n",
      "ambiguous 1\n",
      "situations 1\n",
      "perspective 9\n",
      "employer-funded 1\n",
      "premiums 2\n",
      "work/life 3\n",
      "maternity 1\n",
      "pension 1\n",
      "short-term 4\n",
      "works 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mitigate 1\n",
      "healthcare 16\n",
      "inequities 1\n",
      "supportive 5\n",
      "commit 2\n",
      "practicing 1\n",
      "competent 1\n",
      "e 3\n",
      "e/o/e 1\n",
      "d 1\n",
      "v 1\n",
      "m/f/d/v 1\n",
      "$120,000 2\n",
      "typefull-timequalificationssql 1\n",
      "citizen 6\n",
      "citizen/green 1\n",
      "on-site 4\n",
      "baltimore 2\n",
      "specifics 1\n",
      "$120k 1\n",
      "annually 1\n",
      "non-contract 1\n",
      "relocation 6\n",
      "offered/employee 1\n",
      "partially 1\n",
      "subsidized 1\n",
      "days/2 1\n",
      "weeks 6\n",
      "accrual 1\n",
      "informatics 1\n",
      "fulfil 1\n",
      "scientists 10\n",
      "aid 2\n",
      "existent 1\n",
      "flow 4\n",
      "plays 1\n",
      "ensuring 10\n",
      "brought 3\n",
      "accurate 2\n",
      "assists 7\n",
      "optimum 1\n",
      "capacity 5\n",
      "defines 5\n",
      "builds 4\n",
      "faster 3\n",
      "data-informed 2\n",
      "applied 4\n",
      "· 51\n",
      "administrator 2\n",
      "setting 3\n",
      "servers 4\n",
      "volumes 3\n",
      "example 1\n",
      "macros 1\n",
      "pivot 1\n",
      "debugging 3\n",
      "businesss 2\n",
      "ssas 1\n",
      "ssrs 1\n",
      "disaster 3\n",
      "schema 3\n",
      "tuning 9\n",
      "showing 1\n",
      "fluency 2\n",
      "shell 2\n",
      "php 1\n",
      "t-sql 3\n",
      "she 2\n",
      "he 2\n",
      "she/he 1\n",
      "technologically 1\n",
      "adept 4\n",
      "capable 2\n",
      "powerpoint 2\n",
      "outlook 2\n",
      "verbally 2\n",
      "engaging 5\n",
      "presentations 2\n",
      "result-driven 1\n",
      "solver 1\n",
      "proactive 6\n",
      "handle-multiple 1\n",
      "simultaneous 1\n",
      "aggressive 1\n",
      "stay 5\n",
      "calm 1\n",
      "composed 1\n",
      "adversity 1\n",
      "convey 3\n",
      "messages 1\n",
      "partnerships 3\n",
      "$110,000.00 1\n",
      "$120,000.00 2\n",
      "21044 1\n",
      "$79.3k 1\n",
      "$100k 1\n",
      "mclean 2\n",
      "va.loading 3\n",
      "kldiscovery 5\n",
      "electronic 2\n",
      "discovery 14\n",
      "governance 9\n",
      "developer 2\n",
      "i.join 1\n",
      "enhancements 3\n",
      "releases 1\n",
      "superiors.remote 1\n",
      "opportunity.responsibilities 1\n",
      "researching 1\n",
      "bug 2\n",
      "fixes 2\n",
      "sqa 1\n",
      "defect 1\n",
      "resolution 2\n",
      "utilize 6\n",
      "enforce 1\n",
      "sla 1\n",
      "dynamic 8\n",
      "rapidly 2\n",
      "changing 9\n",
      "adhere 2\n",
      "scientific 5\n",
      "1-2+ 1\n",
      "identification 7\n",
      "resolutions 1\n",
      "adapt 2\n",
      "express 1\n",
      "c++ 2\n",
      "c/c++ 2\n",
      "traffic 1\n",
      "arms 1\n",
      "itar 1\n",
      "therefore 3\n",
      "verifiable 1\n",
      "he/she 1\n",
      "ii 3\n",
      "holder 1\n",
      "pr 1\n",
      "iii 1\n",
      "u.s.c 1\n",
      "1324 1\n",
      "b) 1\n",
      "a) 1\n",
      "3).what 1\n",
      "1324(b 1\n",
      "(a 1\n",
      "(3 1\n",
      ".what 1\n",
      "1324(b)(a)(3).what 1\n",
      "friendly 2\n",
      "welcoming 1\n",
      "team-oriented 1\n",
      "advancement 2\n",
      "casual 1\n",
      "dress 1\n",
      "medical/dental/vision 3\n",
      "valuesentrepreneurs 1\n",
      "heart 2\n",
      "another 6\n",
      "clients’ 1\n",
      "acknowledge 1\n",
      "weaknesses 1\n",
      "hungry 1\n",
      "internally 4\n",
      "expand 3\n",
      "contribution 6\n",
      "smart 5\n",
      "emotional 1\n",
      "shapes 1\n",
      "actions 5\n",
      "forge 1\n",
      "customers.who 1\n",
      "arekldiscovery 1\n",
      "technology-enabled 1\n",
      "firms 7\n",
      "corporations 1\n",
      "40+ 1\n",
      "locations 7\n",
      "countries 1\n",
      "leader 8\n",
      "best-in-class 1\n",
      "ediscovery 1\n",
      "litigation 1\n",
      "regulatory 2\n",
      "clients.serving 1\n",
      "collection 6\n",
      "forensic 1\n",
      "early 3\n",
      "web-based 2\n",
      "reviews 3\n",
      "ontrack 1\n",
      "world-class 2\n",
      "destruction 1\n",
      "management.kldiscovery 1\n",
      "fastest 4\n",
      "north 9\n",
      "magazine 1\n",
      "5000 2\n",
      "deloitte 22\n",
      "deloittes 8\n",
      "500 4\n",
      "ceo 1\n",
      "chris 1\n",
      "weiler 1\n",
      "2014 1\n",
      "ernst 1\n",
      "young 1\n",
      "entrepreneur 1\n",
      "year™ 1\n",
      "relativity 1\n",
      "maintains 9\n",
      "iso 1\n",
      "iec 1\n",
      "iso/iec 1\n",
      "27001 1\n",
      "world.kldiscovery 1\n",
      "computerized 1\n",
      "cmms 1\n",
      "ts 7\n",
      "sci 8\n",
      "ts/sci 5\n",
      "polygraph 2\n",
      "customer-centric 1\n",
      "earth 4\n",
      "builders 1\n",
      "brightest 2\n",
      "minds 1\n",
      "you'd 1\n",
      "buy 2\n",
      "tested 1\n",
      "fruition 1\n",
      "continuity 1\n",
      "gcc 3\n",
      "facilitator 1\n",
      "lses 1\n",
      "cses 1\n",
      "gratifying 1\n",
      "consistency 7\n",
      "co-exist 1\n",
      "exceed 1\n",
      "functioning 1\n",
      "displayed 3\n",
      "box 2\n",
      "aligning 2\n",
      "larger 2\n",
      "peer 3\n",
      "excellence 9\n",
      "globally 4\n",
      "then 3\n",
      "challenge 8\n",
      "you’ve 1\n",
      "roles 6\n",
      "meant 1\n",
      "all-inclusive 1\n",
      "monitors 1\n",
      "escalation 1\n",
      "outage 1\n",
      "mortem 1\n",
      "ensures 4\n",
      "records 2\n",
      "coordination 3\n",
      "connection 1\n",
      "regimen 2\n",
      "doses 1\n",
      "pfizer 2\n",
      "moderna 2\n",
      "dose 3\n",
      "johnson 3\n",
      "embrace 1\n",
      "differences 2\n",
      "furthering 1\n",
      "employee-led 1\n",
      "affinity 1\n",
      "reaching 1\n",
      "40,000 2\n",
      "190 1\n",
      "chapters 1\n",
      "host 1\n",
      "ongoing 8\n",
      "conversations 3\n",
      "ethnicity 1\n",
      "amazecon 1\n",
      "conferences 1\n",
      "amazons 2\n",
      "reinforced 1\n",
      "14 1\n",
      "remind 1\n",
      "perspectives 5\n",
      "years’ 9\n",
      "noc 1\n",
      "traits 1\n",
      "slas 2\n",
      "detection 1\n",
      "entries 1\n",
      "exhibit 2\n",
      "never 3\n",
      "satisfied 1\n",
      "quo 1\n",
      "dive 1\n",
      "touch 1\n",
      "simplification 1\n",
      "root 9\n",
      "cause 9\n",
      "instincts 1\n",
      "legally 6\n",
      "www.amazon.jobs 2\n",
      "en 3\n",
      "https://www.amazon.jobs/en/disability/us 2\n",
      "yields 1\n",
      "pivotal 2\n",
      "gathered 1\n",
      "disparate 2\n",
      "chance 5\n",
      "booz 4\n",
      "allens 1\n",
      "dataops 4\n",
      "someone 5\n",
      "detecting 1\n",
      "anomalous 1\n",
      "mission-driven 2\n",
      "stand 1\n",
      "build-out 1\n",
      "custom 6\n",
      "interface 3\n",
      "examination 1\n",
      "pressing 1\n",
      "anywhere 3\n",
      "ready 2\n",
      "cutting-edge 2\n",
      "can’t 2\n",
      "wait 2\n",
      "operationalizing 2\n",
      "postgres 6\n",
      "commonly 3\n",
      "nice 4\n",
      "possession 1\n",
      "classified 2\n",
      "90,000 1\n",
      "120,000 1\n",
      "final 2\n",
      "factors 2\n",
      "allen 3\n",
      "celebrate 4\n",
      "choice 2\n",
      "methodologies 8\n",
      "hortonworks 3\n",
      "splunk 4\n",
      "bowl—the 1\n",
      "nvidia 1\n",
      "institute 1\n",
      "dli 1\n",
      "wealth 1\n",
      "portal 2\n",
      "geared 1\n",
      "towards 7\n",
      "books 1\n",
      "in-house 1\n",
      "pursuing 2\n",
      "advantage 2\n",
      "bootcamps 1\n",
      "give 4\n",
      "helpful 2\n",
      "tips 5\n",
      "we’ll 3\n",
      "chart 1\n",
      "empowers 1\n",
      "people—no 1\n",
      "characteristic—to 1\n",
      "fearlessly 1\n",
      "change.hiring 1\n",
      "11 4\n",
      "$65,000 1\n",
      "$129,000 1\n",
      "typefull-timecontractqualificationsus 2\n",
      "required)secret 1\n",
      "raytheon 3\n",
      "bbn 3\n",
      "raytheons 1\n",
      "portfolio 8\n",
      "imaginative 1\n",
      "real-world 4\n",
      "beneﬁt 1\n",
      "exploitation 1\n",
      "technically 1\n",
      "dothe 1\n",
      "energized 1\n",
      "envelope 1\n",
      "art 1\n",
      "intersections 2\n",
      "refining 1\n",
      "hard 2\n",
      "involvement 3\n",
      "semantic 1\n",
      "artiﬁcial 1\n",
      "representation 4\n",
      "algorithms 10\n",
      "open-ended 1\n",
      "0 1\n",
      "proﬁciency 1\n",
      "respective 1\n",
      "ecosystems 2\n",
      "practical 3\n",
      "devops 5\n",
      "ci 5\n",
      "cd 4\n",
      "ci/cd 4\n",
      "gitlab 2\n",
      "kubernetes 5\n",
      "dod 6\n",
      "conﬁguration 1\n",
      "gradle 1\n",
      "ivy 1\n",
      "command 3\n",
      "usraytheon 1\n",
      "incentive 2\n",
      "familys 1\n",
      "auto 1\n",
      "child 2\n",
      "elder 1\n",
      "child/elder 1\n",
      "arrangements 1\n",
      "liferesources 1\n",
      "discount 3\n",
      "transportation 2\n",
      "federally 1\n",
      "$65,000.00 1\n",
      "$129,000.00 1\n",
      "9 3\n",
      "$100,000 1\n",
      "typefull-timepart-timecontractqualificationsinformatica 1\n",
      "preferred)sql 1\n",
      "preferred)us 1\n",
      "engineeringvisa 1\n",
      "gc,citizen 1\n",
      "combine 1\n",
      "we’d 5\n",
      "satisfactorily 1\n",
      "bright 1\n",
      "mls 1\n",
      "representative 3\n",
      "assemble 2\n",
      "non-functional 3\n",
      "manual 3\n",
      "re-designing 3\n",
      "greater 5\n",
      "loading 3\n",
      "‘big 6\n",
      "data’ 6\n",
      "etls 3\n",
      "node.js 2\n",
      "lambdas 1\n",
      "fix 1\n",
      "inside 2\n",
      "dynamodb 4\n",
      "emr 7\n",
      "preprocessing 1\n",
      "terraform 2\n",
      "equired 1\n",
      "skills/education/experience 1\n",
      "5+ 8\n",
      "authoring 4\n",
      "disconnected 3\n",
      "elastic 2\n",
      "map 1\n",
      "reduce 2\n",
      "step 2\n",
      "cloudformation 2\n",
      "buckets 1\n",
      "$90,000.00 1\n",
      "$100,000.00 1\n",
      "30668 1\n",
      "60%hiring 1\n",
      "expert-level 1\n",
      "highly-optimized 1\n",
      "hive 11\n",
      "hive/spark 1\n",
      "kinesis 3\n",
      "influencing 1\n",
      "imagine 3\n",
      "supply 3\n",
      "chain 3\n",
      "simulation 3\n",
      "inventory 9\n",
      "flows 3\n",
      "millions 7\n",
      "amazon.com 1\n",
      "worldwide 2\n",
      "involves 1\n",
      "quantities 1\n",
      "frequencies 1\n",
      "assigning 1\n",
      "fulfill 4\n",
      "cash 1\n",
      "keeping 1\n",
      "pace 2\n",
      "simulating 1\n",
      "simulate 2\n",
      "predicting 2\n",
      "labor 2\n",
      "optimizations 1\n",
      "simulations 2\n",
      "trillions 1\n",
      "makes 7\n",
      "purchase 5\n",
      "pricing 1\n",
      "minimize 1\n",
      "frustration 1\n",
      "scot 4\n",
      "develops 4\n",
      "simex 3\n",
      "experiments 2\n",
      "self-driven 2\n",
      "thoughtful 1\n",
      "generate 4\n",
      "multi-billion 1\n",
      "dollar 1\n",
      "visibility 1\n",
      "loves 1\n",
      "bies 1\n",
      "sdes 1\n",
      "sns 2\n",
      "sqs 2\n",
      "sns/sqs 1\n",
      "bachelor 1\n",
      "speciality 1\n",
      "building/operating 1\n",
      "incrementally 1\n",
      "coworkers 1\n",
      "$99.4k 2\n",
      "$126k 2\n",
      "justice 6\n",
      "ijm 16\n",
      "vulnerable 2\n",
      "violence 4\n",
      "1,200 2\n",
      "33 2\n",
      "catalyzing 2\n",
      "revolution 2\n",
      "rescue 2\n",
      "half 2\n",
      "billion 2\n",
      "unstoppable 2\n",
      "gods 2\n",
      "call 4\n",
      "oppressed 2\n",
      "cares 2\n",
      "joy 2\n",
      "celebration 2\n",
      "almost 2\n",
      "experiencing 2\n",
      "poverty 2\n",
      "$100+ 2\n",
      "million 5\n",
      "continues 3\n",
      "trajectory 2\n",
      "scaling 3\n",
      "2030 2\n",
      "ijms 2\n",
      "adding 2\n",
      "powers 4\n",
      "inform 3\n",
      "fundraising 3\n",
      "supporter 4\n",
      "regional 3\n",
      "donor 2\n",
      "headquarters 2\n",
      "recommend 4\n",
      "modernizations 2\n",
      "layers 3\n",
      "reporting/business 2\n",
      "omnichannel 2\n",
      "donor-centric 2\n",
      "relationship 4\n",
      "recommending 2\n",
      "promote 6\n",
      "hygiene 4\n",
      "fundraisers 2\n",
      "marketers 2\n",
      "emerging 9\n",
      "ideate 2\n",
      "analytics-supported 2\n",
      "knowledgeable 3\n",
      "orchestrators 2\n",
      "scraping 3\n",
      "wrangling 3\n",
      "cultures 2\n",
      "interacting 4\n",
      "version 3\n",
      "crm 2\n",
      "salesforce 2\n",
      "canada 3\n",
      "nonprofit 4\n",
      "privacy/nonprofit 2\n",
      "prospect 4\n",
      "ethics 4\n",
      "qualities 3\n",
      "orthodox 2\n",
      "christian 4\n",
      "faith 10\n",
      "apostles’ 2\n",
      "disciplined 2\n",
      "self-awareness 2\n",
      "eager 2\n",
      "fosters 3\n",
      "23 3\n",
      "formation 2\n",
      "upload 2\n",
      "incorporated 2\n",
      "separate 2\n",
      "disciplines 2\n",
      "prayer 2\n",
      "study 3\n",
      "fellowship 2\n",
      "worship 2\n",
      "21 3\n",
      "$200,000 4\n",
      "recruiting 11\n",
      "scratch 5\n",
      "talent 4\n",
      "focuses 5\n",
      "placing 2\n",
      "funded 2\n",
      "investors 3\n",
      "sequoia 2\n",
      "lightspeed 2\n",
      "ventures 2\n",
      "tiger 2\n",
      "a16z 2\n",
      "accel 2\n",
      "dfj 2\n",
      "reach 3\n",
      "hyper-connected 1\n",
      "achieved 2\n",
      "5g 6\n",
      "accessible 2\n",
      "consumable 2\n",
      "intuitive 1\n",
      "innovator 1\n",
      "creator 1\n",
      "industrys 1\n",
      "base-station-on-a-chip 1\n",
      "led 4\n",
      "seasoned 2\n",
      "executives 4\n",
      "industry-transforming 1\n",
      "4g 1\n",
      "4g/5g 1\n",
      "wifi 1\n",
      "wimax 1\n",
      "artificial 4\n",
      "few 1\n",
      "decades 1\n",
      "inventing 1\n",
      "paradigm 1\n",
      "generation 3\n",
      "soc 1\n",
      "kernel 1\n",
      "device 2\n",
      "drivers 1\n",
      "rtos 1\n",
      "firmware 1\n",
      "stacks 1\n",
      "bottlenecks 1\n",
      "dpdk 5\n",
      "pmd 1\n",
      "path 5\n",
      "putting 1\n",
      "armv8 1\n",
      "embedded 2\n",
      "chips 1\n",
      "packet 1\n",
      "forward 1\n",
      "fastpath 1\n",
      "ran 1\n",
      "$111k 2\n",
      "$141k 3\n",
      "rockville 2\n",
      "md.loading 2\n",
      "natural 4\n",
      "w2 2\n",
      "c2c 2\n",
      "responsive 3\n",
      "engage 5\n",
      "peers 4\n",
      "sprint 3\n",
      "estimation 4\n",
      "execute 4\n",
      "domains 2\n",
      "hadoop 15\n",
      "frontier 3\n",
      "pursue 3\n",
      "eks 2\n",
      "thanks 2\n",
      "sony 16\n",
      "branch 3\n",
      "sonys 2\n",
      "unleash 1\n",
      "human 4\n",
      "creativity 4\n",
      "llc 2\n",
      "pictures 1\n",
      "music 2\n",
      "900 1\n",
      "homes 1\n",
      "vast 3\n",
      "array 3\n",
      "movies 1\n",
      "television 1\n",
      "playstation 1\n",
      "creates 1\n",
      "anyone 2\n",
      "else 1\n",
      "ai.sony 1\n",
      "https://ai.sony 1\n",
      "electronics 1\n",
      "enthusiastic 1\n",
      "particularly 1\n",
      "image 2\n",
      "researchers 3\n",
      "programmers 1\n",
      "switzerland 1\n",
      "japan 2\n",
      "ambitious 1\n",
      "addressing 1\n",
      "concerns 1\n",
      "lawyers 2\n",
      "officers 1\n",
      "oral 2\n",
      "bash 1\n",
      "container 2\n",
      "minikube 1\n",
      "helm 1\n",
      "tilt 1\n",
      "tight 1\n",
      "english 1\n",
      "preferable 1\n",
      "tokyo 1\n",
      "li-as1 1\n",
      "condition 4\n",
      "ordinance 4\n",
      "regulation 3\n",
      "corporation 5\n",
      "careers@sonyusa.com 1\n",
      "mail 1\n",
      "madison 1\n",
      "avenue 1\n",
      "york 3\n",
      "ny 2\n",
      "10010 1\n",
      "supplement 2\n",
      "2-dose 1\n",
      "series 1\n",
      "single-dose 1\n",
      "johnsons 1\n",
      "janssen 1\n",
      "sincerely 1\n",
      "held 1\n",
      "beliefs 3\n",
      "indication 1\n",
      "discuss 1\n",
      "18 2\n",
      "fraym 6\n",
      "pioneered 1\n",
      "geospatial 2\n",
      "population 2\n",
      "dynamics 1\n",
      "governments 1\n",
      "rely 2\n",
      "tackling 2\n",
      "inequity 1\n",
      "insecurity 1\n",
      "climate 5\n",
      "ai/ml 2\n",
      "high-resolution 1\n",
      "sub-neighborhood 1\n",
      "commercially 2\n",
      "mid-level 1\n",
      "markets 4\n",
      "sectors 2\n",
      "frayms 2\n",
      "transitioning 1\n",
      "brainstorm 1\n",
      "gaps 2\n",
      "raster 2\n",
      "vector 1\n",
      "survey 2\n",
      "specialize 1\n",
      "sentiment 1\n",
      "externally 2\n",
      "aws-based 1\n",
      "household 1\n",
      "surveys 1\n",
      "satellite 1\n",
      "imagery 1\n",
      "spatial 2\n",
      "simplify 1\n",
      "project-managing 1\n",
      "mentoring 2\n",
      "containerization 3\n",
      "points 6\n",
      "scoping 1\n",
      "sql/postgres 1\n",
      "columnar 1\n",
      "restful 2\n",
      "tick 1\n",
      "boxes 1\n",
      "sounds 1\n",
      "answering 1\n",
      "“why 1\n",
      "fraym.” 1\n",
      "recruits 1\n",
      "trains 2\n",
      "compensates 1\n",
      "genetics 3\n",
      "guidehouse 10\n",
      "combining 2\n",
      "navigate 3\n",
      "pressures 1\n",
      "transformational 1\n",
      "resiliency 1\n",
      "technology-driven 1\n",
      "advisory 2\n",
      "outsourcing 1\n",
      "outwit 1\n",
      "12,000 1\n",
      "veritas 1\n",
      "agenda-setting 1\n",
      "driving 4\n",
      "economies 1\n",
      "www.guidehouse.com 1\n",
      "administering 3\n",
      "upgrading 3\n",
      "adhered 1\n",
      "skills/experience/knowledge 2\n",
      "3-5 2\n",
      "red 1\n",
      "hat 1\n",
      "rhel 1\n",
      "apache 10\n",
      "zeppelin 1\n",
      "cran 1\n",
      "pypi 1\n",
      "perl 1\n",
      "jenkins 5\n",
      "maven 3\n",
      "sailfish 1\n",
      "infosphere 1\n",
      "jira 3\n",
      "tool 5\n",
      "tracker 1\n",
      "versionone 1\n",
      "remediation 1\n",
      "proactively 2\n",
      "stability 1\n",
      "exposure 3\n",
      "dba 1\n",
      "restrictions 3\n",
      "former 1\n",
      "non-compete 1\n",
      "prevent 2\n",
      "criminal 1\n",
      "los 2\n",
      "angeles 2\n",
      "san 1\n",
      "francisco 1\n",
      "visited 1\n",
      "1-571-633-1711 1\n",
      "recruitingaccommodation@guidehouse.com 1\n",
      "confidential 1\n",
      "extent 1\n",
      "unsolicited 2\n",
      "resumes 2\n",
      "property 1\n",
      "obligated 1\n",
      "fee 1\n",
      "reflects 1\n",
      "rx 1\n",
      "variable 1\n",
      "dental/vision 1\n",
      "dependent 1\n",
      "accounts 2\n",
      "sponsored 1\n",
      "outreach 2\n",
      "back-up 1\n",
      "detailssalaryup 2\n",
      "required)bachelors 1\n",
      "ccie 2\n",
      "preferred)ccie 1\n",
      "detailability 1\n",
      "skillsability 1\n",
      "supervisionstrong 1\n",
      "technologies.expertise 1\n",
      "fabric.expert 1\n",
      "implementation.expertise 1\n",
      "platform.expert 1\n",
      "scenarioshigh 1\n",
      "segments.expertise 1\n",
      "managementexpert 1\n",
      "include:tenant 1\n",
      "policiesfunctional 1\n",
      "toolssolid 1\n",
      "integrationexperience 1\n",
      "responsibilities:1 1\n",
      "formulates 1\n",
      "thorough 1\n",
      "requirements.2 1\n",
      "devises 3\n",
      "modifies 2\n",
      "considering 2\n",
      "limitations 1\n",
      "translation 2\n",
      "specifications.3 1\n",
      "consultation 1\n",
      "specialist 2\n",
      "contributor/specialist 1\n",
      "education/certification 2\n",
      "managementccie 1\n",
      "ccdp 2\n",
      "considerations:all 1\n",
      "asking 1\n",
      "subjected 1\n",
      "weekly 3\n",
      "20005 1\n",
      "vxlan 1\n",
      "evpn 1\n",
      "vxlan/evpn 1\n",
      "concept 2\n",
      "$70 1\n",
      "$80 1\n",
      "hello 1\n",
      "ismail 1\n",
      "agileengine 1\n",
      "send 1\n",
      "me 1\n",
      "references 1\n",
      "appreciated 1\n",
      "covidjob 1\n",
      "duration 4\n",
      "hourly 1\n",
      "doe 1\n",
      "prescreening 1\n",
      "followed 2\n",
      "telephonic 1\n",
      "in-person 1\n",
      "video 4\n",
      "conferencing 2\n",
      "finr 1\n",
      "functions:analyze 1\n",
      "solutionsuse 1\n",
      "codeengage 1\n",
      "engineeringwork 1\n",
      "prioritiesperform 1\n",
      "estimationwork 1\n",
      "teamsprovide 1\n",
      "problemsidentify 1\n",
      "skills:experience 1\n",
      "technologiesproficiency 1\n",
      "sqlexperience 1\n",
      "sparkexperience 1\n",
      "javaability 1\n",
      "awsnice 1\n",
      "ismailagileengine 1\n",
      "$70.00 1\n",
      "$80.00 1\n",
      "$148k 1\n",
      "surveyabout 1\n",
      "koalafi 2\n",
      "consumer 3\n",
      "simpler 1\n",
      "transforming 6\n",
      "financing 2\n",
      "purchases 1\n",
      "retail 3\n",
      "nationwide 1\n",
      "modernize 1\n",
      "native 1\n",
      "reinventing 1\n",
      "toolsets 1\n",
      "stitch 3\n",
      "fivetran 1\n",
      "gathering 1\n",
      "patterns 5\n",
      "incorporate 1\n",
      "consensus 3\n",
      "findings 2\n",
      "diagrams 1\n",
      "new/junior 1\n",
      "preparation 3\n",
      "conceptualizing 1\n",
      "keen 2\n",
      "stakeholder 2\n",
      "scrum/agile 1\n",
      "output 2\n",
      "ansi-sql 1\n",
      "library 2\n",
      "gce 1\n",
      "cicd 1\n",
      "science/engineering 1\n",
      "owning 1\n",
      "nerdiness 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fascinating 1\n",
      "seriously 3\n",
      "relentlessness 1\n",
      "try 2\n",
      "fail 1\n",
      "point-of-sale 1\n",
      "empowerment 2\n",
      "smarts 1\n",
      "book 1\n",
      "street 1\n",
      "disposal 3\n",
      "empathy 1\n",
      "compassion 1\n",
      "goods 1\n",
      "hand 1\n",
      "lot 1\n",
      "thinking 4\n",
      "talking 2\n",
      "figure 2\n",
      "stuff 1\n",
      "can't 1\n",
      "conversation 1\n",
      "it.hiring 1\n",
      "$40,000 1\n",
      "employing 1\n",
      "compliantly 1\n",
      "businesses 1\n",
      "handling 3\n",
      "payroll 1\n",
      "taxes 1\n",
      "remote.com 2\n",
      "how-it-works 1\n",
      "remote.com/how-it-works 1\n",
      "backed 1\n",
      "a+ 1\n",
      "literally 1\n",
      "figuratively 1\n",
      "scattered 1\n",
      "handbook 3\n",
      "remote.com/handbook 1\n",
      "folks 2\n",
      "ethnic 3\n",
      "genders 1\n",
      "sexuality 1\n",
      "glassdoor 2\n",
      "resonates 1\n",
      "async 5\n",
      "www.notion.so 2\n",
      "80c01cd443ad4c77a8ceaef7c5fba5d0 1\n",
      "www.notion.so/80c01cd443ad4c77a8ceaef7c5fba5d0 1\n",
      "proactivity 1\n",
      "doubt 1\n",
      "default 1\n",
      "instead 1\n",
      "producers 1\n",
      "you'll 13\n",
      "unify 1\n",
      "compliant 1\n",
      "jump 1\n",
      "meltano 3\n",
      "metabase 1\n",
      "looker 2\n",
      "scheduling 2\n",
      "extractors 2\n",
      "errors 3\n",
      "transformations 2\n",
      "philosophy 2\n",
      "remotes 1\n",
      "unbiased 1\n",
      "cheap-labour 1\n",
      "usd 1\n",
      "geographical 1\n",
      "visiting 3\n",
      "perks 3\n",
      "people-benefits-perks-1e48a5869c274f40910b76d405b92f63 1\n",
      "www.notion.so/people-benefits-perks-1e48a5869c274f40910b76d405b92f63 1\n",
      "practicals 1\n",
      "head 2\n",
      "soon 1\n",
      "recruiter 3\n",
      "check(s 1\n",
      "thank 1\n",
      "li-dni 1\n",
      "$109k 2\n",
      "$139k 1\n",
      "20814.loading 1\n",
      "heliocampus 5\n",
      "chapel 1\n",
      "hill 1\n",
      "nc 1\n",
      "philadelphia 1\n",
      "pa 1\n",
      "complementary 3\n",
      "fulfilling 1\n",
      "investments 1\n",
      "run 3\n",
      "heliocampus’ 1\n",
      "fast-growing 3\n",
      "accountabilities 2\n",
      "integrator 2\n",
      "odi 1\n",
      "recommends 2\n",
      "real-time 3\n",
      "diagnoses 1\n",
      "6+ 1\n",
      "diagnose 1\n",
      "sky 1\n",
      "explore 3\n",
      "$71.2k 1\n",
      "$90.2k 1\n",
      "aurotech 1\n",
      "lvl 1\n",
      "github 2\n",
      "$95,000 1\n",
      "required)top 1\n",
      "mon-thur 1\n",
      "consists 1\n",
      "12-hour 1\n",
      "8570 1\n",
      "cert 1\n",
      "comptia 1\n",
      "security+ 1\n",
      "troubleshoots 1\n",
      "evaluates 1\n",
      "affecting 2\n",
      "supervise 1\n",
      "installing 4\n",
      "adequate 2\n",
      "architects 4\n",
      "planners 2\n",
      "spaces 2\n",
      "advice 2\n",
      "coordinates 1\n",
      "joint 3\n",
      "ddo 2\n",
      "cwo 1\n",
      "surveillance 3\n",
      "officer 4\n",
      "24/7 1\n",
      "subsystem–migration 1\n",
      "pds-m 1\n",
      "installed 1\n",
      "vulnerabilities 1\n",
      "modernization 2\n",
      "gcnm 1\n",
      "battle 1\n",
      "c2bmc 1\n",
      "cps 1\n",
      "system(cps 1\n",
      "routers 1\n",
      "keyboards 1\n",
      "cabling 1\n",
      "computers 1\n",
      "assurance 1\n",
      "covers 1\n",
      "outputs 1\n",
      "4/1/2022 1\n",
      "$95,000.00 1\n",
      "65%hiring 1\n",
      "$177,424 1\n",
      "peraton 3\n",
      "consequence 1\n",
      "globe 4\n",
      "extending 1\n",
      "farthest 1\n",
      "reaches 1\n",
      "galaxy 1\n",
      "transformative 1\n",
      "differentiated 1\n",
      "daunting 1\n",
      "facing 1\n",
      "translating 1\n",
      "acts 1\n",
      "advocate 3\n",
      "ultimate 1\n",
      "authority 2\n",
      "implements 1\n",
      "subsystems 1\n",
      "created 2\n",
      "shelf 1\n",
      "analyzes 1\n",
      "ident 1\n",
      "ifies 1\n",
      "peripheral 1\n",
      "telecommunications 1\n",
      "establishes 2\n",
      "solves 1\n",
      "input/output 1\n",
      "parameters 1\n",
      "sures 1\n",
      "exchange 4\n",
      "advise 3\n",
      "interoperability 1\n",
      "technica 1\n",
      "l 1\n",
      "briefings 4\n",
      "papers 2\n",
      "artifacts 2\n",
      "on-time 2\n",
      "products/services 1\n",
      "monitor 1\n",
      "systems/architectures 1\n",
      "sessions 2\n",
      "cases/scenarios 2\n",
      "modules 2\n",
      "gain 1\n",
      "formulate 1\n",
      "notes 1\n",
      "poly 1\n",
      "bachelor’ 1\n",
      "stem 1\n",
      "especially 2\n",
      "augment 1\n",
      "non-stem 1\n",
      "experienc 1\n",
      "enhancing 3\n",
      "preferably 3\n",
      "ic 1\n",
      "cycle 5\n",
      "net 2\n",
      "resolving 1\n",
      "draft 3\n",
      "executive-level 1\n",
      "makers 1\n",
      "creating/managing 1\n",
      "xml/json 1\n",
      "niem 1\n",
      "uml 1\n",
      "$82,992.00 1\n",
      "maximum 1\n",
      "$177,424.00 1\n",
      "estimate 1\n",
      "represents 2\n",
      "typical 1\n",
      "component 1\n",
      "peratons 1\n",
      "program-specific 1\n",
      "awards 1\n",
      "aledade 12\n",
      "assets 6\n",
      "patients 4\n",
      "tame 1\n",
      "many-headed 1\n",
      "hydra 1\n",
      "spin 1\n",
      "gold 1\n",
      "insight 5\n",
      "permanently 1\n",
      "heres 1\n",
      "polished 1\n",
      "analytic 6\n",
      "dashboard 1\n",
      "downstream 1\n",
      "alongside 2\n",
      "worked 1\n",
      "hires 4\n",
      "booster 3\n",
      "shots 1\n",
      "food 1\n",
      "issued 1\n",
      "mutually-agreed 1\n",
      "certain 1\n",
      "circumstances 1\n",
      "infection 1\n",
      "lieu 1\n",
      "shot 2\n",
      "doctors 1\n",
      "society 1\n",
      "idea 1\n",
      "succeeds 1\n",
      "practice 5\n",
      "everything 4\n",
      "aco 1\n",
      "revamping 1\n",
      "getting 1\n",
      "quarterbacking 1\n",
      "patients’ 1\n",
      "customized 2\n",
      "clinicians 1\n",
      "preserve 1\n",
      "autonomy 1\n",
      "costs 1\n",
      "physician 1\n",
      "flourishing 1\n",
      "mean 3\n",
      "open-mindedness 1\n",
      "we’ve 6\n",
      "biopharma 1\n",
      "medium 1\n",
      "tribune 1\n",
      "startups 4\n",
      "parents 4\n",
      "2020 2\n",
      "inno 2\n",
      "thats 3\n",
      "because 3\n",
      "enjoyment 1\n",
      "team-members 1\n",
      "assistant 1\n",
      "sabbatical 1\n",
      "80 1\n",
      "dependents 1\n",
      "stock 4\n",
      "cell 1\n",
      "stipend 1\n",
      "catered 1\n",
      "lunches 1\n",
      "jeans 1\n",
      "neutral 1\n",
      "bathrooms 1\n",
      "attract 1\n",
      "representing 1\n",
      "live 1\n",
      "childbirth 4\n",
      "20850.loading 1\n",
      "gnayld58zg 1\n",
      "multi-cloud 3\n",
      "truly 1\n",
      "no-sql 2\n",
      "engines 1\n",
      "messaging 3\n",
      "caching 2\n",
      "cloud-native 4\n",
      "story 2\n",
      "perfectly 1\n",
      "positioned 1\n",
      "accelerate 2\n",
      "reimbursements 1\n",
      "subscriptions 1\n",
      "tanzu 8\n",
      "equally 1\n",
      "shop 1\n",
      "little 3\n",
      "bit 1\n",
      "obsessed 1\n",
      "add 2\n",
      "honest 1\n",
      "giving 4\n",
      "usable 1\n",
      "worthwhile 1\n",
      "accelerating 1\n",
      "eventing 1\n",
      "petabytes 1\n",
      "complementary/competitive 1\n",
      "educate/enable 1\n",
      "greenplum 2\n",
      "postgres/mysql 1\n",
      "gemfire 1\n",
      "geode 1\n",
      "rabbitmq 1\n",
      "contributors 1\n",
      "prospects 2\n",
      "demo 1\n",
      "immerse 1\n",
      "ever-evolving 1\n",
      "datas 2\n",
      "connect 7\n",
      "impromptu 1\n",
      "whiteboard 1\n",
      "demos 1\n",
      "dw/bi 1\n",
      "ods 1\n",
      "behind 1\n",
      "statistical/bi 1\n",
      "calculations 2\n",
      "vsphere 1\n",
      "containers 2\n",
      "tooling 2\n",
      "massively 1\n",
      "parallel 1\n",
      "teradata 1\n",
      "netezza 1\n",
      "exadata 1\n",
      "gis 1\n",
      "madlib 1\n",
      "dbaas 1\n",
      "ones 2\n",
      "supported 2\n",
      "view 3\n",
      "www.benefits.vmware.com 2\n",
      "rethinks 2\n",
      "neurodiversity 2\n",
      "raising 2\n",
      "behavior 2\n",
      "developmental 2\n",
      "conference 2\n",
      "participation 3\n",
      "fitness 2\n",
      "wellbeing 2\n",
      "entry 2\n",
      "subcategory 2\n",
      "posted 2\n",
      "2022-03-30 1\n",
      "unlock 2\n",
      "planet 2\n",
      "beyond 2\n",
      "barriers 2\n",
      "compromise 2\n",
      "seamlessly 2\n",
      "foundation 6\n",
      "securely 2\n",
      "apps 4\n",
      "deeply 5\n",
      "careers.vmware.com 2\n",
      "http://careers.vmware.com 2\n",
      "prohibits 4\n",
      "discrimination 11\n",
      "harassment 8\n",
      "kind 3\n",
      "sensory 2\n",
      "hiv 2\n",
      "civil 3\n",
      "tolerate 2\n",
      "encourages 5\n",
      "owner 2\n",
      "descriptive 1\n",
      "diagnostic 1\n",
      "prescriptive 2\n",
      "collect 5\n",
      "streamline 1\n",
      "curated 1\n",
      "repositories 1\n",
      "informative 1\n",
      "open-source 4\n",
      "checking 1\n",
      "cloudera 3\n",
      "7+ 3\n",
      "$140,000.00 1\n",
      "67%hiring 1\n",
      "27 4\n",
      "$91.3k 1\n",
      "$116k 1\n",
      "20024.loading 1\n",
      "surveycna 1\n",
      "iterative 2\n",
      "stage 3\n",
      "investigations 1\n",
      "procured 2\n",
      "formulation 1\n",
      "fact-finding 1\n",
      "gather 2\n",
      "somewhat 1\n",
      "well-structured 1\n",
      "pieces 1\n",
      "strands 1\n",
      "budgeting 1\n",
      "sponsors 2\n",
      "client/sponsors 1\n",
      "sections 1\n",
      "moderate 1\n",
      "proposal 1\n",
      "sponsor 1\n",
      "client/sponsor 1\n",
      "interactions 3\n",
      "cna 5\n",
      "collector 1\n",
      "substantive 1\n",
      "inputs 1\n",
      "proposals 1\n",
      "memoranda 1\n",
      "seminars 1\n",
      "intermediate 1\n",
      "concisely 2\n",
      "precisely 1\n",
      "grammatically 1\n",
      "correct 1\n",
      "summarize 1\n",
      "clients/sponsors 1\n",
      "measurement 1\n",
      "non-merit 1\n",
      "governing 1\n",
      "protections 2\n",
      "promotion 4\n",
      "termination 3\n",
      "layoff 3\n",
      "recall 2\n",
      "transfer 3\n",
      "leaves 2\n",
      "absence 2\n",
      "posters 1\n",
      "poster 3\n",
      "clearance.hiring 1\n",
      "$130k 1\n",
      "$165k 1\n",
      "22102.loading 1\n",
      "surveyoverview 1\n",
      "steampunk 5\n",
      "cli 1\n",
      "aws-roles 1\n",
      "standardize 1\n",
      "hybrid 6\n",
      "installation 3\n",
      "multi-layer 2\n",
      "customize 1\n",
      "qradar 2\n",
      "aggregation 1\n",
      "rigor 1\n",
      "comparison 1\n",
      "patches 1\n",
      "logging 2\n",
      "images 2\n",
      "ami 1\n",
      "road-maps 1\n",
      "refine 2\n",
      "sequences 1\n",
      "exceptionally 1\n",
      "15+ 1\n",
      "heavy 1\n",
      "negotiation 1\n",
      "self-managed 1\n",
      "athena 4\n",
      "sagemaker 1\n",
      "premise 3\n",
      "replacing 1\n",
      "augmenting 1\n",
      "sops 1\n",
      "sysops 1\n",
      "practitioner 1\n",
      "far 1\n",
      "52.223-99 1\n",
      "except 1\n",
      "mandate 1\n",
      "barred 1\n",
      "court 1\n",
      "ordered 1\n",
      "injunction 1\n",
      "agent 1\n",
      "contracting 1\n",
      "human-centered 1\n",
      "fundamentally 1\n",
      "accountability 2\n",
      "toughest 2\n",
      "owned 2\n",
      "investing 1\n",
      "greatest 1\n",
      "careers 2\n",
      "www.steampunk.com 1\n",
      "http://www.steampunk.com 1\n",
      "participates 2\n",
      "e-verify 1\n",
      "program.hiring 1\n",
      "disruption 4\n",
      "confidence 1\n",
      "tapping 1\n",
      "robotics 1\n",
      "rigorous 3\n",
      "pragmatic 3\n",
      "uncover 2\n",
      "hidden 2\n",
      "troves 1\n",
      "marketplace 5\n",
      "game-changing 1\n",
      "team(s 3\n",
      "migrated 3\n",
      "gps 6\n",
      "outcomes-is 3\n",
      "15,000+ 3\n",
      "brings 5\n",
      "fresh 4\n",
      "reimagine 3\n",
      "promise 5\n",
      "a&c 3\n",
      "mathematical 3\n",
      "decision-makers 6\n",
      "practitioners 3\n",
      "interplay 3\n",
      "consume 3\n",
      "mongodb 4\n",
      "event 1\n",
      "strengths 5\n",
      "entry-level 3\n",
      "theres 3\n",
      "always 7\n",
      "sharpen 3\n",
      "fast-changing 3\n",
      "on-the-job 3\n",
      "formal 3\n",
      "blue 8\n",
      "vibrant 1\n",
      "servicing 1\n",
      "progressive 5\n",
      "underpinning 1\n",
      "campaign 1\n",
      "strategists 1\n",
      "advisor 1\n",
      "counterparts 1\n",
      "day-to-day 1\n",
      "compiling 1\n",
      "difficult 1\n",
      "exports 1\n",
      "synchronization 1\n",
      "reopen 1\n",
      "week 5\n",
      "enter 1\n",
      "attend 1\n",
      "visitors 1\n",
      "exceptions 1\n",
      "grounds 1\n",
      "foundational 1\n",
      "ads 2\n",
      "facebook 1\n",
      "go-to 1\n",
      "thing 2\n",
      "twice 1\n",
      "script 4\n",
      "task 2\n",
      "dask 1\n",
      "competently 1\n",
      "unfamiliar 1\n",
      "cross-channel 1\n",
      "utilizing 3\n",
      "analysing 1\n",
      "compute 2\n",
      "scheduler 1\n",
      "iam 1\n",
      "prefer 1\n",
      "sheets 2\n",
      "you've 1\n",
      "extended 1\n",
      "habits 1\n",
      "repeatable 1\n",
      "well-documented 1\n",
      "technically-savvy 1\n",
      "non-python 1\n",
      "easy 1\n",
      "command-line 1\n",
      "scripts 4\n",
      "guis 1\n",
      "necessity 1\n",
      "nice-to-have 3\n",
      "underrepresented 3\n",
      "lgbtqia+ 1\n",
      "immigrants 1\n",
      "indigenous 1\n",
      "seems 1\n",
      "values-led 1\n",
      "campaigns 4\n",
      "causes 3\n",
      "trouble 2\n",
      "powerful 1\n",
      "collective 1\n",
      "pretend 1\n",
      "surprise 1\n",
      "unhcr 1\n",
      "amnesty 1\n",
      "tesco 1\n",
      "nesta 1\n",
      "tate 1\n",
      "london 2\n",
      "oakland 1\n",
      "chicago 3\n",
      "$106k 1\n",
      "$134k 1\n",
      "engineeraarete 1\n",
      "culture*.why 1\n",
      "aarete 5\n",
      "bar 1\n",
      "guided 1\n",
      "loyalty 1\n",
      "stewardship 1\n",
      "sustainability 1\n",
      "successful.**aarete 1\n",
      "1000 1\n",
      "entrusted 1\n",
      "companys 2\n",
      "enriching 1\n",
      "empowering 2\n",
      "abundant 1\n",
      "impactful 1\n",
      "unlimited 1\n",
      "embracing 1\n",
      "dallas 1\n",
      "denver 1\n",
      "india 2\n",
      "aaretians 1\n",
      "nearby 1\n",
      "locations.aarete 1\n",
      "certification™ 1\n",
      "named 2\n",
      "vaults 1\n",
      "crains 1\n",
      "3rd 1\n",
      "5000s 1\n",
      "consecutive 2\n",
      "magazines 4\n",
      "2021.work 1\n",
      "discussing 1\n",
      "extracted 1\n",
      "meets 3\n",
      "validating 1\n",
      "ingested 3\n",
      "connectors 1\n",
      "java/kafka 1\n",
      "appears 1\n",
      "explores 1\n",
      "pipelines/transformations 1\n",
      "connector 1\n",
      "processed 1\n",
      "jupyter 1\n",
      "labs 2\n",
      "openapi 1\n",
      "junit 1\n",
      "pytest 1\n",
      "jmeter 1\n",
      "pyspark 4\n",
      "servicenow 1\n",
      "$130,000 1\n",
      "$160,000 1\n",
      "required)spark 1\n",
      "preferred)hadoop 1\n",
      "clean-up 1\n",
      "dictionaries 2\n",
      "deal 1\n",
      "speed 5\n",
      "consultants 1\n",
      "acquisitions 1\n",
      "archive 1\n",
      "econometricians 1\n",
      "multidimensional 1\n",
      "1-3 1\n",
      "yrs 3\n",
      "spark-related 1\n",
      "extract-transform-load 1\n",
      "laterally 1\n",
      "$50,000 1\n",
      "much 2\n",
      "heard 1\n",
      "sought 1\n",
      "rewarded 1\n",
      "frequent 2\n",
      "amenities 1\n",
      "standing 2\n",
      "desks 1\n",
      "rooftop 1\n",
      "terrace 1\n",
      "espresso 1\n",
      "fruit 1\n",
      "pool 1\n",
      "tennis 1\n",
      "employee-driven 1\n",
      "featuring 1\n",
      "game 1\n",
      "cooking 1\n",
      "competitions 1\n",
      "funds 1\n",
      "investment 1\n",
      "womens 1\n",
      "diversity-inclusion 1\n",
      "council 3\n",
      "$130,000.00 1\n",
      "$160,000.00 1\n",
      "74%hiring 1\n",
      "10+ 1\n",
      "$30 1\n",
      "$40 1\n",
      "1-5 1\n",
      "ocfo 4\n",
      "telecommunication 1\n",
      "avaya 1\n",
      "unified 1\n",
      "webex 1\n",
      "audio\\video 1\n",
      "voip 1\n",
      "sip 1\n",
      "analog 1\n",
      "efax 1\n",
      "telecom 4\n",
      "helpdesk 1\n",
      "tickets 1\n",
      "zen 1\n",
      "desk 2\n",
      "voicemail 1\n",
      "name 1\n",
      "phones 1\n",
      "telephony 1\n",
      "refreshes 1\n",
      "ios 2\n",
      "octo 1\n",
      "airwatch 3\n",
      "inventories 1\n",
      "fcms 1\n",
      "verizon 1\n",
      "insure 1\n",
      "familiar 1\n",
      "workspace 2\n",
      "asset 1\n",
      "softphone 1\n",
      "\\ 1\n",
      "port.---------------------------------------------contract 1\n",
      "descriptionresponsibilities:1 1\n",
      "networks.2 1\n",
      "standards.3 1\n",
      "systems.4 1\n",
      "requirements:bachelors 1\n",
      "$30.00 1\n",
      "$40.00 1\n",
      "comm 1\n",
      "$138k 1\n",
      "20910.loading 1\n",
      "standards-aligned 1\n",
      "classrooms 1\n",
      "districts 1\n",
      "like-minded 1\n",
      "learners 5\n",
      "excitement 3\n",
      "high-energy 1\n",
      "purpose-driven 1\n",
      "tremendous 2\n",
      "inclusivity 2\n",
      "high-performing 1\n",
      "living 1\n",
      "breathes 1\n",
      "tomorrow 1\n",
      "anticipating 1\n",
      "adapting 1\n",
      "landscape 2\n",
      "highest-standards 1\n",
      "socio-economic 1\n",
      "blend 1\n",
      "acumen 2\n",
      "business-facing 1\n",
      "technology-focused 1\n",
      "chosen 1\n",
      "attribution 1\n",
      "captured 2\n",
      "dozens 1\n",
      "turning 1\n",
      "definitions 4\n",
      "train/support 1\n",
      "craft 1\n",
      "style 1\n",
      "maintainability 2\n",
      "high-scale 1\n",
      "solution-oriented 1\n",
      "iterate 1\n",
      "management-level 1\n",
      "detailing 1\n",
      "learned 1\n",
      "capture 2\n",
      "metadata 22\n",
      "journey 1\n",
      "adjustments 1\n",
      "buyer 1\n",
      "personas 1\n",
      "inconsistencies 1\n",
      "4-5 1\n",
      "configure 1\n",
      "automations 1\n",
      "master 2\n",
      "pressure 2\n",
      "rigid 1\n",
      "humor 1\n",
      "laugh 1\n",
      "meaningfully 1\n",
      "rich 1\n",
      "$89.4k 1\n",
      "$113k 1\n",
      "reston 3\n",
      "admission 1\n",
      "gmac 5\n",
      "data-centric 1\n",
      "mulesoft 3\n",
      "cross-discipline 1\n",
      "connectivity 1\n",
      "flat 1\n",
      "customers’ 2\n",
      "profiling 2\n",
      "threading 1\n",
      "examining 2\n",
      "thread 1\n",
      "dumps 1\n",
      "multi-tasking 1\n",
      "in-office 1\n",
      "according 2\n",
      "gmacs 2\n",
      "locally 1\n",
      "403b 1\n",
      "paid-time 1\n",
      "holiday 1\n",
      "professionally 1\n",
      "collegial 1\n",
      "flsa 2\n",
      "exemptreport 1\n",
      "proposition 1\n",
      "appreciate 1\n",
      "wholly 1\n",
      "perceived 1\n",
      "recognizing 3\n",
      "vaccinations 1\n",
      "implemented 1\n",
      "mandatory 2\n",
      "$123k 1\n",
      "$156k 1\n",
      "surveytitle 1\n",
      "rackner 2\n",
      "consultancy 2\n",
      "enterprises 3\n",
      "incorporating 2\n",
      "bleeding 1\n",
      "appraising 1\n",
      "hail 1\n",
      "ever 1\n",
      "hypergrowth 1\n",
      "python(pyspark 1\n",
      "cluster 1\n",
      "rdbms 1\n",
      "services:ec2 1\n",
      "kms 1\n",
      "self-motivation 1\n",
      "self-motivation/self 1\n",
      "starter 1\n",
      "percent 2\n",
      "prorated 1\n",
      "fridays 1\n",
      "laws.hiring 1\n",
      "missionwired 2\n",
      "digital-obsessed 2\n",
      "tech-savvy 2\n",
      "do-gooders 2\n",
      "sandy 2\n",
      "hook 2\n",
      "friends 2\n",
      "dga 2\n",
      "flipping 2\n",
      "governorships 2\n",
      "expanding 3\n",
      "democratic 2\n",
      "senate 2\n",
      "dscc 2\n",
      "sen 6\n",
      "raphael 2\n",
      "warnock 2\n",
      "rep 2\n",
      "val 2\n",
      "demings 2\n",
      "catherine 2\n",
      "cortez 2\n",
      "masto 2\n",
      "maggie 2\n",
      "hassan 2\n",
      "equal-opportunity 2\n",
      "equality 2\n",
      "joins 2\n",
      "sights 2\n",
      "stronger 2\n",
      "broadens 2\n",
      "lived 2\n",
      "principal 3\n",
      "electing 2\n",
      "democrats 2\n",
      "combating 2\n",
      "disruptive 2\n",
      "first-of-their-kind 2\n",
      "lets 2\n",
      "data-intensive 4\n",
      "massive 2\n",
      "assembling 2\n",
      "must-have 2\n",
      "pandas 2\n",
      "energy 3\n",
      "high-performance 3\n",
      "deep-learning 2\n",
      "seniority 2\n",
      "floor 2\n",
      "goes 2\n",
      "feel 5\n",
      "anyway 2\n",
      "brand 2\n",
      "eminence 2\n",
      "could 2\n",
      "roadmap 2\n",
      "matters 4\n",
      "migrate 2\n",
      "etl/data 2\n",
      "industry-standard 2\n",
      "science/statistics 2\n",
      "innate 2\n",
      "business/functional 2\n",
      "constant 2\n",
      "thirst 2\n",
      "confluence 2\n",
      "stash 2\n",
      "artifactory 2\n",
      "conversational 2\n",
      "uniqueness 2\n",
      "healthy 5\n",
      "centered 2\n",
      "confident 4\n",
      "aware 2\n",
      "extends 2\n",
      "inspire 2\n",
      "skill-based 2\n",
      "volunteerism 2\n",
      "exploring 3\n",
      "prepared 2\n",
      "16 2\n",
      "elevator 1\n",
      "pitch 1\n",
      "customer-proven 1\n",
      "reducing 1\n",
      "socially 1\n",
      "silicon 1\n",
      "valley 1\n",
      "reimagining 1\n",
      "harnessing 1\n",
      "stream 2\n",
      "talk 1\n",
      "6-12 1\n",
      "performant 1\n",
      "judgement 1\n",
      "customer-focused 1\n",
      "curation 2\n",
      "criticality 1\n",
      "reusability 2\n",
      "convert 1\n",
      "stories 1\n",
      "hdfs 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqoop 1\n",
      "sqls 1\n",
      "elasticsearch 1\n",
      "batch 2\n",
      "sap 5\n",
      "bobj 1\n",
      "hinder 1\n",
      "increase 2\n",
      "influence 2\n",
      "observability 1\n",
      "simplifying 1\n",
      "comprised 1\n",
      "90+ 1\n",
      "palo 1\n",
      "alto 1\n",
      "ca 1\n",
      "austin 1\n",
      "tx 1\n",
      "costa 1\n",
      "rica 1\n",
      "on-going 1\n",
      "psychologically 1\n",
      "compassionate 1\n",
      "“this 1\n",
      "employment-based 1\n",
      "immigration 1\n",
      "vmware.” 1\n",
      "inspired 1\n",
      "snacks 1\n",
      "pantries 1\n",
      "2022-04-01 1\n",
      "chevy 4\n",
      "chase 4\n",
      "loc 1\n",
      "reqs 1\n",
      "debug 1\n",
      "doc 1\n",
      "int 2\n",
      "sme 2\n",
      "systs 1\n",
      "undergo 2\n",
      "incl 1\n",
      "screen 1\n",
      "bach 1\n",
      "comp 1\n",
      "rel 1\n",
      "exp 2\n",
      "geico.com 1\n",
      "geico.com/careers 1\n",
      "refer 1\n",
      "r0033802 1\n",
      "20 1\n",
      "$115k 1\n",
      "$146k 1\n",
      "20006.loading 1\n",
      "surveysimple 1\n",
      "sts 11\n",
      "quick 1\n",
      "fault-tolerant 1\n",
      "iaas 2\n",
      "solutioning 1\n",
      "prepares 1\n",
      "adherence 1\n",
      "5years 1\n",
      "conducting 1\n",
      "remarkable 1\n",
      "busy-ness 1\n",
      "cultivate 1\n",
      "coaches 1\n",
      "thought-leaders 1\n",
      "value-orientation 1\n",
      "employee-centric 1\n",
      "journal 1\n",
      "fast50 1\n",
      "cloudbees 1\n",
      "improved 1\n",
      "religious/medical 1\n",
      "affect 1\n",
      "retaliation 1\n",
      "matriculation 2\n",
      "contacting 1\n",
      "recruting@simpletechnology.io.hiring 1\n",
      "cryptography 1\n",
      "encryption 5\n",
      "element-level 1\n",
      "microfocus 1\n",
      "voltage 5\n",
      "tier 3\n",
      "wrapper 3\n",
      "wants 1\n",
      "write/support 1\n",
      "data-element 1\n",
      "ease 1\n",
      "security/governance 1\n",
      "data-in-motion 1\n",
      "consult 1\n",
      "addresses 1\n",
      "confusion 1\n",
      "measurable 1\n",
      "communicating 1\n",
      "correction 1\n",
      "paradigms 1\n",
      "micro 1\n",
      "pandemic 1\n",
      "trained 1\n",
      "li-dp1 1\n",
      "$96.4k 1\n",
      "20004.loading 1\n",
      "supervises 1\n",
      "dhs 1\n",
      "multi-year 1\n",
      "chief 3\n",
      "customs 1\n",
      "border 1\n",
      "drafting 2\n",
      "qlik 2\n",
      "ocmo 1\n",
      "procedural 1\n",
      "bursting 1\n",
      "publication 1\n",
      "shooting 1\n",
      "dimensional 3\n",
      "migrating 2\n",
      "clr 1\n",
      "shall 2\n",
      "abide 1\n",
      "41cfr 1\n",
      "60-1.4 1\n",
      "60-1.4(a 1\n",
      "60-300.5 1\n",
      "60-300.5(a 1\n",
      "60-741.5 1\n",
      "60-741.5(a 1\n",
      "prohibit 2\n",
      "moreover 1\n",
      "prime 1\n",
      "$112k 1\n",
      "20005.loading 1\n",
      "surveyjob 1\n",
      "msrbs 1\n",
      "cross 1\n",
      "wrangler 1\n",
      "enjoys 1\n",
      "semi-structure 1\n",
      "data-related 1\n",
      "education/qualifications 1\n",
      "queuing 1\n",
      "aurora 1\n",
      "eventbridge 1\n",
      "parquet 1\n",
      "avro 1\n",
      "multi 1\n",
      "hybrid/multi 1\n",
      "microservices 3\n",
      "apis.hiring 1\n",
      "typecontractindeeds 1\n",
      "$98.1k 1\n",
      "$124k 1\n",
      "lanham 2\n",
      "20706.loading 1\n",
      "databases3 1\n",
      "plsqlexperience 1\n",
      "systemability 1\n",
      "unix 2\n",
      "scriptsability 1\n",
      "clearanceba 1\n",
      "$55 1\n",
      "$60 1\n",
      "typecontractfull 1\n",
      "vosb 1\n",
      "years+ 2\n",
      "stable 2\n",
      "skype 2\n",
      "h1b 2\n",
      "gc 2\n",
      "speak 2\n",
      "yarn 2\n",
      "mapreduce 2\n",
      "oozie 2\n",
      "data/dimensional 2\n",
      "hbase 2\n",
      "cassandra 2\n",
      "db 2\n",
      "talend 1\n",
      "kettle 1\n",
      "ab 1\n",
      "initio 1\n",
      "hibench 1\n",
      "ycsb 1\n",
      "ganglia 1\n",
      "nagios 1\n",
      "dynatrace 1\n",
      "murray 1\n",
      "newcomb 1\n",
      "laison 1\n",
      "unlike 1\n",
      "cs 1\n",
      "35 1\n",
      "unix/linux 1\n",
      "recruiters 1\n",
      "703-501-8395 1\n",
      "www.etwws.com 1\n",
      "$55.00 1\n",
      "$60.00 1\n",
      "indeed 1\n",
      "hadaoop 1\n",
      "coludera 1\n",
      "$94.1k 1\n",
      "$119k 1\n",
      "20301.loading 1\n",
      "lpi 4\n",
      "administrative 2\n",
      "oversight 1\n",
      "usmc 2\n",
      "marine 4\n",
      "coalition 1\n",
      "expeditionary 1\n",
      "pfm 2\n",
      "war 1\n",
      "reserve 1\n",
      "prepositioning 1\n",
      "reengineering 1\n",
      "oag 1\n",
      "dsd 1\n",
      "lpm-3 1\n",
      "enterprise-level 1\n",
      "hierarchy 1\n",
      "curating 1\n",
      "hundreds 1\n",
      "injects 1\n",
      "logistics-specific 1\n",
      "readiness 1\n",
      "blocks 1\n",
      "enhanced 1\n",
      "duties/responsibilities 1\n",
      "enterprise-owned 1\n",
      "rules 1\n",
      "rules/calculations 1\n",
      "traceability 1\n",
      "lineage 3\n",
      "governed 1\n",
      "columns 1\n",
      "published 1\n",
      "adopting 1\n",
      "parent/child 1\n",
      "tagging 1\n",
      "navigation 1\n",
      "mechanism 1\n",
      "falling 1\n",
      "dictionary 1\n",
      "sync 1\n",
      "relate 1\n",
      "cataloging 2\n",
      "dependency 1\n",
      "maturation 1\n",
      "querying 1\n",
      "querying/scripting 1\n",
      "telework/remote 1\n",
      "pentagon 1\n",
      "significantly 1\n",
      "lockheed 7\n",
      "martin 6\n",
      "increased 1\n",
      "uncertainty 1\n",
      "variants 1\n",
      "pose 1\n",
      "commitments 1\n",
      "uphold 1\n",
      "unvaccinated 1\n",
      "description:this 1\n",
      "lm 2\n",
      "cdao 1\n",
      "guides 1\n",
      "users.establish 1\n",
      "productivity 1\n",
      "velocity 1\n",
      "effectiveness.we 1\n",
      "business-critical 1\n",
      "improvement.collaborate 1\n",
      "stakeholders.build 1\n",
      "tackle 2\n",
      "solutionsfunctional 1\n",
      "operationsdemonstrate 1\n",
      "rotations 1\n",
      "management.strong 1\n",
      "frameworkunderstanding 1\n",
      "of/experience 1\n",
      "practicesfamiliarity 1\n",
      "aws/cloud 1\n",
      "technologiesleverage 1\n",
      "platformbuild 1\n",
      "serverless 1\n",
      "applicationsbuild 1\n",
      "aws)evaluate 1\n",
      "practices.ability 1\n",
      "strategystrong 1\n",
      "sophisticated 1\n",
      "business-friendly 1\n",
      "experiencedemonstrate 1\n",
      "status-quo 1\n",
      "tabledemonstrated 1\n",
      "environment.working 1\n",
      "bitbucketexperience 1\n",
      "kuberneteseye 1\n",
      "experienceproven 1\n",
      "organizations.staff 1\n",
      "promotions 1\n",
      "etc. 1\n",
      "etc.)experience 1\n",
      "retiring 1\n",
      "platforms.proven 1\n",
      "framework 1\n",
      "kanban.prior 1\n",
      "job.qualifications 1\n",
      "ours 1\n",
      "hardest 1\n",
      "extraordinary 1\n",
      "amounts 1\n",
      "resilience 1\n",
      "precision 1\n",
      "they’re 1\n",
      "dangerous 1\n",
      "martins 1\n",
      "internationally 1\n",
      "territories 1\n",
      "professionalhiring 1\n",
      "$93.5k 1\n",
      "$118k 2\n",
      "videos 1\n",
      "annotating 1\n",
      "optimizes 1\n",
      "cbos 1\n",
      "asl 4\n",
      "bilingual 3\n",
      "beta 1\n",
      "lens 1\n",
      "bilingualism 1\n",
      "grammatical 1\n",
      "american 2\n",
      "sign 2\n",
      "discovers 1\n",
      "dataset 1\n",
      "intertwine 1\n",
      "deploys 1\n",
      "annotators 1\n",
      "translators 1\n",
      "loose 1\n",
      "co-workers 1\n",
      "genuine 1\n",
      "workshops 1\n",
      "ix 2\n",
      "reporter 1\n",
      "screened 1\n",
      "wide-column 1\n",
      "demonstrative 1\n",
      "negotiate 1\n",
      "deadline-driven 1\n",
      "constituents 1\n",
      "valuing 1\n",
      "samples 1\n",
      "influenza 1\n",
      "flu 1\n",
      "cannot 1\n",
      "gallaudet 2\n",
      "exempt 1\n",
      "employer/educational 1\n",
      "hearing 1\n",
      "income 1\n",
      "residence 1\n",
      "unlawful 1\n",
      "vii 1\n",
      "necessarily 1\n",
      "recruitment 1\n",
      "reassignment 1\n",
      "reappointment 1\n",
      "tenure 1\n",
      "demotion 1\n",
      "furlough 1\n",
      "privileges 1\n",
      "privacyops 1\n",
      "businessops 1\n",
      "dev/businessops 1\n",
      "coinbase 1\n",
      "samsara 1\n",
      "twilio 1\n",
      "robinhood 1\n",
      "flexport 1\n",
      "constructing 1\n",
      "scrappiness 1\n",
      "heavily 1\n",
      "test-driven 1\n",
      "obsess 1\n",
      "simplest 1\n",
      "nlp 2\n",
      "text 1\n",
      "entity 1\n",
      "summarization 1\n",
      "scikit-learn 1\n",
      "pytorch 1\n",
      "tensorflow 1\n",
      "keras 1\n",
      "spacy 1\n",
      "huggingface 1\n",
      "gensim 1\n",
      "labeling 1\n",
      "age-old 1\n",
      "$149k 1\n",
      "organizationnow 1\n",
      "redhorse 5\n",
      "environmental 1\n",
      "descriptionredhorse 1\n",
      "high-level 1\n",
      "reconnaissance 1\n",
      "isr 1\n",
      "ousd 1\n",
      "i&s 1\n",
      "ousd(i&s 1\n",
      "maximal 1\n",
      "buy-in 1\n",
      "compartmented 1\n",
      "comprehension 1\n",
      "engineering-specific 1\n",
      "structuring 1\n",
      "retrieving 1\n",
      "deconflicting 1\n",
      "general-purpose 1\n",
      "nodejs 1\n",
      "soap 1\n",
      "text-based 1\n",
      "development/database 1\n",
      "december 1\n",
      "whichever 1\n",
      "discretion 1\n",
      "adjust 1\n",
      "redhorses 2\n",
      "needs.this 1\n",
      "adjusted 1\n",
      "sole 1\n",
      "discretion.eoe 1\n",
      "vet 1\n",
      "discretion.eoe/m/f/vet/disabled 1\n",
      "66%job 1\n",
      "28 1\n"
     ]
    }
   ],
   "source": [
    "for keys, values in word_frequency.items():\n",
    "    print(keys, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b38f4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
