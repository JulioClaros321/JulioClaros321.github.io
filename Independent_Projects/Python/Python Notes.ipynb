{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f25c2722-0790-4003-ab7b-0cae3bb2260f",
   "metadata": {},
   "source": [
    "# Python Code Block Function Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebdef3e4-0bff-4358-ba6e-e7b1ab093121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports \n",
    "import pyspark \n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "'''\n",
    "import datetime, time, logging, pyspark, sys\n",
    "from datetime import datetime, date, timedelta\n",
    "import boto3\n",
    "import re\n",
    "import logging\n",
    "\n",
    "from pyspark import SparkContext \n",
    "from pyspark.context import SparkContext\n",
    "\n",
    "from awsglue.transforms import *\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "from awsglue.utils import getResolvedOptions\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, regexp_replace, input_file_name\n",
    "import pyspark.sql.functions as sqlfIntegerType\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType, FloatType\n",
    "'''\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('headstart_pipeline_code') \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\",\"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8d20aa-364b-4990-aa66-1793a360d4c5",
   "metadata": {},
   "source": [
    "# Generate S3 Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d79b99-8111-41da-bf10-31c3296ee682",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_bucket_name = (str(s3_input).split('/'))[2] ## Extracts ads bucket mame from S3://ads_bucket/folder Parameter S3_INPUT\n",
    "\n",
    "\n",
    "def generate_curated_layer_folders(bucket_name):\n",
    "    #Check if problem_history_outcome folder exists, if not add it to the curated layer\n",
    "    s3 = boto3.client('s3')\n",
    "    list_of_folders = [\"folder\", \"folder\", \"folder\"]\n",
    "    \n",
    "    for folder in list_of_folders:\n",
    "        response = s3.list_objects_v2(Bucket=bucket_name, Prefix=\"curated/\" + folder + \"/\")\n",
    "        \n",
    "        if 'Contents' in response:\n",
    "            # Folder exists\n",
    "            logger.info(\"problem_history_outcome folder exists and code will begin executing\")\n",
    "        else:\n",
    "            logger.info(\"Folder problem_history_outcome not found, will add it now\")   \n",
    "            s3.put_object(Bucket=bucket_name, Key=\"curated/\" + folder + \"/\")\n",
    "\n",
    "generate_curated_layer_folders(ads_bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c2a61e-ee39-4143-a9c7-90c6c79fdc0b",
   "metadata": {},
   "source": [
    "# General Pyspark Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65fab0f-2afb-413c-8a92-e97dcf536092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# education = spark.read.option(\"delimiter\", \";\").option(\"header\", True).csv(path)\n",
    "\n",
    "# df.createOrReplaceTempView(\"people\")\n",
    "\n",
    "#source_df = source_df.withColumn(\"input_file_name\", input_file_name())\n",
    "#source_df = source_df.withColumn(\"input_file_name\", input_file_name())\n",
    "#removed_column = regexp_replace(col(\"input_file_name\"), \".csv\", \"\")\n",
    "#source_df = source_df.withColumn(\"file_name\", removed_column).drop(\"input_file_name\")\n",
    "\n",
    "#split_col = pyspark.sql.functions.split(source_df['file_name'], '/')\n",
    "#further_split = pyspark.sql.functions.split(split_col.getItem(5), \"_\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
