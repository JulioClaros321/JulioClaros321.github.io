{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f8c6377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jclaros\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24a9eefa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t = tf.zeros([5,5,5,5])\n",
    "t = tf.reshape(t, [625])\n",
    "#print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40f4568",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f5316b",
   "metadata": {},
   "source": [
    "## Linear Regression Tutorial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb7fdf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import matplotlib.pyplot as plt #visualization of charts and graphs\n",
    "from IPython.display import clear_output\n",
    "from six.moves import urllib \n",
    "\n",
    "import tensorflow.compat.v2.feature_column as fc #feature column for linear regression model \n",
    "\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb565738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cef171fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.75, 'accuracy_baseline': 0.625, 'auc': 0.8361799, 'auc_precision_recall': 0.7766994, 'average_loss': 0.47838226, 'label/mean': 0.375, 'loss': 0.46765268, 'precision': 0.6633663, 'prediction/mean': 0.37318197, 'recall': 0.67676765, 'global_step': 300}\n"
     ]
    }
   ],
   "source": [
    "# Titanic Datasets Survival Rates\n",
    "#dftrain.age.hist(bins=20)\n",
    "#dftrain.sex.value_counts().plot(kind='barh') Gender bar graph sideways \n",
    "#dftrain['class'].value_counts().plot(kind='barh') Classes as side bargraph \n",
    "#pd.concat([dftrain, ytrain], axis= 1).groupby('sex').survived.mean().plot(kind='barh').set_xlabel('% survive')\n",
    "\n",
    "\n",
    "\n",
    "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n",
    "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\n",
    "\n",
    "ytrain = dftrain.pop('survived') # Removed the survived column\n",
    "y_eval = dfeval.pop('survived') # Removed the survived column\n",
    "\n",
    "\n",
    "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck', 'embark_town', 'alone']\n",
    "numeric_columns = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "for feature_name in categorical_columns: \n",
    "    vocabulary = dftrain[feature_name].unique() # Gets a list of unique values \n",
    "    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
    "    \n",
    "for feature_name in numeric_columns: \n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
    "\n",
    "\n",
    "    \n",
    "def make_input_fn(data_df, label_df, num_epocs=15, shuffle=True, batch_size=32): \n",
    "    def input_function(): \n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df)) #create a tf.data.dataset object with data and its la\n",
    "        if shuffle: \n",
    "            ds = ds.shuffle(1000) # randomize order of data \n",
    "        ds = ds.batch(batch_size).repeat(num_epocs) # Split dataset into batches of 32 & repeat process\n",
    "        return ds #return a batch of the dataset \n",
    "    return input_function # return a function object for use\n",
    "\n",
    "train_input_fn = make_input_fn(dftrain, ytrain) #Call input function that was returned to use to get a a \n",
    "eval_input_fn = make_input_fn(dfeval, y_eval, num_epocs=1, shuffle=False)\n",
    "\n",
    "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
    "\n",
    "linear_est.train(train_input_fn) # train\n",
    "result = linear_est.evaluate(eval_input_fn) # get model metrics/stats by testing on testing data\n",
    "\n",
    "clear_output() # clears console output\n",
    "print(result) # the result variable is simply a dict of stats about our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "796d4a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\jclaros\\AppData\\Local\\Temp\\tmp3mhpusoq\\model.ckpt-300\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "sex                        female\n",
      "age                          58.0\n",
      "n_siblings_spouses              0\n",
      "parch                           0\n",
      "fare                        26.55\n",
      "class                       First\n",
      "deck                            C\n",
      "embark_town           Southampton\n",
      "alone                           y\n",
      "Name: 2, dtype: object\n",
      "SURVIVED: 1\n",
      "0.63567215\n"
     ]
    }
   ],
   "source": [
    "result = list(linear_est.predict(eval_input_fn))\n",
    "print(dfeval.loc[2])\n",
    "print('SURVIVED: ' + str(y_eval.loc[2]))\n",
    "print(result[2]['probabilities'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db61b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cae49cf4",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "# CLASSIFICATION TUTORIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0aa61b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf \n",
    "import pandas as pd \n",
    "\n",
    "# Defining constants for model \n",
    "csv_column_names = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species'] \n",
    "species = ['Setosa', 'Versicolor', 'Virginica'] \n",
    "\n",
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=csv_column_names, header=0) \n",
    "test = pd.read_csv(test_path, names=csv_column_names, header=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e427e1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0a61956e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          6.4         2.8          5.6         2.2\n",
       "1          5.0         2.3          3.3         1.0\n",
       "2          4.9         2.5          4.5         1.7\n",
       "3          4.9         3.1          1.5         0.1\n",
       "4          5.7         3.8          1.7         0.3"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train.pop('Species') \n",
    "test_y = test.pop('Species') \n",
    "train.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "226f1e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "99cc7902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n",
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n",
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n",
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256): \n",
    "    #Convert the inputs to a dataset \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    \n",
    "    # Shuffle and repeat if you are in training mode \n",
    "    if training: \n",
    "        dataset = dataset.shuffle(1000).repeat() \n",
    "    \n",
    "    return dataset.batch(batch_size)\n",
    "\n",
    "\n",
    "my_feature_columns = [] \n",
    "for key in train.keys(): \n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "    print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4d6feb5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\jclaros\\AppData\\Local\\Temp\\tmpnz4fdj3c\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\jclaros\\\\AppData\\\\Local\\\\Temp\\\\tmpnz4fdj3c', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\jclaros\\AppData\\Local\\Temp\\tmpnz4fdj3c\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.928237, step = 0\n",
      "INFO:tensorflow:global_step/sec: 408.209\n",
      "INFO:tensorflow:loss = 1.276284, step = 100 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 526.633\n",
      "INFO:tensorflow:loss = 1.1642407, step = 200 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 545.309\n",
      "INFO:tensorflow:loss = 1.0990688, step = 300 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 595.149\n",
      "INFO:tensorflow:loss = 1.0556593, step = 400 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 607.949\n",
      "INFO:tensorflow:loss = 1.013478, step = 500 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 576.602\n",
      "INFO:tensorflow:loss = 0.9857493, step = 600 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 605.962\n",
      "INFO:tensorflow:loss = 0.9567858, step = 700 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 593.438\n",
      "INFO:tensorflow:loss = 0.935798, step = 800 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 585.001\n",
      "INFO:tensorflow:loss = 0.9126041, step = 900 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 616.985\n",
      "INFO:tensorflow:loss = 0.8922552, step = 1000 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 636.883\n",
      "INFO:tensorflow:loss = 0.87528515, step = 1100 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.18\n",
      "INFO:tensorflow:loss = 0.8544539, step = 1200 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.719\n",
      "INFO:tensorflow:loss = 0.8330009, step = 1300 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 641.016\n",
      "INFO:tensorflow:loss = 0.82278407, step = 1400 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 503.872\n",
      "INFO:tensorflow:loss = 0.81134343, step = 1500 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 663.361\n",
      "INFO:tensorflow:loss = 0.79973876, step = 1600 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.338\n",
      "INFO:tensorflow:loss = 0.78329253, step = 1700 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 633.879\n",
      "INFO:tensorflow:loss = 0.77077055, step = 1800 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 627.61\n",
      "INFO:tensorflow:loss = 0.76677054, step = 1900 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 615.661\n",
      "INFO:tensorflow:loss = 0.74983704, step = 2000 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 618.819\n",
      "INFO:tensorflow:loss = 0.737829, step = 2100 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 670.327\n",
      "INFO:tensorflow:loss = 0.7271491, step = 2200 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.669\n",
      "INFO:tensorflow:loss = 0.7181945, step = 2300 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 729.833\n",
      "INFO:tensorflow:loss = 0.70863545, step = 2400 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.719\n",
      "INFO:tensorflow:loss = 0.6926039, step = 2500 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 663.367\n",
      "INFO:tensorflow:loss = 0.6923671, step = 2600 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 659.064\n",
      "INFO:tensorflow:loss = 0.68529487, step = 2700 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.589\n",
      "INFO:tensorflow:loss = 0.6814672, step = 2800 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 644.851\n",
      "INFO:tensorflow:loss = 0.667363, step = 2900 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 670.915\n",
      "INFO:tensorflow:loss = 0.66378427, step = 3000 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.093\n",
      "INFO:tensorflow:loss = 0.65488595, step = 3100 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 663.958\n",
      "INFO:tensorflow:loss = 0.64604366, step = 3200 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 672.005\n",
      "INFO:tensorflow:loss = 0.6296898, step = 3300 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 672.089\n",
      "INFO:tensorflow:loss = 0.63252115, step = 3400 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.487\n",
      "INFO:tensorflow:loss = 0.6178391, step = 3500 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.533\n",
      "INFO:tensorflow:loss = 0.60930085, step = 3600 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 663.7\n",
      "INFO:tensorflow:loss = 0.6102749, step = 3700 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.732\n",
      "INFO:tensorflow:loss = 0.6068945, step = 3800 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.783\n",
      "INFO:tensorflow:loss = 0.59154177, step = 3900 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 663.228\n",
      "INFO:tensorflow:loss = 0.589159, step = 4000 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 692.712\n",
      "INFO:tensorflow:loss = 0.592734, step = 4100 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 638.339\n",
      "INFO:tensorflow:loss = 0.58575773, step = 4200 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 613.366\n",
      "INFO:tensorflow:loss = 0.5764526, step = 4300 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 618.532\n",
      "INFO:tensorflow:loss = 0.5586257, step = 4400 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.058\n",
      "INFO:tensorflow:loss = 0.56401634, step = 4500 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.574\n",
      "INFO:tensorflow:loss = 0.55892116, step = 4600 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.833\n",
      "INFO:tensorflow:loss = 0.54344654, step = 4700 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.721\n",
      "INFO:tensorflow:loss = 0.5580541, step = 4800 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 675.65\n",
      "INFO:tensorflow:loss = 0.53657514, step = 4900 (0.148 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\jclaros\\AppData\\Local\\Temp\\tmpnz4fdj3c\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.5380647.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x1d5ad344150>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each \n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns = my_feature_columns,\n",
    "    # Two hidden layers of 30 and 10 nodes respectifully \n",
    "    hidden_units=[30, 10], \n",
    "    # The model must choose 3 classes \n",
    "    n_classes=3\n",
    "    )\n",
    "\n",
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True), \n",
    "    steps=5000\n",
    "    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "14c2aebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2024-02-22T18:41:05\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\jclaros\\AppData\\Local\\Temp\\tmpnz4fdj3c\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.28763s\n",
      "INFO:tensorflow:Finished evaluation at 2024-02-22-18:41:05\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.6666667, average_loss = 0.6333119, global_step = 5000, loss = 0.6333119\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: C:\\Users\\jclaros\\AppData\\Local\\Temp\\tmpnz4fdj3c\\model.ckpt-5000\n",
      "\n",
      "Test set accuracy: 0.667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6b78df23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type Numeric values as prompted.\n",
      "SepalLength: 2.4\n",
      "SepalWidth: 2.6\n",
      "PetalLength: 6.5\n",
      "PetalWidth: 6.3\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\jclaros\\AppData\\Local\\Temp\\tmpnz4fdj3c\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Species' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m class_id \u001b[38;5;241m=\u001b[39m pred_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_ids\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     22\u001b[0m probability \u001b[38;5;241m=\u001b[39m pred_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprobabilities\u001b[39m\u001b[38;5;124m'\u001b[39m][class_id]\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrediciton is \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{:.1f}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mSpecies\u001b[49m[class_id], \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m probability))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Species' is not defined"
     ]
    }
   ],
   "source": [
    "def input_fn(features, batch_size=256):\n",
    "    # Convert the inputs to a dataset without labels \n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "predict = {}\n",
    "\n",
    "print(\"Please type Numeric values as prompted.\") \n",
    "\n",
    "for feature in features: \n",
    "    valid = True \n",
    "    while valid:\n",
    "        val = input(feature + \": \") \n",
    "        if not val.isdigit(): valid = False\n",
    "    \n",
    "    predict[feature] = [float(val)]\n",
    "\n",
    "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\n",
    "\n",
    "for pred_dict in predictions: \n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "    \n",
    "    print('Prediciton is \"{}\" ({:.1f}%)'.format(Species[class_id], 100 * probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d16e93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
